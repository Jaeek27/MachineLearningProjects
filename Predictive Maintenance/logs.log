2023-04-02 11:45:31,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-02 11:45:31,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-02 11:45:31,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-02 11:45:31,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-02 11:45:32,775:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-02 11:45:33,526:INFO:PyCaret ClassificationExperiment
2023-04-02 11:45:33,526:INFO:Logging name: clf-default-name
2023-04-02 11:45:33,526:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-02 11:45:33,526:INFO:version 3.0.0
2023-04-02 11:45:33,526:INFO:Initializing setup()
2023-04-02 11:45:33,526:INFO:self.USI: f8f6
2023-04-02 11:45:33,526:INFO:self._variable_keys: {'X_test', 'exp_id', 'html_param', 'pipeline', 'y_test', 'is_multiclass', 'X', 'y_train', 'X_train', 'gpu_param', 'USI', 'y', 'target_param', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'fix_imbalance', 'memory', 'fold_shuffle_param', '_available_plots', 'logging_param', 'log_plots_param', 'idx', 'seed', 'fold_generator', 'fold_groups_param'}
2023-04-02 11:45:33,526:INFO:Checking environment
2023-04-02 11:45:33,526:INFO:python_version: 3.9.12
2023-04-02 11:45:33,526:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-02 11:45:33,526:INFO:machine: AMD64
2023-04-02 11:45:33,526:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-02 11:45:33,526:INFO:Memory: svmem(total=8316030976, available=1355161600, percent=83.7, used=6960869376, free=1355161600)
2023-04-02 11:45:33,526:INFO:Physical Core: 4
2023-04-02 11:45:33,526:INFO:Logical Core: 8
2023-04-02 11:45:33,526:INFO:Checking libraries
2023-04-02 11:45:33,526:INFO:System:
2023-04-02 11:45:33,526:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-02 11:45:33,526:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-04-02 11:45:33,526:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-02 11:45:33,526:INFO:PyCaret required dependencies:
2023-04-02 11:45:33,526:INFO:                 pip: 21.2.4
2023-04-02 11:45:33,526:INFO:          setuptools: 61.2.0
2023-04-02 11:45:33,526:INFO:             pycaret: 3.0.0
2023-04-02 11:45:33,526:INFO:             IPython: 8.2.0
2023-04-02 11:45:33,526:INFO:          ipywidgets: 7.6.5
2023-04-02 11:45:33,526:INFO:                tqdm: 4.64.0
2023-04-02 11:45:33,526:INFO:               numpy: 1.21.6
2023-04-02 11:45:33,526:INFO:              pandas: 1.4.2
2023-04-02 11:45:33,526:INFO:              jinja2: 2.11.3
2023-04-02 11:45:33,526:INFO:               scipy: 1.7.3
2023-04-02 11:45:33,526:INFO:              joblib: 1.2.0
2023-04-02 11:45:33,526:INFO:             sklearn: 1.0.2
2023-04-02 11:45:33,526:INFO:                pyod: 1.0.9
2023-04-02 11:45:33,526:INFO:            imblearn: 0.10.1
2023-04-02 11:45:33,526:INFO:   category_encoders: 2.6.0
2023-04-02 11:45:33,526:INFO:            lightgbm: 3.3.5
2023-04-02 11:45:33,526:INFO:               numba: 0.55.1
2023-04-02 11:45:33,526:INFO:            requests: 2.27.1
2023-04-02 11:45:33,526:INFO:          matplotlib: 3.5.1
2023-04-02 11:45:33,526:INFO:          scikitplot: 0.3.7
2023-04-02 11:45:33,526:INFO:         yellowbrick: 1.5
2023-04-02 11:45:33,526:INFO:              plotly: 5.6.0
2023-04-02 11:45:33,526:INFO:             kaleido: 0.2.1
2023-04-02 11:45:33,526:INFO:         statsmodels: 0.13.2
2023-04-02 11:45:33,526:INFO:              sktime: 0.16.1
2023-04-02 11:45:33,526:INFO:               tbats: 1.1.2
2023-04-02 11:45:33,526:INFO:            pmdarima: 2.0.3
2023-04-02 11:45:33,526:INFO:              psutil: 5.9.4
2023-04-02 11:45:33,526:INFO:PyCaret optional dependencies:
2023-04-02 11:45:33,557:INFO:                shap: 0.41.0
2023-04-02 11:45:33,557:INFO:           interpret: Not installed
2023-04-02 11:45:33,557:INFO:                umap: Not installed
2023-04-02 11:45:33,557:INFO:    pandas_profiling: 4.1.2
2023-04-02 11:45:33,557:INFO:  explainerdashboard: Not installed
2023-04-02 11:45:33,557:INFO:             autoviz: Not installed
2023-04-02 11:45:33,557:INFO:           fairlearn: Not installed
2023-04-02 11:45:33,557:INFO:             xgboost: Not installed
2023-04-02 11:45:33,557:INFO:            catboost: Not installed
2023-04-02 11:45:33,557:INFO:              kmodes: Not installed
2023-04-02 11:45:33,557:INFO:             mlxtend: Not installed
2023-04-02 11:45:33,557:INFO:       statsforecast: Not installed
2023-04-02 11:45:33,557:INFO:        tune_sklearn: Not installed
2023-04-02 11:45:33,557:INFO:                 ray: Not installed
2023-04-02 11:45:33,557:INFO:            hyperopt: Not installed
2023-04-02 11:45:33,557:INFO:              optuna: Not installed
2023-04-02 11:45:33,557:INFO:               skopt: Not installed
2023-04-02 11:45:33,557:INFO:              mlflow: Not installed
2023-04-02 11:45:33,557:INFO:              gradio: Not installed
2023-04-02 11:45:33,557:INFO:             fastapi: Not installed
2023-04-02 11:45:33,557:INFO:             uvicorn: Not installed
2023-04-02 11:45:33,557:INFO:              m2cgen: Not installed
2023-04-02 11:45:33,557:INFO:           evidently: Not installed
2023-04-02 11:45:33,557:INFO:               fugue: Not installed
2023-04-02 11:45:33,557:INFO:           streamlit: Not installed
2023-04-02 11:45:33,557:INFO:             prophet: Not installed
2023-04-02 11:45:33,557:INFO:None
2023-04-02 11:45:33,557:INFO:Set up data.
2023-04-02 11:45:33,557:INFO:Set up train/test split.
2023-04-02 11:45:33,573:INFO:Set up index.
2023-04-02 11:45:33,573:INFO:Set up folding strategy.
2023-04-02 11:45:33,573:INFO:Assigning column types.
2023-04-02 11:45:33,588:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-02 11:45:33,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-02 11:45:33,666:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-02 11:45:33,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:33,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:33,792:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-02 11:45:33,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-02 11:45:33,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:33,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:33,838:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-02 11:45:33,901:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-02 11:45:33,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:33,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:33,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-02 11:45:34,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,012:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-02 11:45:34,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,214:INFO:Preparing preprocessing pipeline...
2023-04-02 11:45:34,214:INFO:Set up simple imputation.
2023-04-02 11:45:34,214:INFO:Set up column name cleaning.
2023-04-02 11:45:34,245:INFO:Finished creating preprocessing pipeline.
2023-04-02 11:45:34,245:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Type', 'Air Temperature',
                                             'Process Temperature',
                                             'Rotational Speed', 'Torque',
                                             'Tool Wear', 'Failure Type'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-04-02 11:45:34,245:INFO:Creating final display dataframe.
2023-04-02 11:45:34,370:INFO:Setup _display_container:                     Description             Value
0                    Session id              3395
1                        Target            Target
2                   Target type            Binary
3           Original data shape         (9973, 8)
4        Transformed data shape         (9973, 8)
5   Transformed train set shape         (6981, 8)
6    Transformed test set shape         (2992, 8)
7              Numeric features                 7
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              f8f6
2023-04-02 11:45:34,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-02 11:45:34,623:INFO:setup() successfully completed in 1.7s...............
2023-04-02 11:45:34,644:INFO:Initializing compare_models()
2023-04-02 11:45:34,644:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-02 11:45:34,644:INFO:Checking exceptions
2023-04-02 11:45:34,651:INFO:Preparing display monitor
2023-04-02 11:45:34,683:INFO:Initializing Logistic Regression
2023-04-02 11:45:34,683:INFO:Total runtime is 0.0 minutes
2023-04-02 11:45:34,688:INFO:SubProcess create_model() called ==================================
2023-04-02 11:45:34,689:INFO:Initializing create_model()
2023-04-02 11:45:34,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:45:34,689:INFO:Checking exceptions
2023-04-02 11:45:34,689:INFO:Importing libraries
2023-04-02 11:45:34,689:INFO:Copying training dataset
2023-04-02 11:45:34,693:INFO:Defining folds
2023-04-02 11:45:34,693:INFO:Declaring metric variables
2023-04-02 11:45:34,699:INFO:Importing untrained model
2023-04-02 11:45:34,703:INFO:Logistic Regression Imported successfully
2023-04-02 11:45:34,710:INFO:Starting cross validation
2023-04-02 11:45:34,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:45:44,758:INFO:Calculating mean and std
2023-04-02 11:45:44,758:INFO:Creating metrics dataframe
2023-04-02 11:45:45,461:INFO:Uploading results into container
2023-04-02 11:45:45,461:INFO:Uploading model into container now
2023-04-02 11:45:45,461:INFO:_master_model_container: 1
2023-04-02 11:45:45,461:INFO:_display_container: 2
2023-04-02 11:45:45,461:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3395, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-02 11:45:45,464:INFO:create_model() successfully completed......................................
2023-04-02 11:45:45,657:INFO:SubProcess create_model() end ==================================
2023-04-02 11:45:45,657:INFO:Creating metrics dataframe
2023-04-02 11:45:45,657:INFO:Initializing K Neighbors Classifier
2023-04-02 11:45:45,657:INFO:Total runtime is 0.18289342721303303 minutes
2023-04-02 11:45:45,674:INFO:SubProcess create_model() called ==================================
2023-04-02 11:45:45,674:INFO:Initializing create_model()
2023-04-02 11:45:45,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:45:45,674:INFO:Checking exceptions
2023-04-02 11:45:45,675:INFO:Importing libraries
2023-04-02 11:45:45,675:INFO:Copying training dataset
2023-04-02 11:45:45,681:INFO:Defining folds
2023-04-02 11:45:45,682:INFO:Declaring metric variables
2023-04-02 11:45:45,685:INFO:Importing untrained model
2023-04-02 11:45:45,688:INFO:K Neighbors Classifier Imported successfully
2023-04-02 11:45:45,703:INFO:Starting cross validation
2023-04-02 11:45:45,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:45:49,421:INFO:Calculating mean and std
2023-04-02 11:45:49,421:INFO:Creating metrics dataframe
2023-04-02 11:45:50,000:INFO:Uploading results into container
2023-04-02 11:45:50,000:INFO:Uploading model into container now
2023-04-02 11:45:50,000:INFO:_master_model_container: 2
2023-04-02 11:45:50,000:INFO:_display_container: 2
2023-04-02 11:45:50,000:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-02 11:45:50,000:INFO:create_model() successfully completed......................................
2023-04-02 11:45:50,236:INFO:SubProcess create_model() end ==================================
2023-04-02 11:45:50,236:INFO:Creating metrics dataframe
2023-04-02 11:45:50,252:INFO:Initializing Naive Bayes
2023-04-02 11:45:50,252:INFO:Total runtime is 0.2594771782557169 minutes
2023-04-02 11:45:50,252:INFO:SubProcess create_model() called ==================================
2023-04-02 11:45:50,252:INFO:Initializing create_model()
2023-04-02 11:45:50,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:45:50,252:INFO:Checking exceptions
2023-04-02 11:45:50,252:INFO:Importing libraries
2023-04-02 11:45:50,252:INFO:Copying training dataset
2023-04-02 11:45:50,265:INFO:Defining folds
2023-04-02 11:45:50,265:INFO:Declaring metric variables
2023-04-02 11:45:50,265:INFO:Importing untrained model
2023-04-02 11:45:50,265:INFO:Naive Bayes Imported successfully
2023-04-02 11:45:50,281:INFO:Starting cross validation
2023-04-02 11:45:50,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:45:53,891:INFO:Calculating mean and std
2023-04-02 11:45:53,891:INFO:Creating metrics dataframe
2023-04-02 11:45:54,606:INFO:Uploading results into container
2023-04-02 11:45:54,606:INFO:Uploading model into container now
2023-04-02 11:45:54,606:INFO:_master_model_container: 3
2023-04-02 11:45:54,606:INFO:_display_container: 2
2023-04-02 11:45:54,606:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-02 11:45:54,606:INFO:create_model() successfully completed......................................
2023-04-02 11:45:54,792:INFO:SubProcess create_model() end ==================================
2023-04-02 11:45:54,792:INFO:Creating metrics dataframe
2023-04-02 11:45:54,808:INFO:Initializing Decision Tree Classifier
2023-04-02 11:45:54,808:INFO:Total runtime is 0.33541047970453897 minutes
2023-04-02 11:45:54,808:INFO:SubProcess create_model() called ==================================
2023-04-02 11:45:54,812:INFO:Initializing create_model()
2023-04-02 11:45:54,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:45:54,812:INFO:Checking exceptions
2023-04-02 11:45:54,812:INFO:Importing libraries
2023-04-02 11:45:54,812:INFO:Copying training dataset
2023-04-02 11:45:54,817:INFO:Defining folds
2023-04-02 11:45:54,817:INFO:Declaring metric variables
2023-04-02 11:45:54,820:INFO:Importing untrained model
2023-04-02 11:45:54,826:INFO:Decision Tree Classifier Imported successfully
2023-04-02 11:45:54,835:INFO:Starting cross validation
2023-04-02 11:45:54,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:45:58,411:INFO:Calculating mean and std
2023-04-02 11:45:58,411:INFO:Creating metrics dataframe
2023-04-02 11:45:59,112:INFO:Uploading results into container
2023-04-02 11:45:59,112:INFO:Uploading model into container now
2023-04-02 11:45:59,112:INFO:_master_model_container: 4
2023-04-02 11:45:59,112:INFO:_display_container: 2
2023-04-02 11:45:59,112:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best')
2023-04-02 11:45:59,112:INFO:create_model() successfully completed......................................
2023-04-02 11:45:59,363:INFO:SubProcess create_model() end ==================================
2023-04-02 11:45:59,363:INFO:Creating metrics dataframe
2023-04-02 11:45:59,378:INFO:Initializing SVM - Linear Kernel
2023-04-02 11:45:59,378:INFO:Total runtime is 0.41158087650934855 minutes
2023-04-02 11:45:59,378:INFO:SubProcess create_model() called ==================================
2023-04-02 11:45:59,378:INFO:Initializing create_model()
2023-04-02 11:45:59,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:45:59,378:INFO:Checking exceptions
2023-04-02 11:45:59,378:INFO:Importing libraries
2023-04-02 11:45:59,378:INFO:Copying training dataset
2023-04-02 11:45:59,399:INFO:Defining folds
2023-04-02 11:45:59,399:INFO:Declaring metric variables
2023-04-02 11:45:59,414:INFO:Importing untrained model
2023-04-02 11:45:59,419:INFO:SVM - Linear Kernel Imported successfully
2023-04-02 11:45:59,420:INFO:Starting cross validation
2023-04-02 11:45:59,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:45:59,585:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,593:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,625:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,631:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,631:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:45:59,658:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,662:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,662:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:45:59,662:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,686:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:45:59,688:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:00,350:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:46:00,366:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:00,366:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-02 11:46:00,381:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:03,118:INFO:Calculating mean and std
2023-04-02 11:46:03,118:INFO:Creating metrics dataframe
2023-04-02 11:46:03,792:INFO:Uploading results into container
2023-04-02 11:46:03,792:INFO:Uploading model into container now
2023-04-02 11:46:03,792:INFO:_master_model_container: 5
2023-04-02 11:46:03,792:INFO:_display_container: 2
2023-04-02 11:46:03,792:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3395, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-02 11:46:03,792:INFO:create_model() successfully completed......................................
2023-04-02 11:46:04,004:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:04,004:INFO:Creating metrics dataframe
2023-04-02 11:46:04,021:INFO:Initializing Ridge Classifier
2023-04-02 11:46:04,021:INFO:Total runtime is 0.4889670530954997 minutes
2023-04-02 11:46:04,021:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:04,021:INFO:Initializing create_model()
2023-04-02 11:46:04,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:04,021:INFO:Checking exceptions
2023-04-02 11:46:04,021:INFO:Importing libraries
2023-04-02 11:46:04,021:INFO:Copying training dataset
2023-04-02 11:46:04,033:INFO:Defining folds
2023-04-02 11:46:04,033:INFO:Declaring metric variables
2023-04-02 11:46:04,038:INFO:Importing untrained model
2023-04-02 11:46:04,040:INFO:Ridge Classifier Imported successfully
2023-04-02 11:46:04,049:INFO:Starting cross validation
2023-04-02 11:46:04,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:04,165:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,165:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,165:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,178:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,194:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,221:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,226:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,226:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,907:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:04,922:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-02 11:46:07,543:INFO:Calculating mean and std
2023-04-02 11:46:07,543:INFO:Creating metrics dataframe
2023-04-02 11:46:08,350:INFO:Uploading results into container
2023-04-02 11:46:08,350:INFO:Uploading model into container now
2023-04-02 11:46:08,365:INFO:_master_model_container: 6
2023-04-02 11:46:08,365:INFO:_display_container: 2
2023-04-02 11:46:08,365:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=3395, solver='auto', tol=0.001)
2023-04-02 11:46:08,365:INFO:create_model() successfully completed......................................
2023-04-02 11:46:08,554:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:08,554:INFO:Creating metrics dataframe
2023-04-02 11:46:08,586:INFO:Initializing Random Forest Classifier
2023-04-02 11:46:08,586:INFO:Total runtime is 0.5650367657343547 minutes
2023-04-02 11:46:08,590:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:08,591:INFO:Initializing create_model()
2023-04-02 11:46:08,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:08,591:INFO:Checking exceptions
2023-04-02 11:46:08,591:INFO:Importing libraries
2023-04-02 11:46:08,591:INFO:Copying training dataset
2023-04-02 11:46:08,598:INFO:Defining folds
2023-04-02 11:46:08,599:INFO:Declaring metric variables
2023-04-02 11:46:08,603:INFO:Importing untrained model
2023-04-02 11:46:08,605:INFO:Random Forest Classifier Imported successfully
2023-04-02 11:46:08,614:INFO:Starting cross validation
2023-04-02 11:46:08,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:13,274:INFO:Calculating mean and std
2023-04-02 11:46:13,274:INFO:Creating metrics dataframe
2023-04-02 11:46:14,085:INFO:Uploading results into container
2023-04-02 11:46:14,085:INFO:Uploading model into container now
2023-04-02 11:46:14,085:INFO:_master_model_container: 7
2023-04-02 11:46:14,085:INFO:_display_container: 2
2023-04-02 11:46:14,085:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3395, verbose=0, warm_start=False)
2023-04-02 11:46:14,085:INFO:create_model() successfully completed......................................
2023-04-02 11:46:14,288:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:14,288:INFO:Creating metrics dataframe
2023-04-02 11:46:14,288:INFO:Initializing Quadratic Discriminant Analysis
2023-04-02 11:46:14,288:INFO:Total runtime is 0.6600749532381693 minutes
2023-04-02 11:46:14,306:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:14,306:INFO:Initializing create_model()
2023-04-02 11:46:14,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:14,306:INFO:Checking exceptions
2023-04-02 11:46:14,306:INFO:Importing libraries
2023-04-02 11:46:14,306:INFO:Copying training dataset
2023-04-02 11:46:14,311:INFO:Defining folds
2023-04-02 11:46:14,312:INFO:Declaring metric variables
2023-04-02 11:46:14,316:INFO:Importing untrained model
2023-04-02 11:46:14,319:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-02 11:46:14,321:INFO:Starting cross validation
2023-04-02 11:46:14,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:14,412:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,412:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,428:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,428:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,459:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,475:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,507:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,523:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,523:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,523:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,523:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,523:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,538:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,538:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,538:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,538:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,538:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:14,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:14,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:14,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:14,570:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:15,227:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:15,244:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-02 11:46:15,259:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,259:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,259:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:15,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:15,290:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:15,306:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,306:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-02 11:46:15,306:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-02 11:46:15,306:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-04-02 11:46:15,306:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:18,089:INFO:Calculating mean and std
2023-04-02 11:46:18,105:INFO:Creating metrics dataframe
2023-04-02 11:46:18,694:INFO:Uploading results into container
2023-04-02 11:46:18,694:INFO:Uploading model into container now
2023-04-02 11:46:18,694:INFO:_master_model_container: 8
2023-04-02 11:46:18,694:INFO:_display_container: 2
2023-04-02 11:46:18,694:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-02 11:46:18,694:INFO:create_model() successfully completed......................................
2023-04-02 11:46:18,936:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:18,936:INFO:Creating metrics dataframe
2023-04-02 11:46:18,936:INFO:Initializing Ada Boost Classifier
2023-04-02 11:46:18,936:INFO:Total runtime is 0.7375493288040161 minutes
2023-04-02 11:46:18,959:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:18,960:INFO:Initializing create_model()
2023-04-02 11:46:18,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:18,961:INFO:Checking exceptions
2023-04-02 11:46:18,961:INFO:Importing libraries
2023-04-02 11:46:18,961:INFO:Copying training dataset
2023-04-02 11:46:18,973:INFO:Defining folds
2023-04-02 11:46:18,973:INFO:Declaring metric variables
2023-04-02 11:46:18,973:INFO:Importing untrained model
2023-04-02 11:46:18,982:INFO:Ada Boost Classifier Imported successfully
2023-04-02 11:46:18,989:INFO:Starting cross validation
2023-04-02 11:46:18,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:23,198:INFO:Calculating mean and std
2023-04-02 11:46:23,198:INFO:Creating metrics dataframe
2023-04-02 11:46:23,698:INFO:Uploading results into container
2023-04-02 11:46:23,698:INFO:Uploading model into container now
2023-04-02 11:46:23,698:INFO:_master_model_container: 9
2023-04-02 11:46:23,698:INFO:_display_container: 2
2023-04-02 11:46:23,698:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3395)
2023-04-02 11:46:23,698:INFO:create_model() successfully completed......................................
2023-04-02 11:46:23,972:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:23,972:INFO:Creating metrics dataframe
2023-04-02 11:46:23,982:INFO:Initializing Gradient Boosting Classifier
2023-04-02 11:46:23,982:INFO:Total runtime is 0.8216369311014812 minutes
2023-04-02 11:46:23,982:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:23,982:INFO:Initializing create_model()
2023-04-02 11:46:23,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:23,982:INFO:Checking exceptions
2023-04-02 11:46:23,982:INFO:Importing libraries
2023-04-02 11:46:23,982:INFO:Copying training dataset
2023-04-02 11:46:23,982:INFO:Defining folds
2023-04-02 11:46:23,982:INFO:Declaring metric variables
2023-04-02 11:46:23,982:INFO:Importing untrained model
2023-04-02 11:46:24,001:INFO:Gradient Boosting Classifier Imported successfully
2023-04-02 11:46:24,009:INFO:Starting cross validation
2023-04-02 11:46:24,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:29,413:INFO:Calculating mean and std
2023-04-02 11:46:29,414:INFO:Creating metrics dataframe
2023-04-02 11:46:29,906:INFO:Uploading results into container
2023-04-02 11:46:29,907:INFO:Uploading model into container now
2023-04-02 11:46:29,908:INFO:_master_model_container: 10
2023-04-02 11:46:29,908:INFO:_display_container: 2
2023-04-02 11:46:29,909:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3395, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-02 11:46:29,909:INFO:create_model() successfully completed......................................
2023-04-02 11:46:30,131:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:30,131:INFO:Creating metrics dataframe
2023-04-02 11:46:30,149:INFO:Initializing Linear Discriminant Analysis
2023-04-02 11:46:30,149:INFO:Total runtime is 0.924422287940979 minutes
2023-04-02 11:46:30,163:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:30,163:INFO:Initializing create_model()
2023-04-02 11:46:30,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:30,163:INFO:Checking exceptions
2023-04-02 11:46:30,164:INFO:Importing libraries
2023-04-02 11:46:30,164:INFO:Copying training dataset
2023-04-02 11:46:30,165:INFO:Defining folds
2023-04-02 11:46:30,165:INFO:Declaring metric variables
2023-04-02 11:46:30,165:INFO:Importing untrained model
2023-04-02 11:46:30,181:INFO:Linear Discriminant Analysis Imported successfully
2023-04-02 11:46:30,192:INFO:Starting cross validation
2023-04-02 11:46:30,194:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:34,160:INFO:Calculating mean and std
2023-04-02 11:46:34,161:INFO:Creating metrics dataframe
2023-04-02 11:46:34,757:INFO:Uploading results into container
2023-04-02 11:46:34,758:INFO:Uploading model into container now
2023-04-02 11:46:34,759:INFO:_master_model_container: 11
2023-04-02 11:46:34,760:INFO:_display_container: 2
2023-04-02 11:46:34,760:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-02 11:46:34,760:INFO:create_model() successfully completed......................................
2023-04-02 11:46:34,964:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:34,964:INFO:Creating metrics dataframe
2023-04-02 11:46:34,964:INFO:Initializing Extra Trees Classifier
2023-04-02 11:46:34,964:INFO:Total runtime is 1.004677911599477 minutes
2023-04-02 11:46:34,980:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:34,980:INFO:Initializing create_model()
2023-04-02 11:46:34,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:34,980:INFO:Checking exceptions
2023-04-02 11:46:34,980:INFO:Importing libraries
2023-04-02 11:46:34,980:INFO:Copying training dataset
2023-04-02 11:46:34,980:INFO:Defining folds
2023-04-02 11:46:34,980:INFO:Declaring metric variables
2023-04-02 11:46:34,995:INFO:Importing untrained model
2023-04-02 11:46:34,995:INFO:Extra Trees Classifier Imported successfully
2023-04-02 11:46:34,995:INFO:Starting cross validation
2023-04-02 11:46:34,995:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:39,964:INFO:Calculating mean and std
2023-04-02 11:46:39,980:INFO:Creating metrics dataframe
2023-04-02 11:46:40,496:INFO:Uploading results into container
2023-04-02 11:46:40,497:INFO:Uploading model into container now
2023-04-02 11:46:40,497:INFO:_master_model_container: 12
2023-04-02 11:46:40,497:INFO:_display_container: 2
2023-04-02 11:46:40,497:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3395, verbose=0, warm_start=False)
2023-04-02 11:46:40,497:INFO:create_model() successfully completed......................................
2023-04-02 11:46:40,766:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:40,766:INFO:Creating metrics dataframe
2023-04-02 11:46:40,777:INFO:Initializing Light Gradient Boosting Machine
2023-04-02 11:46:40,777:INFO:Total runtime is 1.1015520373980203 minutes
2023-04-02 11:46:40,781:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:40,782:INFO:Initializing create_model()
2023-04-02 11:46:40,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:40,782:INFO:Checking exceptions
2023-04-02 11:46:40,782:INFO:Importing libraries
2023-04-02 11:46:40,782:INFO:Copying training dataset
2023-04-02 11:46:40,789:INFO:Defining folds
2023-04-02 11:46:40,789:INFO:Declaring metric variables
2023-04-02 11:46:40,793:INFO:Importing untrained model
2023-04-02 11:46:40,798:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-02 11:46:40,805:INFO:Starting cross validation
2023-04-02 11:46:40,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:46,444:INFO:Calculating mean and std
2023-04-02 11:46:46,446:INFO:Creating metrics dataframe
2023-04-02 11:46:47,253:INFO:Uploading results into container
2023-04-02 11:46:47,253:INFO:Uploading model into container now
2023-04-02 11:46:47,253:INFO:_master_model_container: 13
2023-04-02 11:46:47,262:INFO:_display_container: 2
2023-04-02 11:46:47,262:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3395, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-02 11:46:47,262:INFO:create_model() successfully completed......................................
2023-04-02 11:46:47,448:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:47,448:INFO:Creating metrics dataframe
2023-04-02 11:46:47,464:INFO:Initializing Dummy Classifier
2023-04-02 11:46:47,464:INFO:Total runtime is 1.2130112449328103 minutes
2023-04-02 11:46:47,464:INFO:SubProcess create_model() called ==================================
2023-04-02 11:46:47,464:INFO:Initializing create_model()
2023-04-02 11:46:47,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC108850>, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:47,464:INFO:Checking exceptions
2023-04-02 11:46:47,464:INFO:Importing libraries
2023-04-02 11:46:47,464:INFO:Copying training dataset
2023-04-02 11:46:47,482:INFO:Defining folds
2023-04-02 11:46:47,482:INFO:Declaring metric variables
2023-04-02 11:46:47,485:INFO:Importing untrained model
2023-04-02 11:46:47,489:INFO:Dummy Classifier Imported successfully
2023-04-02 11:46:47,498:INFO:Starting cross validation
2023-04-02 11:46:47,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:46:47,635:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,654:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,665:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,686:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,686:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,732:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,749:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:47,832:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:48,534:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:48,536:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-02 11:46:51,642:INFO:Calculating mean and std
2023-04-02 11:46:51,642:INFO:Creating metrics dataframe
2023-04-02 11:46:52,180:INFO:Uploading results into container
2023-04-02 11:46:52,180:INFO:Uploading model into container now
2023-04-02 11:46:52,180:INFO:_master_model_container: 14
2023-04-02 11:46:52,180:INFO:_display_container: 2
2023-04-02 11:46:52,180:INFO:DummyClassifier(constant=None, random_state=3395, strategy='prior')
2023-04-02 11:46:52,180:INFO:create_model() successfully completed......................................
2023-04-02 11:46:52,430:INFO:SubProcess create_model() end ==================================
2023-04-02 11:46:52,430:INFO:Creating metrics dataframe
2023-04-02 11:46:52,447:INFO:Initializing create_model()
2023-04-02 11:46:52,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:46:52,447:INFO:Checking exceptions
2023-04-02 11:46:52,447:INFO:Importing libraries
2023-04-02 11:46:52,447:INFO:Copying training dataset
2023-04-02 11:46:52,447:INFO:Defining folds
2023-04-02 11:46:52,447:INFO:Declaring metric variables
2023-04-02 11:46:52,447:INFO:Importing untrained model
2023-04-02 11:46:52,447:INFO:Declaring custom model
2023-04-02 11:46:52,447:INFO:Decision Tree Classifier Imported successfully
2023-04-02 11:46:52,462:INFO:Cross validation set to False
2023-04-02 11:46:52,462:INFO:Fitting Model
2023-04-02 11:46:52,947:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best')
2023-04-02 11:46:52,947:INFO:create_model() successfully completed......................................
2023-04-02 11:46:53,220:INFO:_master_model_container: 14
2023-04-02 11:46:53,229:INFO:_display_container: 2
2023-04-02 11:46:53,229:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best')
2023-04-02 11:46:53,230:INFO:compare_models() successfully completed......................................
2023-04-02 11:46:53,248:INFO:Initializing tune_model()
2023-04-02 11:46:53,248:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>)
2023-04-02 11:46:53,249:INFO:Checking exceptions
2023-04-02 11:46:53,270:INFO:Copying training dataset
2023-04-02 11:46:53,280:INFO:Checking base model
2023-04-02 11:46:53,280:INFO:Base model : Decision Tree Classifier
2023-04-02 11:46:53,285:INFO:Declaring metric variables
2023-04-02 11:46:53,286:INFO:Defining Hyperparameters
2023-04-02 11:46:53,498:INFO:Tuning with n_jobs=-1
2023-04-02 11:46:53,498:INFO:Initializing RandomizedSearchCV
2023-04-02 11:47:36,682:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'gini'}
2023-04-02 11:47:36,699:INFO:Hyperparameter search completed
2023-04-02 11:47:36,699:INFO:SubProcess create_model() called ==================================
2023-04-02 11:47:36,699:INFO:Initializing create_model()
2023-04-02 11:47:36,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000212AC34DCD0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.002, 'max_features': 1.0, 'max_depth': 5, 'criterion': 'gini'})
2023-04-02 11:47:36,699:INFO:Checking exceptions
2023-04-02 11:47:36,699:INFO:Importing libraries
2023-04-02 11:47:36,699:INFO:Copying training dataset
2023-04-02 11:47:36,706:INFO:Defining folds
2023-04-02 11:47:36,706:INFO:Declaring metric variables
2023-04-02 11:47:36,712:INFO:Importing untrained model
2023-04-02 11:47:36,712:INFO:Declaring custom model
2023-04-02 11:47:36,719:INFO:Decision Tree Classifier Imported successfully
2023-04-02 11:47:36,726:INFO:Starting cross validation
2023-04-02 11:47:36,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:47:40,455:INFO:Calculating mean and std
2023-04-02 11:47:40,455:INFO:Creating metrics dataframe
2023-04-02 11:47:40,471:INFO:Finalizing model
2023-04-02 11:47:41,128:INFO:Uploading results into container
2023-04-02 11:47:41,128:INFO:Uploading model into container now
2023-04-02 11:47:41,128:INFO:_master_model_container: 15
2023-04-02 11:47:41,128:INFO:_display_container: 3
2023-04-02 11:47:41,128:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=5, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best')
2023-04-02 11:47:41,128:INFO:create_model() successfully completed......................................
2023-04-02 11:47:41,332:INFO:SubProcess create_model() end ==================================
2023-04-02 11:47:41,332:INFO:choose_better activated
2023-04-02 11:47:41,337:INFO:SubProcess create_model() called ==================================
2023-04-02 11:47:41,338:INFO:Initializing create_model()
2023-04-02 11:47:41,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-02 11:47:41,339:INFO:Checking exceptions
2023-04-02 11:47:41,341:INFO:Importing libraries
2023-04-02 11:47:41,341:INFO:Copying training dataset
2023-04-02 11:47:41,346:INFO:Defining folds
2023-04-02 11:47:41,346:INFO:Declaring metric variables
2023-04-02 11:47:41,346:INFO:Importing untrained model
2023-04-02 11:47:41,346:INFO:Declaring custom model
2023-04-02 11:47:41,346:INFO:Decision Tree Classifier Imported successfully
2023-04-02 11:47:41,347:INFO:Starting cross validation
2023-04-02 11:47:41,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-02 11:47:45,388:INFO:Calculating mean and std
2023-04-02 11:47:45,389:INFO:Creating metrics dataframe
2023-04-02 11:47:45,391:INFO:Finalizing model
2023-04-02 11:47:45,861:INFO:Uploading results into container
2023-04-02 11:47:45,877:INFO:Uploading model into container now
2023-04-02 11:47:45,877:INFO:_master_model_container: 16
2023-04-02 11:47:45,877:INFO:_display_container: 4
2023-04-02 11:47:45,877:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best')
2023-04-02 11:47:45,877:INFO:create_model() successfully completed......................................
2023-04-02 11:47:46,067:INFO:SubProcess create_model() end ==================================
2023-04-02 11:47:46,067:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best') result for Accuracy is 1.0
2023-04-02 11:47:46,067:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=5, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best') result for Accuracy is 1.0
2023-04-02 11:47:46,067:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best') is best model
2023-04-02 11:47:46,067:INFO:choose_better completed
2023-04-02 11:47:46,082:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-02 11:47:46,101:INFO:_master_model_container: 16
2023-04-02 11:47:46,101:INFO:_display_container: 3
2023-04-02 11:47:46,101:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best')
2023-04-02 11:47:46,101:INFO:tune_model() successfully completed......................................
2023-04-02 11:47:46,744:INFO:Initializing plot_model()
2023-04-02 11:47:46,744:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3395, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000212A242A1F0>, system=True)
2023-04-02 11:47:46,744:INFO:Checking exceptions
2023-04-02 11:47:46,745:INFO:Preloading libraries
2023-04-02 11:47:46,745:INFO:Copying training dataset
2023-04-02 11:47:46,745:INFO:Plot type: confusion_matrix
2023-04-02 11:47:46,876:INFO:Fitting Model
2023-04-02 11:47:46,892:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-02 11:47:46,892:INFO:Scoring test/hold-out set
2023-04-02 11:47:47,015:INFO:Visual Rendered Successfully
2023-04-02 11:47:47,239:INFO:plot_model() successfully completed......................................
