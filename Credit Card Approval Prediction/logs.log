2023-03-30 12:31:21,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 12:31:21,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 12:31:21,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 12:31:21,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 12:31:23,417:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-30 12:34:29,490:INFO:PyCaret ClassificationExperiment
2023-03-30 12:34:29,490:INFO:Logging name: clf-default-name
2023-03-30 12:34:29,490:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-30 12:34:29,490:INFO:version 3.0.0
2023-03-30 12:34:29,490:INFO:Initializing setup()
2023-03-30 12:34:29,490:INFO:self.USI: 4761
2023-03-30 12:34:29,490:INFO:self._variable_keys: {'X', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'memory', 'y', '_available_plots', 'X_test', 'y_test', 'y_train', 'exp_name_log', 'is_multiclass', 'gpu_param', 'target_param', 'logging_param', 'idx', 'gpu_n_jobs_param', 'USI', '_ml_usecase', 'data', 'seed', 'html_param', 'log_plots_param', 'fold_shuffle_param', 'pipeline', 'X_train', 'exp_id', 'fix_imbalance'}
2023-03-30 12:34:29,490:INFO:Checking environment
2023-03-30 12:34:29,490:INFO:python_version: 3.9.12
2023-03-30 12:34:29,490:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-03-30 12:34:29,490:INFO:machine: AMD64
2023-03-30 12:34:29,490:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-30 12:34:29,490:INFO:Memory: svmem(total=8316030976, available=662175744, percent=92.0, used=7653855232, free=662175744)
2023-03-30 12:34:29,490:INFO:Physical Core: 4
2023-03-30 12:34:29,490:INFO:Logical Core: 8
2023-03-30 12:34:29,490:INFO:Checking libraries
2023-03-30 12:34:29,490:INFO:System:
2023-03-30 12:34:29,490:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-03-30 12:34:29,490:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-03-30 12:34:29,490:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-30 12:34:29,490:INFO:PyCaret required dependencies:
2023-03-30 12:34:29,490:INFO:                 pip: 21.2.4
2023-03-30 12:34:29,490:INFO:          setuptools: 61.2.0
2023-03-30 12:34:29,490:INFO:             pycaret: 3.0.0
2023-03-30 12:34:29,490:INFO:             IPython: 8.2.0
2023-03-30 12:34:29,490:INFO:          ipywidgets: 7.6.5
2023-03-30 12:34:29,490:INFO:                tqdm: 4.64.0
2023-03-30 12:34:29,490:INFO:               numpy: 1.22.4
2023-03-30 12:34:29,490:INFO:              pandas: 1.4.2
2023-03-30 12:34:29,490:INFO:              jinja2: 2.11.3
2023-03-30 12:34:29,490:INFO:               scipy: 1.7.3
2023-03-30 12:34:29,490:INFO:              joblib: 1.2.0
2023-03-30 12:34:29,490:INFO:             sklearn: 1.0.2
2023-03-30 12:34:29,490:INFO:                pyod: 1.0.9
2023-03-30 12:34:29,490:INFO:            imblearn: 0.10.1
2023-03-30 12:34:29,490:INFO:   category_encoders: 2.6.0
2023-03-30 12:34:29,490:INFO:            lightgbm: 3.3.5
2023-03-30 12:34:29,490:INFO:               numba: 0.55.1
2023-03-30 12:34:29,490:INFO:            requests: 2.27.1
2023-03-30 12:34:29,490:INFO:          matplotlib: 3.5.1
2023-03-30 12:34:29,490:INFO:          scikitplot: 0.3.7
2023-03-30 12:34:29,490:INFO:         yellowbrick: 1.5
2023-03-30 12:34:29,490:INFO:              plotly: 5.6.0
2023-03-30 12:34:29,490:INFO:             kaleido: 0.2.1
2023-03-30 12:34:29,490:INFO:         statsmodels: 0.13.2
2023-03-30 12:34:29,490:INFO:              sktime: 0.16.1
2023-03-30 12:34:29,490:INFO:               tbats: 1.1.2
2023-03-30 12:34:29,490:INFO:            pmdarima: 2.0.3
2023-03-30 12:34:29,490:INFO:              psutil: 5.9.4
2023-03-30 12:34:29,490:INFO:PyCaret optional dependencies:
2023-03-30 12:34:29,522:INFO:                shap: Not installed
2023-03-30 12:34:29,522:INFO:           interpret: Not installed
2023-03-30 12:34:29,522:INFO:                umap: Not installed
2023-03-30 12:34:29,522:INFO:    pandas_profiling: Not installed
2023-03-30 12:34:29,522:INFO:  explainerdashboard: Not installed
2023-03-30 12:34:29,522:INFO:             autoviz: Not installed
2023-03-30 12:34:29,522:INFO:           fairlearn: Not installed
2023-03-30 12:34:29,522:INFO:             xgboost: Not installed
2023-03-30 12:34:29,522:INFO:            catboost: Not installed
2023-03-30 12:34:29,522:INFO:              kmodes: Not installed
2023-03-30 12:34:29,522:INFO:             mlxtend: Not installed
2023-03-30 12:34:29,522:INFO:       statsforecast: Not installed
2023-03-30 12:34:29,522:INFO:        tune_sklearn: Not installed
2023-03-30 12:34:29,522:INFO:                 ray: Not installed
2023-03-30 12:34:29,522:INFO:            hyperopt: Not installed
2023-03-30 12:34:29,522:INFO:              optuna: Not installed
2023-03-30 12:34:29,522:INFO:               skopt: Not installed
2023-03-30 12:34:29,522:INFO:              mlflow: Not installed
2023-03-30 12:34:29,522:INFO:              gradio: Not installed
2023-03-30 12:34:29,522:INFO:             fastapi: Not installed
2023-03-30 12:34:29,522:INFO:             uvicorn: Not installed
2023-03-30 12:34:29,522:INFO:              m2cgen: Not installed
2023-03-30 12:34:29,522:INFO:           evidently: Not installed
2023-03-30 12:34:29,522:INFO:               fugue: Not installed
2023-03-30 12:34:29,522:INFO:           streamlit: Not installed
2023-03-30 12:34:29,522:INFO:             prophet: Not installed
2023-03-30 12:34:29,522:INFO:None
2023-03-30 12:34:29,522:INFO:Set up data.
2023-03-30 12:34:29,631:INFO:Set up train/test split.
2023-03-30 12:34:29,788:INFO:Set up index.
2023-03-30 12:34:29,793:INFO:Set up folding strategy.
2023-03-30 12:34:29,794:INFO:Assigning column types.
2023-03-30 12:34:29,882:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-30 12:34:30,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-30 12:34:30,007:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 12:34:30,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-30 12:34:30,291:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 12:34:30,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,369:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-30 12:34:30,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 12:34:30,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,558:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,653:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 12:34:30,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,731:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-30 12:34:30,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:30,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:31,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:31,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:33,078:INFO:Preparing preprocessing pipeline...
2023-03-30 12:34:33,094:INFO:Set up simple imputation.
2023-03-30 12:34:33,363:INFO:Finished creating preprocessing pipeline.
2023-03-30 12:34:33,378:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CODE_GENDER', 'FLAG_OWN_CAR',
                                             'FLAG_OWN_REALTY', 'CNT_CHILDREN',
                                             'AMT_INCOME_TOTAL',
                                             'NAME_INCOME_TYPE',
                                             'NAME_EDUCATION_TYPE',
                                             'NAME_FAMILY_STATUS',
                                             'NAME_HOUSING_TYPE', 'DAYS_BIRTH',
                                             'DAYS_EMPLOYED', 'FLAG_MOBIL...
                                             'CNT_FAM_MEMBERS',
                                             'MONTHS_BALANCE'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-03-30 12:34:33,378:INFO:Creating final display dataframe.
2023-03-30 12:34:34,100:INFO:Setup _display_container:                     Description             Value
0                    Session id              5753
1                        Target            STATUS
2                   Target type            Binary
3           Original data shape      (148486, 19)
4        Transformed data shape      (148486, 19)
5   Transformed train set shape      (103940, 19)
6    Transformed test set shape       (44546, 19)
7              Numeric features                18
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4761
2023-03-30 12:34:34,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:34,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:34,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:34,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 12:34:34,526:INFO:setup() successfully completed in 5.19s...............
2023-03-30 12:34:52,242:INFO:Initializing compare_models()
2023-03-30 12:34:52,242:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-30 12:34:52,242:INFO:Checking exceptions
2023-03-30 12:34:52,319:INFO:Preparing display monitor
2023-03-30 12:34:52,399:INFO:Initializing Logistic Regression
2023-03-30 12:34:52,399:INFO:Total runtime is 0.0 minutes
2023-03-30 12:34:52,401:INFO:SubProcess create_model() called ==================================
2023-03-30 12:34:52,401:INFO:Initializing create_model()
2023-03-30 12:34:52,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:34:52,401:INFO:Checking exceptions
2023-03-30 12:34:52,401:INFO:Importing libraries
2023-03-30 12:34:52,401:INFO:Copying training dataset
2023-03-30 12:34:52,529:INFO:Defining folds
2023-03-30 12:34:52,529:INFO:Declaring metric variables
2023-03-30 12:34:52,539:INFO:Importing untrained model
2023-03-30 12:34:52,539:INFO:Logistic Regression Imported successfully
2023-03-30 12:34:52,556:INFO:Starting cross validation
2023-03-30 12:34:52,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:35:01,749:INFO:Calculating mean and std
2023-03-30 12:35:01,751:INFO:Creating metrics dataframe
2023-03-30 12:35:01,851:INFO:Uploading results into container
2023-03-30 12:35:01,855:INFO:Uploading model into container now
2023-03-30 12:35:01,856:INFO:_master_model_container: 1
2023-03-30 12:35:01,856:INFO:_display_container: 2
2023-03-30 12:35:01,856:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5753, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-30 12:35:01,859:INFO:create_model() successfully completed......................................
2023-03-30 12:35:02,069:INFO:SubProcess create_model() end ==================================
2023-03-30 12:35:02,069:INFO:Creating metrics dataframe
2023-03-30 12:35:02,089:INFO:Initializing K Neighbors Classifier
2023-03-30 12:35:02,089:INFO:Total runtime is 0.16150747537612914 minutes
2023-03-30 12:35:02,099:INFO:SubProcess create_model() called ==================================
2023-03-30 12:35:02,099:INFO:Initializing create_model()
2023-03-30 12:35:02,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:35:02,100:INFO:Checking exceptions
2023-03-30 12:35:02,100:INFO:Importing libraries
2023-03-30 12:35:02,100:INFO:Copying training dataset
2023-03-30 12:35:02,209:INFO:Defining folds
2023-03-30 12:35:02,209:INFO:Declaring metric variables
2023-03-30 12:35:02,213:INFO:Importing untrained model
2023-03-30 12:35:02,218:INFO:K Neighbors Classifier Imported successfully
2023-03-30 12:35:02,239:INFO:Starting cross validation
2023-03-30 12:35:02,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:35:07,632:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:35:09,613:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:35:09,661:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:35:59,558:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 12:35:59,607:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 12:35:59,962:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 12:36:01,536:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 12:36:10,027:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-30 12:36:37,989:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2023-03-30 12:36:38,544:WARNING:Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "C:\Users\jaeek\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "C:\Users\jaeek\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.


2023-03-30 12:36:38,592:INFO:Initializing create_model()
2023-03-30 12:36:38,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:36:38,592:INFO:Checking exceptions
2023-03-30 12:36:38,592:INFO:Importing libraries
2023-03-30 12:36:38,592:INFO:Copying training dataset
2023-03-30 12:36:38,985:INFO:Defining folds
2023-03-30 12:36:38,985:INFO:Declaring metric variables
2023-03-30 12:36:39,048:INFO:Importing untrained model
2023-03-30 12:36:39,064:INFO:K Neighbors Classifier Imported successfully
2023-03-30 12:36:39,080:INFO:Starting cross validation
2023-03-30 12:36:39,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:38:10,677:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 12:38:11,098:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 12:40:17,225:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 12:40:17,265:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 12:40:17,271:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 12:40:23,579:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\extmath.py", line 153, in safe_sparse_dot
    ret = a @ b
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 12:48:25,813:INFO:Calculating mean and std
2023-03-30 12:48:25,922:INFO:Creating metrics dataframe
2023-03-30 12:48:26,112:INFO:Uploading results into container
2023-03-30 12:48:26,117:INFO:Uploading model into container now
2023-03-30 12:48:26,126:INFO:_master_model_container: 2
2023-03-30 12:48:26,126:INFO:_display_container: 2
2023-03-30 12:48:26,142:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-30 12:48:26,142:INFO:create_model() successfully completed......................................
2023-03-30 12:48:27,057:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2023-03-30 12:48:27,072:ERROR:Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 267, in cross_validate
    results = parallel(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1098, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "C:\Users\jaeek\anaconda3\lib\concurrent\futures\_base.py", line 446, in result
    return self.__get_result()
  File "C:\Users\jaeek\anaconda3\lib\concurrent\futures\_base.py", line 391, in __get_result
    raise self._exception
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 812, in compare_models
    assert (
AssertionError

2023-03-30 12:48:27,072:INFO:Initializing Naive Bayes
2023-03-30 12:48:27,072:INFO:Total runtime is 13.577897469202679 minutes
2023-03-30 12:48:27,072:INFO:SubProcess create_model() called ==================================
2023-03-30 12:48:27,072:INFO:Initializing create_model()
2023-03-30 12:48:27,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:48:27,072:INFO:Checking exceptions
2023-03-30 12:48:27,072:INFO:Importing libraries
2023-03-30 12:48:27,072:INFO:Copying training dataset
2023-03-30 12:48:27,167:INFO:Defining folds
2023-03-30 12:48:27,167:INFO:Declaring metric variables
2023-03-30 12:48:27,169:INFO:Importing untrained model
2023-03-30 12:48:27,169:INFO:Naive Bayes Imported successfully
2023-03-30 12:48:27,169:INFO:Starting cross validation
2023-03-30 12:48:27,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:48:28,910:INFO:Calculating mean and std
2023-03-30 12:48:28,910:INFO:Creating metrics dataframe
2023-03-30 12:48:29,005:INFO:Uploading results into container
2023-03-30 12:48:29,005:INFO:Uploading model into container now
2023-03-30 12:48:29,005:INFO:_master_model_container: 3
2023-03-30 12:48:29,005:INFO:_display_container: 2
2023-03-30 12:48:29,005:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-30 12:48:29,005:INFO:create_model() successfully completed......................................
2023-03-30 12:48:29,258:INFO:SubProcess create_model() end ==================================
2023-03-30 12:48:29,258:INFO:Creating metrics dataframe
2023-03-30 12:48:29,274:INFO:Initializing Decision Tree Classifier
2023-03-30 12:48:29,274:INFO:Total runtime is 13.614585185050965 minutes
2023-03-30 12:48:29,289:INFO:SubProcess create_model() called ==================================
2023-03-30 12:48:29,289:INFO:Initializing create_model()
2023-03-30 12:48:29,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:48:29,289:INFO:Checking exceptions
2023-03-30 12:48:29,289:INFO:Importing libraries
2023-03-30 12:48:29,289:INFO:Copying training dataset
2023-03-30 12:48:29,385:INFO:Defining folds
2023-03-30 12:48:29,385:INFO:Declaring metric variables
2023-03-30 12:48:29,401:INFO:Importing untrained model
2023-03-30 12:48:29,401:INFO:Decision Tree Classifier Imported successfully
2023-03-30 12:48:29,416:INFO:Starting cross validation
2023-03-30 12:48:29,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:48:36,939:INFO:Calculating mean and std
2023-03-30 12:48:36,939:INFO:Creating metrics dataframe
2023-03-30 12:48:37,002:INFO:Uploading results into container
2023-03-30 12:48:37,002:INFO:Uploading model into container now
2023-03-30 12:48:37,002:INFO:_master_model_container: 4
2023-03-30 12:48:37,002:INFO:_display_container: 2
2023-03-30 12:48:37,002:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5753, splitter='best')
2023-03-30 12:48:37,002:INFO:create_model() successfully completed......................................
2023-03-30 12:48:37,116:INFO:SubProcess create_model() end ==================================
2023-03-30 12:48:37,116:INFO:Creating metrics dataframe
2023-03-30 12:48:37,116:INFO:Initializing SVM - Linear Kernel
2023-03-30 12:48:37,116:INFO:Total runtime is 13.745294257005057 minutes
2023-03-30 12:48:37,129:INFO:SubProcess create_model() called ==================================
2023-03-30 12:48:37,129:INFO:Initializing create_model()
2023-03-30 12:48:37,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:48:37,129:INFO:Checking exceptions
2023-03-30 12:48:37,129:INFO:Importing libraries
2023-03-30 12:48:37,129:INFO:Copying training dataset
2023-03-30 12:48:37,176:INFO:Defining folds
2023-03-30 12:48:37,176:INFO:Declaring metric variables
2023-03-30 12:48:37,176:INFO:Importing untrained model
2023-03-30 12:48:37,176:INFO:SVM - Linear Kernel Imported successfully
2023-03-30 12:48:37,192:INFO:Starting cross validation
2023-03-30 12:48:37,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:48:50,844:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,844:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,860:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,860:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:48:50,860:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,860:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,860:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,860:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:50,876:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:56,338:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:56,338:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:48:57,780:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 12:48:57,907:INFO:Calculating mean and std
2023-03-30 12:48:57,907:INFO:Creating metrics dataframe
2023-03-30 12:48:57,971:INFO:Uploading results into container
2023-03-30 12:48:57,971:INFO:Uploading model into container now
2023-03-30 12:48:57,971:INFO:_master_model_container: 5
2023-03-30 12:48:57,971:INFO:_display_container: 2
2023-03-30 12:48:57,971:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5753, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-30 12:48:57,971:INFO:create_model() successfully completed......................................
2023-03-30 12:48:58,098:INFO:SubProcess create_model() end ==================================
2023-03-30 12:48:58,098:INFO:Creating metrics dataframe
2023-03-30 12:48:58,114:INFO:Initializing Ridge Classifier
2023-03-30 12:48:58,114:INFO:Total runtime is 14.095263727506003 minutes
2023-03-30 12:48:58,114:INFO:SubProcess create_model() called ==================================
2023-03-30 12:48:58,114:INFO:Initializing create_model()
2023-03-30 12:48:58,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:48:58,114:INFO:Checking exceptions
2023-03-30 12:48:58,114:INFO:Importing libraries
2023-03-30 12:48:58,114:INFO:Copying training dataset
2023-03-30 12:48:58,161:INFO:Defining folds
2023-03-30 12:48:58,161:INFO:Declaring metric variables
2023-03-30 12:48:58,177:INFO:Importing untrained model
2023-03-30 12:48:58,177:INFO:Ridge Classifier Imported successfully
2023-03-30 12:48:58,188:INFO:Starting cross validation
2023-03-30 12:48:58,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:48:58,523:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,586:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,586:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,633:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,648:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,696:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,711:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,711:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,900:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:58,931:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 12:48:59,404:INFO:Calculating mean and std
2023-03-30 12:48:59,404:INFO:Creating metrics dataframe
2023-03-30 12:48:59,468:INFO:Uploading results into container
2023-03-30 12:48:59,468:INFO:Uploading model into container now
2023-03-30 12:48:59,468:INFO:_master_model_container: 6
2023-03-30 12:48:59,468:INFO:_display_container: 2
2023-03-30 12:48:59,468:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=5753, solver='auto', tol=0.001)
2023-03-30 12:48:59,468:INFO:create_model() successfully completed......................................
2023-03-30 12:48:59,562:INFO:SubProcess create_model() end ==================================
2023-03-30 12:48:59,577:INFO:Creating metrics dataframe
2023-03-30 12:48:59,577:INFO:Initializing Random Forest Classifier
2023-03-30 12:48:59,577:INFO:Total runtime is 14.119648079077404 minutes
2023-03-30 12:48:59,577:INFO:SubProcess create_model() called ==================================
2023-03-30 12:48:59,593:INFO:Initializing create_model()
2023-03-30 12:48:59,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:48:59,593:INFO:Checking exceptions
2023-03-30 12:48:59,593:INFO:Importing libraries
2023-03-30 12:48:59,593:INFO:Copying training dataset
2023-03-30 12:48:59,640:INFO:Defining folds
2023-03-30 12:48:59,640:INFO:Declaring metric variables
2023-03-30 12:48:59,640:INFO:Importing untrained model
2023-03-30 12:48:59,640:INFO:Random Forest Classifier Imported successfully
2023-03-30 12:48:59,657:INFO:Starting cross validation
2023-03-30 12:48:59,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:49:26,624:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:49:33,785:INFO:Calculating mean and std
2023-03-30 12:49:33,785:INFO:Creating metrics dataframe
2023-03-30 12:49:33,848:INFO:Uploading results into container
2023-03-30 12:49:33,848:INFO:Uploading model into container now
2023-03-30 12:49:33,848:INFO:_master_model_container: 7
2023-03-30 12:49:33,848:INFO:_display_container: 2
2023-03-30 12:49:33,848:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False)
2023-03-30 12:49:33,848:INFO:create_model() successfully completed......................................
2023-03-30 12:49:33,958:INFO:SubProcess create_model() end ==================================
2023-03-30 12:49:33,958:INFO:Creating metrics dataframe
2023-03-30 12:49:33,989:INFO:Initializing Quadratic Discriminant Analysis
2023-03-30 12:49:33,989:INFO:Total runtime is 14.693180986245475 minutes
2023-03-30 12:49:33,989:INFO:SubProcess create_model() called ==================================
2023-03-30 12:49:33,989:INFO:Initializing create_model()
2023-03-30 12:49:33,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:49:33,989:INFO:Checking exceptions
2023-03-30 12:49:33,989:INFO:Importing libraries
2023-03-30 12:49:33,989:INFO:Copying training dataset
2023-03-30 12:49:34,052:INFO:Defining folds
2023-03-30 12:49:34,052:INFO:Declaring metric variables
2023-03-30 12:49:34,052:INFO:Importing untrained model
2023-03-30 12:49:34,052:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-30 12:49:34,068:INFO:Starting cross validation
2023-03-30 12:49:34,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:49:34,447:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:34,463:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:34,463:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:34,573:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:34,604:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:34,666:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:34,666:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:35,169:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:35,216:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 12:49:35,816:INFO:Calculating mean and std
2023-03-30 12:49:35,818:INFO:Creating metrics dataframe
2023-03-30 12:49:35,880:INFO:Uploading results into container
2023-03-30 12:49:35,880:INFO:Uploading model into container now
2023-03-30 12:49:35,880:INFO:_master_model_container: 8
2023-03-30 12:49:35,880:INFO:_display_container: 2
2023-03-30 12:49:35,880:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-30 12:49:35,880:INFO:create_model() successfully completed......................................
2023-03-30 12:49:35,975:INFO:SubProcess create_model() end ==================================
2023-03-30 12:49:35,975:INFO:Creating metrics dataframe
2023-03-30 12:49:35,990:INFO:Initializing Ada Boost Classifier
2023-03-30 12:49:35,990:INFO:Total runtime is 14.726529661814373 minutes
2023-03-30 12:49:35,990:INFO:SubProcess create_model() called ==================================
2023-03-30 12:49:35,990:INFO:Initializing create_model()
2023-03-30 12:49:35,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:49:35,990:INFO:Checking exceptions
2023-03-30 12:49:35,990:INFO:Importing libraries
2023-03-30 12:49:35,990:INFO:Copying training dataset
2023-03-30 12:49:36,038:INFO:Defining folds
2023-03-30 12:49:36,038:INFO:Declaring metric variables
2023-03-30 12:49:36,038:INFO:Importing untrained model
2023-03-30 12:49:36,054:INFO:Ada Boost Classifier Imported successfully
2023-03-30 12:49:36,059:INFO:Starting cross validation
2023-03-30 12:49:36,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:49:46,970:INFO:Calculating mean and std
2023-03-30 12:49:46,970:INFO:Creating metrics dataframe
2023-03-30 12:49:47,033:INFO:Uploading results into container
2023-03-30 12:49:47,033:INFO:Uploading model into container now
2023-03-30 12:49:47,033:INFO:_master_model_container: 9
2023-03-30 12:49:47,033:INFO:_display_container: 2
2023-03-30 12:49:47,033:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5753)
2023-03-30 12:49:47,033:INFO:create_model() successfully completed......................................
2023-03-30 12:49:47,144:INFO:SubProcess create_model() end ==================================
2023-03-30 12:49:47,144:INFO:Creating metrics dataframe
2023-03-30 12:49:47,144:INFO:Initializing Gradient Boosting Classifier
2023-03-30 12:49:47,144:INFO:Total runtime is 14.912422597408296 minutes
2023-03-30 12:49:47,160:INFO:SubProcess create_model() called ==================================
2023-03-30 12:49:47,160:INFO:Initializing create_model()
2023-03-30 12:49:47,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:49:47,160:INFO:Checking exceptions
2023-03-30 12:49:47,160:INFO:Importing libraries
2023-03-30 12:49:47,160:INFO:Copying training dataset
2023-03-30 12:49:47,191:INFO:Defining folds
2023-03-30 12:49:47,191:INFO:Declaring metric variables
2023-03-30 12:49:47,207:INFO:Importing untrained model
2023-03-30 12:49:47,207:INFO:Gradient Boosting Classifier Imported successfully
2023-03-30 12:49:47,223:INFO:Starting cross validation
2023-03-30 12:49:47,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:50:20,771:INFO:Calculating mean and std
2023-03-30 12:50:20,771:INFO:Creating metrics dataframe
2023-03-30 12:50:20,850:INFO:Uploading results into container
2023-03-30 12:50:20,850:INFO:Uploading model into container now
2023-03-30 12:50:20,850:INFO:_master_model_container: 10
2023-03-30 12:50:20,850:INFO:_display_container: 2
2023-03-30 12:50:20,850:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5753, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-30 12:50:20,850:INFO:create_model() successfully completed......................................
2023-03-30 12:50:20,960:INFO:SubProcess create_model() end ==================================
2023-03-30 12:50:20,960:INFO:Creating metrics dataframe
2023-03-30 12:50:20,960:INFO:Initializing Linear Discriminant Analysis
2023-03-30 12:50:20,960:INFO:Total runtime is 15.47602284749349 minutes
2023-03-30 12:50:20,960:INFO:SubProcess create_model() called ==================================
2023-03-30 12:50:20,960:INFO:Initializing create_model()
2023-03-30 12:50:20,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:50:20,960:INFO:Checking exceptions
2023-03-30 12:50:20,960:INFO:Importing libraries
2023-03-30 12:50:20,960:INFO:Copying training dataset
2023-03-30 12:50:21,008:INFO:Defining folds
2023-03-30 12:50:21,008:INFO:Declaring metric variables
2023-03-30 12:50:21,008:INFO:Importing untrained model
2023-03-30 12:50:21,023:INFO:Linear Discriminant Analysis Imported successfully
2023-03-30 12:50:21,023:INFO:Starting cross validation
2023-03-30 12:50:21,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:50:23,176:INFO:Calculating mean and std
2023-03-30 12:50:23,176:INFO:Creating metrics dataframe
2023-03-30 12:50:23,238:INFO:Uploading results into container
2023-03-30 12:50:23,254:INFO:Uploading model into container now
2023-03-30 12:50:23,254:INFO:_master_model_container: 11
2023-03-30 12:50:23,254:INFO:_display_container: 2
2023-03-30 12:50:23,254:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-30 12:50:23,254:INFO:create_model() successfully completed......................................
2023-03-30 12:50:23,348:INFO:SubProcess create_model() end ==================================
2023-03-30 12:50:23,348:INFO:Creating metrics dataframe
2023-03-30 12:50:23,348:INFO:Initializing Extra Trees Classifier
2023-03-30 12:50:23,348:INFO:Total runtime is 15.515816060702008 minutes
2023-03-30 12:50:23,348:INFO:SubProcess create_model() called ==================================
2023-03-30 12:50:23,348:INFO:Initializing create_model()
2023-03-30 12:50:23,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:50:23,348:INFO:Checking exceptions
2023-03-30 12:50:23,348:INFO:Importing libraries
2023-03-30 12:50:23,348:INFO:Copying training dataset
2023-03-30 12:50:23,411:INFO:Defining folds
2023-03-30 12:50:23,411:INFO:Declaring metric variables
2023-03-30 12:50:23,411:INFO:Importing untrained model
2023-03-30 12:50:23,411:INFO:Extra Trees Classifier Imported successfully
2023-03-30 12:50:23,411:INFO:Starting cross validation
2023-03-30 12:50:23,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:50:46,749:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:50:46,813:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:50:46,985:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:50:47,001:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:50:47,615:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:50:48,164:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:50:48,371:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:50:48,650:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:50:49,167:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:50:55,894:INFO:Calculating mean and std
2023-03-30 12:50:55,929:INFO:Creating metrics dataframe
2023-03-30 12:50:56,115:INFO:Uploading results into container
2023-03-30 12:50:56,131:INFO:Uploading model into container now
2023-03-30 12:50:56,131:INFO:_master_model_container: 12
2023-03-30 12:50:56,131:INFO:_display_container: 2
2023-03-30 12:50:56,131:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5753, verbose=0, warm_start=False)
2023-03-30 12:50:56,131:INFO:create_model() successfully completed......................................
2023-03-30 12:50:56,572:INFO:SubProcess create_model() end ==================================
2023-03-30 12:50:56,572:INFO:Creating metrics dataframe
2023-03-30 12:50:56,588:INFO:Initializing Light Gradient Boosting Machine
2023-03-30 12:50:56,588:INFO:Total runtime is 16.069826261202497 minutes
2023-03-30 12:50:56,588:INFO:SubProcess create_model() called ==================================
2023-03-30 12:50:56,588:INFO:Initializing create_model()
2023-03-30 12:50:56,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:50:56,588:INFO:Checking exceptions
2023-03-30 12:50:56,588:INFO:Importing libraries
2023-03-30 12:50:56,588:INFO:Copying training dataset
2023-03-30 12:50:56,667:INFO:Defining folds
2023-03-30 12:50:56,667:INFO:Declaring metric variables
2023-03-30 12:50:56,667:INFO:Importing untrained model
2023-03-30 12:50:56,667:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-30 12:50:56,683:INFO:Starting cross validation
2023-03-30 12:50:56,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:51:02,463:INFO:Calculating mean and std
2023-03-30 12:51:02,463:INFO:Creating metrics dataframe
2023-03-30 12:51:02,557:INFO:Uploading results into container
2023-03-30 12:51:02,557:INFO:Uploading model into container now
2023-03-30 12:51:02,557:INFO:_master_model_container: 13
2023-03-30 12:51:02,557:INFO:_display_container: 2
2023-03-30 12:51:02,557:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5753, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-30 12:51:02,557:INFO:create_model() successfully completed......................................
2023-03-30 12:51:02,666:INFO:SubProcess create_model() end ==================================
2023-03-30 12:51:02,666:INFO:Creating metrics dataframe
2023-03-30 12:51:02,682:INFO:Initializing Dummy Classifier
2023-03-30 12:51:02,682:INFO:Total runtime is 16.171392838160198 minutes
2023-03-30 12:51:02,682:INFO:SubProcess create_model() called ==================================
2023-03-30 12:51:02,682:INFO:Initializing create_model()
2023-03-30 12:51:02,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B614884FD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:51:02,682:INFO:Checking exceptions
2023-03-30 12:51:02,682:INFO:Importing libraries
2023-03-30 12:51:02,682:INFO:Copying training dataset
2023-03-30 12:51:02,745:INFO:Defining folds
2023-03-30 12:51:02,745:INFO:Declaring metric variables
2023-03-30 12:51:02,745:INFO:Importing untrained model
2023-03-30 12:51:02,745:INFO:Dummy Classifier Imported successfully
2023-03-30 12:51:02,761:INFO:Starting cross validation
2023-03-30 12:51:02,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:51:03,029:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,076:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,145:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,202:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,218:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,248:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,249:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,342:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,469:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:03,501:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 12:51:04,034:INFO:Calculating mean and std
2023-03-30 12:51:04,034:INFO:Creating metrics dataframe
2023-03-30 12:51:04,158:INFO:Uploading results into container
2023-03-30 12:51:04,158:INFO:Uploading model into container now
2023-03-30 12:51:04,158:INFO:_master_model_container: 14
2023-03-30 12:51:04,158:INFO:_display_container: 2
2023-03-30 12:51:04,158:INFO:DummyClassifier(constant=None, random_state=5753, strategy='prior')
2023-03-30 12:51:04,158:INFO:create_model() successfully completed......................................
2023-03-30 12:51:04,269:INFO:SubProcess create_model() end ==================================
2023-03-30 12:51:04,269:INFO:Creating metrics dataframe
2023-03-30 12:51:04,284:INFO:Initializing create_model()
2023-03-30 12:51:04,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:51:04,284:INFO:Checking exceptions
2023-03-30 12:51:04,300:INFO:Importing libraries
2023-03-30 12:51:04,300:INFO:Copying training dataset
2023-03-30 12:51:04,347:INFO:Defining folds
2023-03-30 12:51:04,347:INFO:Declaring metric variables
2023-03-30 12:51:04,347:INFO:Importing untrained model
2023-03-30 12:51:04,347:INFO:Declaring custom model
2023-03-30 12:51:04,347:INFO:Random Forest Classifier Imported successfully
2023-03-30 12:51:04,347:INFO:Cross validation set to False
2023-03-30 12:51:04,347:INFO:Fitting Model
2023-03-30 12:51:07,906:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False)
2023-03-30 12:51:07,906:INFO:create_model() successfully completed......................................
2023-03-30 12:51:08,049:INFO:_master_model_container: 14
2023-03-30 12:51:08,049:INFO:_display_container: 2
2023-03-30 12:51:08,049:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False)
2023-03-30 12:51:08,049:INFO:compare_models() successfully completed......................................
2023-03-30 12:54:43,758:INFO:Initializing tune_model()
2023-03-30 12:54:43,758:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>)
2023-03-30 12:54:43,758:INFO:Checking exceptions
2023-03-30 12:54:43,808:INFO:Copying training dataset
2023-03-30 12:54:43,838:INFO:Checking base model
2023-03-30 12:54:43,853:INFO:Base model : Random Forest Classifier
2023-03-30 12:54:43,853:INFO:Declaring metric variables
2023-03-30 12:54:43,853:INFO:Defining Hyperparameters
2023-03-30 12:54:43,963:INFO:Tuning with n_jobs=-1
2023-03-30 12:54:43,963:INFO:Initializing RandomizedSearchCV
2023-03-30 12:55:04,774:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:05,854:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:06,403:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:06,654:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:09,429:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:55:19,117:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:19,759:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:22,017:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:22,550:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:28,319:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:29,198:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:29,245:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:55:29,965:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:00,585:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:03,026:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:03,120:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:03,573:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:04,935:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:05,790:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:06,187:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:07,458:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:08,821:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:09,354:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:09,996:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:10,732:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:12,032:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:12,282:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:12,704:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:12,939:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:13,095:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:13,127:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:13,581:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:14,583:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:20,071:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:20,572:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:21,392:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:21,761:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:22,105:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:22,309:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:23,061:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:23,249:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:23,437:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:24,473:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:28,183:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:28,284:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:29,165:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:29,212:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:30,423:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:35,500:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:35,610:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:37,114:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:39,748:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:39,779:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:41,158:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:41,284:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:41,299:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:41,346:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:48,487:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:49,115:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:54,396:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:56,423:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:56,517:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:58,927:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:56:58,989:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:56:59,552:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:01,199:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:01,277:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:01,392:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:03,110:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:05,257:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:05,587:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:07,248:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:07,545:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:08,140:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:09,299:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:09,910:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:10,224:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:10,476:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:11,262:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:12,140:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:12,171:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:12,312:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:14,062:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:15,196:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:16,298:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:16,660:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:17,122:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:18,343:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:19,314:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:21,022:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:21,101:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:21,336:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:22,575:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:23,546:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:24,891:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:27,379:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:27,645:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:29,086:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:29,727:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:29,946:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 12:57:31,599:INFO:best_params: {'actual_estimator__n_estimators': 90, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-03-30 12:57:31,599:INFO:Hyperparameter search completed
2023-03-30 12:57:31,599:INFO:SubProcess create_model() called ==================================
2023-03-30 12:57:31,599:INFO:Initializing create_model()
2023-03-30 12:57:31,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B61347BE80>, model_only=True, return_train_score=False, kwargs={'n_estimators': 90, 'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-03-30 12:57:31,599:INFO:Checking exceptions
2023-03-30 12:57:31,599:INFO:Importing libraries
2023-03-30 12:57:31,599:INFO:Copying training dataset
2023-03-30 12:57:31,646:INFO:Defining folds
2023-03-30 12:57:31,646:INFO:Declaring metric variables
2023-03-30 12:57:31,646:INFO:Importing untrained model
2023-03-30 12:57:31,646:INFO:Declaring custom model
2023-03-30 12:57:31,646:INFO:Random Forest Classifier Imported successfully
2023-03-30 12:57:31,662:INFO:Starting cross validation
2023-03-30 12:57:31,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:57:34,277:INFO:Calculating mean and std
2023-03-30 12:57:34,277:INFO:Creating metrics dataframe
2023-03-30 12:57:34,277:INFO:Finalizing model
2023-03-30 12:57:36,900:INFO:Uploading results into container
2023-03-30 12:57:36,909:INFO:Uploading model into container now
2023-03-30 12:57:36,909:INFO:_master_model_container: 15
2023-03-30 12:57:36,909:INFO:_display_container: 3
2023-03-30 12:57:36,909:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=2, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=-1,
                       oob_score=False, random_state=5753, verbose=0,
                       warm_start=False)
2023-03-30 12:57:36,909:INFO:create_model() successfully completed......................................
2023-03-30 12:57:37,012:INFO:SubProcess create_model() end ==================================
2023-03-30 12:57:37,012:INFO:choose_better activated
2023-03-30 12:57:37,012:INFO:SubProcess create_model() called ==================================
2023-03-30 12:57:37,012:INFO:Initializing create_model()
2023-03-30 12:57:37,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-30 12:57:37,012:INFO:Checking exceptions
2023-03-30 12:57:37,027:INFO:Importing libraries
2023-03-30 12:57:37,027:INFO:Copying training dataset
2023-03-30 12:57:37,074:INFO:Defining folds
2023-03-30 12:57:37,074:INFO:Declaring metric variables
2023-03-30 12:57:37,074:INFO:Importing untrained model
2023-03-30 12:57:37,074:INFO:Declaring custom model
2023-03-30 12:57:37,074:INFO:Random Forest Classifier Imported successfully
2023-03-30 12:57:37,090:INFO:Starting cross validation
2023-03-30 12:57:37,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 12:57:40,440:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 12:57:42,824:INFO:Calculating mean and std
2023-03-30 12:57:42,824:INFO:Creating metrics dataframe
2023-03-30 12:57:42,824:INFO:Finalizing model
2023-03-30 12:57:43,345:INFO:Uploading results into container
2023-03-30 12:57:43,345:INFO:Uploading model into container now
2023-03-30 12:57:43,345:INFO:_master_model_container: 16
2023-03-30 12:57:43,345:INFO:_display_container: 4
2023-03-30 12:57:43,345:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False)
2023-03-30 12:57:43,345:INFO:create_model() successfully completed......................................
2023-03-30 12:57:43,471:INFO:SubProcess create_model() end ==================================
2023-03-30 12:57:43,471:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False) result for Accuracy is 0.8616
2023-03-30 12:57:43,471:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='entropy',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0,
                       min_samples_leaf=2, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=-1,
                       oob_score=False, random_state=5753, verbose=0,
                       warm_start=False) result for Accuracy is 0.7765
2023-03-30 12:57:43,471:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False) is best model
2023-03-30 12:57:43,471:INFO:choose_better completed
2023-03-30 12:57:43,471:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-03-30 12:57:43,488:INFO:_master_model_container: 16
2023-03-30 12:57:43,488:INFO:_display_container: 3
2023-03-30 12:57:43,488:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False)
2023-03-30 12:57:43,488:INFO:tune_model() successfully completed......................................
2023-03-30 12:57:56,961:INFO:Initializing plot_model()
2023-03-30 12:57:56,961:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5753, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B60F45A3A0>, system=True)
2023-03-30 12:57:56,961:INFO:Checking exceptions
2023-03-30 12:57:57,008:INFO:Preloading libraries
2023-03-30 12:57:57,150:INFO:Copying training dataset
2023-03-30 12:57:57,150:INFO:Plot type: confusion_matrix
2023-03-30 12:57:57,352:INFO:Fitting Model
2023-03-30 12:57:57,368:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-30 12:57:57,368:INFO:Scoring test/hold-out set
2023-03-30 12:57:57,858:INFO:Visual Rendered Successfully
2023-03-30 12:57:57,953:INFO:plot_model() successfully completed......................................
2023-03-30 13:41:11,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 13:41:11,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 13:41:11,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 13:41:11,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 13:41:12,135:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-30 13:41:12,435:INFO:PyCaret ClassificationExperiment
2023-03-30 13:41:12,435:INFO:Logging name: clf-default-name
2023-03-30 13:41:12,435:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-30 13:41:12,435:INFO:version 3.0.0
2023-03-30 13:41:12,435:INFO:Initializing setup()
2023-03-30 13:41:12,435:INFO:self.USI: 2c41
2023-03-30 13:41:12,435:INFO:self._variable_keys: {'X', 'fix_imbalance', 'X_test', 'log_plots_param', 'y_test', 'data', 'exp_id', 'USI', 'is_multiclass', 'memory', 'y_train', 'fold_shuffle_param', 'y', 'exp_name_log', 'seed', '_ml_usecase', 'pipeline', 'n_jobs_param', 'idx', 'target_param', 'fold_generator', 'X_train', 'gpu_param', 'gpu_n_jobs_param', 'fold_groups_param', 'logging_param', '_available_plots', 'html_param'}
2023-03-30 13:41:12,435:INFO:Checking environment
2023-03-30 13:41:12,435:INFO:python_version: 3.9.12
2023-03-30 13:41:12,435:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-03-30 13:41:12,435:INFO:machine: AMD64
2023-03-30 13:41:12,435:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-30 13:41:12,435:INFO:Memory: svmem(total=8316030976, available=1091993600, percent=86.9, used=7224037376, free=1091993600)
2023-03-30 13:41:12,435:INFO:Physical Core: 4
2023-03-30 13:41:12,435:INFO:Logical Core: 8
2023-03-30 13:41:12,435:INFO:Checking libraries
2023-03-30 13:41:12,435:INFO:System:
2023-03-30 13:41:12,435:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-03-30 13:41:12,435:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-03-30 13:41:12,435:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-30 13:41:12,435:INFO:PyCaret required dependencies:
2023-03-30 13:41:12,435:INFO:                 pip: 21.2.4
2023-03-30 13:41:12,435:INFO:          setuptools: 61.2.0
2023-03-30 13:41:12,435:INFO:             pycaret: 3.0.0
2023-03-30 13:41:12,435:INFO:             IPython: 8.2.0
2023-03-30 13:41:12,435:INFO:          ipywidgets: 7.6.5
2023-03-30 13:41:12,435:INFO:                tqdm: 4.64.0
2023-03-30 13:41:12,435:INFO:               numpy: 1.21.6
2023-03-30 13:41:12,435:INFO:              pandas: 1.4.2
2023-03-30 13:41:12,435:INFO:              jinja2: 2.11.3
2023-03-30 13:41:12,435:INFO:               scipy: 1.7.3
2023-03-30 13:41:12,435:INFO:              joblib: 1.2.0
2023-03-30 13:41:12,435:INFO:             sklearn: 1.0.2
2023-03-30 13:41:12,435:INFO:                pyod: 1.0.9
2023-03-30 13:41:12,435:INFO:            imblearn: 0.10.1
2023-03-30 13:41:12,435:INFO:   category_encoders: 2.6.0
2023-03-30 13:41:12,435:INFO:            lightgbm: 3.3.5
2023-03-30 13:41:12,435:INFO:               numba: 0.55.1
2023-03-30 13:41:12,435:INFO:            requests: 2.27.1
2023-03-30 13:41:12,435:INFO:          matplotlib: 3.5.1
2023-03-30 13:41:12,435:INFO:          scikitplot: 0.3.7
2023-03-30 13:41:12,435:INFO:         yellowbrick: 1.5
2023-03-30 13:41:12,435:INFO:              plotly: 5.6.0
2023-03-30 13:41:12,435:INFO:             kaleido: 0.2.1
2023-03-30 13:41:12,435:INFO:         statsmodels: 0.13.2
2023-03-30 13:41:12,435:INFO:              sktime: 0.16.1
2023-03-30 13:41:12,435:INFO:               tbats: 1.1.2
2023-03-30 13:41:12,435:INFO:            pmdarima: 2.0.3
2023-03-30 13:41:12,435:INFO:              psutil: 5.9.4
2023-03-30 13:41:12,435:INFO:PyCaret optional dependencies:
2023-03-30 13:41:12,451:INFO:                shap: 0.41.0
2023-03-30 13:41:12,451:INFO:           interpret: Not installed
2023-03-30 13:41:12,451:INFO:                umap: Not installed
2023-03-30 13:41:12,451:INFO:    pandas_profiling: 4.1.2
2023-03-30 13:41:12,451:INFO:  explainerdashboard: Not installed
2023-03-30 13:41:12,451:INFO:             autoviz: Not installed
2023-03-30 13:41:12,451:INFO:           fairlearn: Not installed
2023-03-30 13:41:12,451:INFO:             xgboost: Not installed
2023-03-30 13:41:12,451:INFO:            catboost: Not installed
2023-03-30 13:41:12,451:INFO:              kmodes: Not installed
2023-03-30 13:41:12,451:INFO:             mlxtend: Not installed
2023-03-30 13:41:12,451:INFO:       statsforecast: Not installed
2023-03-30 13:41:12,451:INFO:        tune_sklearn: Not installed
2023-03-30 13:41:12,451:INFO:                 ray: Not installed
2023-03-30 13:41:12,451:INFO:            hyperopt: Not installed
2023-03-30 13:41:12,451:INFO:              optuna: Not installed
2023-03-30 13:41:12,451:INFO:               skopt: Not installed
2023-03-30 13:41:12,451:INFO:              mlflow: Not installed
2023-03-30 13:41:12,451:INFO:              gradio: Not installed
2023-03-30 13:41:12,451:INFO:             fastapi: Not installed
2023-03-30 13:41:12,451:INFO:             uvicorn: Not installed
2023-03-30 13:41:12,451:INFO:              m2cgen: Not installed
2023-03-30 13:41:12,451:INFO:           evidently: Not installed
2023-03-30 13:41:12,451:INFO:               fugue: Not installed
2023-03-30 13:41:12,451:INFO:           streamlit: Not installed
2023-03-30 13:41:12,451:INFO:             prophet: Not installed
2023-03-30 13:41:12,451:INFO:None
2023-03-30 13:41:12,451:INFO:Set up data.
2023-03-30 13:41:12,482:INFO:Set up train/test split.
2023-03-30 13:41:12,529:INFO:Set up index.
2023-03-30 13:41:12,529:INFO:Set up folding strategy.
2023-03-30 13:41:12,529:INFO:Assigning column types.
2023-03-30 13:41:12,560:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-30 13:41:12,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-30 13:41:12,607:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 13:41:12,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,701:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-30 13:41:12,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 13:41:12,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,717:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-30 13:41:12,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 13:41:12,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 13:41:12,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,843:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-30 13:41:12,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:12,968:INFO:Preparing preprocessing pipeline...
2023-03-30 13:41:12,984:INFO:Set up simple imputation.
2023-03-30 13:41:13,063:INFO:Finished creating preprocessing pipeline.
2023-03-30 13:41:13,079:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CODE_GENDER', 'FLAG_OWN_CAR',
                                             'FLAG_OWN_REALTY', 'CNT_CHILDREN',
                                             'AMT_INCOME_TOTAL',
                                             'NAME_INCOME_TYPE',
                                             'NAME_EDUCATION_TYPE',
                                             'NAME_FAMILY_STATUS',
                                             'NAME_HOUSING_TYPE', 'DAYS_BIRTH',
                                             'DAYS_EMPLOYED', 'FLAG_MOBIL...
                                             'CNT_FAM_MEMBERS',
                                             'MONTHS_BALANCE'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-03-30 13:41:13,079:INFO:Creating final display dataframe.
2023-03-30 13:41:13,316:INFO:Setup _display_container:                     Description             Value
0                    Session id              1080
1                        Target            STATUS
2                   Target type            Binary
3           Original data shape      (148486, 19)
4        Transformed data shape      (148486, 19)
5   Transformed train set shape      (103940, 19)
6    Transformed test set shape       (44546, 19)
7              Numeric features                18
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              2c41
2023-03-30 13:41:13,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:13,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:13,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:13,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 13:41:13,457:INFO:setup() successfully completed in 1.23s...............
2023-03-30 13:41:13,473:INFO:Initializing compare_models()
2023-03-30 13:41:13,473:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-30 13:41:13,473:INFO:Checking exceptions
2023-03-30 13:41:13,489:INFO:Preparing display monitor
2023-03-30 13:41:13,536:INFO:Initializing Logistic Regression
2023-03-30 13:41:13,536:INFO:Total runtime is 0.0 minutes
2023-03-30 13:41:13,536:INFO:SubProcess create_model() called ==================================
2023-03-30 13:41:13,536:INFO:Initializing create_model()
2023-03-30 13:41:13,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:41:13,536:INFO:Checking exceptions
2023-03-30 13:41:13,536:INFO:Importing libraries
2023-03-30 13:41:13,536:INFO:Copying training dataset
2023-03-30 13:41:13,583:INFO:Defining folds
2023-03-30 13:41:13,583:INFO:Declaring metric variables
2023-03-30 13:41:13,583:INFO:Importing untrained model
2023-03-30 13:41:13,599:INFO:Logistic Regression Imported successfully
2023-03-30 13:41:13,599:INFO:Starting cross validation
2023-03-30 13:41:13,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:41:25,426:INFO:Calculating mean and std
2023-03-30 13:41:25,426:INFO:Creating metrics dataframe
2023-03-30 13:41:25,552:INFO:Uploading results into container
2023-03-30 13:41:25,552:INFO:Uploading model into container now
2023-03-30 13:41:25,552:INFO:_master_model_container: 1
2023-03-30 13:41:25,552:INFO:_display_container: 2
2023-03-30 13:41:25,552:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1080, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-30 13:41:25,552:INFO:create_model() successfully completed......................................
2023-03-30 13:41:25,725:INFO:SubProcess create_model() end ==================================
2023-03-30 13:41:25,725:INFO:Creating metrics dataframe
2023-03-30 13:41:25,725:INFO:Initializing K Neighbors Classifier
2023-03-30 13:41:25,725:INFO:Total runtime is 0.2031625270843506 minutes
2023-03-30 13:41:25,725:INFO:SubProcess create_model() called ==================================
2023-03-30 13:41:25,725:INFO:Initializing create_model()
2023-03-30 13:41:25,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:41:25,725:INFO:Checking exceptions
2023-03-30 13:41:25,725:INFO:Importing libraries
2023-03-30 13:41:25,725:INFO:Copying training dataset
2023-03-30 13:41:25,789:INFO:Defining folds
2023-03-30 13:41:25,789:INFO:Declaring metric variables
2023-03-30 13:41:25,789:INFO:Importing untrained model
2023-03-30 13:41:25,804:INFO:K Neighbors Classifier Imported successfully
2023-03-30 13:41:25,804:INFO:Starting cross validation
2023-03-30 13:41:25,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:41:27,807:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:41:38,832:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 2.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-30 13:41:49,706:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 9.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 13:42:27,234:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 19.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-03-30 13:42:35,950:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 4.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-03-30 13:42:51,781:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 15.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 13:43:31,051:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\extmath.py", line 153, in safe_sparse_dot
    ret = a @ b
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 13:43:50,024:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 13:44:20,444:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\extmath.py", line 153, in safe_sparse_dot
    ret = a @ b
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 13:44:26,695:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 22.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-30 13:46:01,964:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 13:46:03,989:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 13:53:39,314:INFO:Calculating mean and std
2023-03-30 13:53:39,392:INFO:Creating metrics dataframe
2023-03-30 13:53:39,623:INFO:Uploading results into container
2023-03-30 13:53:39,629:INFO:Uploading model into container now
2023-03-30 13:53:39,639:INFO:_master_model_container: 2
2023-03-30 13:53:39,639:INFO:_display_container: 2
2023-03-30 13:53:39,648:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-30 13:53:39,648:INFO:create_model() successfully completed......................................
2023-03-30 13:53:40,547:INFO:SubProcess create_model() end ==================================
2023-03-30 13:53:40,547:INFO:Creating metrics dataframe
2023-03-30 13:53:40,569:INFO:Initializing Naive Bayes
2023-03-30 13:53:40,569:INFO:Total runtime is 12.450565087795257 minutes
2023-03-30 13:53:40,569:INFO:SubProcess create_model() called ==================================
2023-03-30 13:53:40,569:INFO:Initializing create_model()
2023-03-30 13:53:40,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:53:40,569:INFO:Checking exceptions
2023-03-30 13:53:40,569:INFO:Importing libraries
2023-03-30 13:53:40,569:INFO:Copying training dataset
2023-03-30 13:53:40,644:INFO:Defining folds
2023-03-30 13:53:40,644:INFO:Declaring metric variables
2023-03-30 13:53:40,647:INFO:Importing untrained model
2023-03-30 13:53:40,650:INFO:Naive Bayes Imported successfully
2023-03-30 13:53:40,655:INFO:Starting cross validation
2023-03-30 13:53:40,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:53:43,155:INFO:Calculating mean and std
2023-03-30 13:53:43,155:INFO:Creating metrics dataframe
2023-03-30 13:53:43,279:INFO:Uploading results into container
2023-03-30 13:53:43,279:INFO:Uploading model into container now
2023-03-30 13:53:43,279:INFO:_master_model_container: 3
2023-03-30 13:53:43,279:INFO:_display_container: 2
2023-03-30 13:53:43,279:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-30 13:53:43,279:INFO:create_model() successfully completed......................................
2023-03-30 13:53:43,412:INFO:SubProcess create_model() end ==================================
2023-03-30 13:53:43,412:INFO:Creating metrics dataframe
2023-03-30 13:53:43,427:INFO:Initializing Decision Tree Classifier
2023-03-30 13:53:43,427:INFO:Total runtime is 12.498197495937346 minutes
2023-03-30 13:53:43,427:INFO:SubProcess create_model() called ==================================
2023-03-30 13:53:43,427:INFO:Initializing create_model()
2023-03-30 13:53:43,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:53:43,427:INFO:Checking exceptions
2023-03-30 13:53:43,427:INFO:Importing libraries
2023-03-30 13:53:43,427:INFO:Copying training dataset
2023-03-30 13:53:43,479:INFO:Defining folds
2023-03-30 13:53:43,479:INFO:Declaring metric variables
2023-03-30 13:53:43,482:INFO:Importing untrained model
2023-03-30 13:53:43,485:INFO:Decision Tree Classifier Imported successfully
2023-03-30 13:53:43,490:INFO:Starting cross validation
2023-03-30 13:53:43,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:53:48,640:INFO:Calculating mean and std
2023-03-30 13:53:48,640:INFO:Creating metrics dataframe
2023-03-30 13:53:48,763:INFO:Uploading results into container
2023-03-30 13:53:48,779:INFO:Uploading model into container now
2023-03-30 13:53:48,779:INFO:_master_model_container: 4
2023-03-30 13:53:48,779:INFO:_display_container: 2
2023-03-30 13:53:48,779:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1080, splitter='best')
2023-03-30 13:53:48,779:INFO:create_model() successfully completed......................................
2023-03-30 13:53:48,912:INFO:SubProcess create_model() end ==================================
2023-03-30 13:53:48,912:INFO:Creating metrics dataframe
2023-03-30 13:53:48,927:INFO:Initializing SVM - Linear Kernel
2023-03-30 13:53:48,927:INFO:Total runtime is 12.58986278772354 minutes
2023-03-30 13:53:48,927:INFO:SubProcess create_model() called ==================================
2023-03-30 13:53:48,927:INFO:Initializing create_model()
2023-03-30 13:53:48,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:53:48,927:INFO:Checking exceptions
2023-03-30 13:53:48,927:INFO:Importing libraries
2023-03-30 13:53:48,927:INFO:Copying training dataset
2023-03-30 13:53:48,972:INFO:Defining folds
2023-03-30 13:53:48,972:INFO:Declaring metric variables
2023-03-30 13:53:48,974:INFO:Importing untrained model
2023-03-30 13:53:48,974:INFO:SVM - Linear Kernel Imported successfully
2023-03-30 13:53:48,974:INFO:Starting cross validation
2023-03-30 13:53:48,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:53:55,511:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:55,526:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 13:53:57,412:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:58,051:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:58,118:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:59,163:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:59,167:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 13:53:59,925:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:59,941:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:53:59,941:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 13:54:00,931:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:54:02,356:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:54:04,658:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 13:54:04,783:INFO:Calculating mean and std
2023-03-30 13:54:04,783:INFO:Creating metrics dataframe
2023-03-30 13:54:04,912:INFO:Uploading results into container
2023-03-30 13:54:04,912:INFO:Uploading model into container now
2023-03-30 13:54:04,912:INFO:_master_model_container: 5
2023-03-30 13:54:04,912:INFO:_display_container: 2
2023-03-30 13:54:04,912:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1080, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-30 13:54:04,912:INFO:create_model() successfully completed......................................
2023-03-30 13:54:05,060:INFO:SubProcess create_model() end ==================================
2023-03-30 13:54:05,060:INFO:Creating metrics dataframe
2023-03-30 13:54:05,068:INFO:Initializing Ridge Classifier
2023-03-30 13:54:05,069:INFO:Total runtime is 12.858883289496102 minutes
2023-03-30 13:54:05,069:INFO:SubProcess create_model() called ==================================
2023-03-30 13:54:05,069:INFO:Initializing create_model()
2023-03-30 13:54:05,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:54:05,069:INFO:Checking exceptions
2023-03-30 13:54:05,069:INFO:Importing libraries
2023-03-30 13:54:05,069:INFO:Copying training dataset
2023-03-30 13:54:05,112:INFO:Defining folds
2023-03-30 13:54:05,112:INFO:Declaring metric variables
2023-03-30 13:54:05,115:INFO:Importing untrained model
2023-03-30 13:54:05,118:INFO:Ridge Classifier Imported successfully
2023-03-30 13:54:05,123:INFO:Starting cross validation
2023-03-30 13:54:05,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:54:05,392:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,392:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,458:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,499:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,538:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,546:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,625:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,656:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,954:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:05,985:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 13:54:07,006:INFO:Calculating mean and std
2023-03-30 13:54:07,006:INFO:Creating metrics dataframe
2023-03-30 13:54:07,127:INFO:Uploading results into container
2023-03-30 13:54:07,127:INFO:Uploading model into container now
2023-03-30 13:54:07,127:INFO:_master_model_container: 6
2023-03-30 13:54:07,127:INFO:_display_container: 2
2023-03-30 13:54:07,127:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1080, solver='auto', tol=0.001)
2023-03-30 13:54:07,127:INFO:create_model() successfully completed......................................
2023-03-30 13:54:07,260:INFO:SubProcess create_model() end ==================================
2023-03-30 13:54:07,260:INFO:Creating metrics dataframe
2023-03-30 13:54:07,269:INFO:Initializing Random Forest Classifier
2023-03-30 13:54:07,269:INFO:Total runtime is 12.895555361111958 minutes
2023-03-30 13:54:07,269:INFO:SubProcess create_model() called ==================================
2023-03-30 13:54:07,269:INFO:Initializing create_model()
2023-03-30 13:54:07,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:54:07,269:INFO:Checking exceptions
2023-03-30 13:54:07,269:INFO:Importing libraries
2023-03-30 13:54:07,269:INFO:Copying training dataset
2023-03-30 13:54:07,311:INFO:Defining folds
2023-03-30 13:54:07,311:INFO:Declaring metric variables
2023-03-30 13:54:07,314:INFO:Importing untrained model
2023-03-30 13:54:07,317:INFO:Random Forest Classifier Imported successfully
2023-03-30 13:54:07,321:INFO:Starting cross validation
2023-03-30 13:54:07,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:54:24,943:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:54:28,583:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:54:28,928:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:54:28,980:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:54:29,006:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 13:54:29,617:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 13:54:29,758:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 13:54:35,201:INFO:Calculating mean and std
2023-03-30 13:54:35,201:INFO:Creating metrics dataframe
2023-03-30 13:54:35,374:INFO:Uploading results into container
2023-03-30 13:54:35,374:INFO:Uploading model into container now
2023-03-30 13:54:35,374:INFO:_master_model_container: 7
2023-03-30 13:54:35,374:INFO:_display_container: 2
2023-03-30 13:54:35,374:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1080, verbose=0, warm_start=False)
2023-03-30 13:54:35,382:INFO:create_model() successfully completed......................................
2023-03-30 13:54:35,527:INFO:SubProcess create_model() end ==================================
2023-03-30 13:54:35,527:INFO:Creating metrics dataframe
2023-03-30 13:54:35,527:INFO:Initializing Quadratic Discriminant Analysis
2023-03-30 13:54:35,527:INFO:Total runtime is 13.366528006394704 minutes
2023-03-30 13:54:35,527:INFO:SubProcess create_model() called ==================================
2023-03-30 13:54:35,527:INFO:Initializing create_model()
2023-03-30 13:54:35,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:54:35,541:INFO:Checking exceptions
2023-03-30 13:54:35,541:INFO:Importing libraries
2023-03-30 13:54:35,541:INFO:Copying training dataset
2023-03-30 13:54:35,582:INFO:Defining folds
2023-03-30 13:54:35,582:INFO:Declaring metric variables
2023-03-30 13:54:35,586:INFO:Importing untrained model
2023-03-30 13:54:35,588:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-30 13:54:35,593:INFO:Starting cross validation
2023-03-30 13:54:35,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:54:35,807:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:35,871:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:35,949:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:35,980:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:36,058:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:36,153:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:36,153:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:36,221:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:36,884:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:36,966:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 13:54:38,064:INFO:Calculating mean and std
2023-03-30 13:54:38,066:INFO:Creating metrics dataframe
2023-03-30 13:54:38,200:INFO:Uploading results into container
2023-03-30 13:54:38,200:INFO:Uploading model into container now
2023-03-30 13:54:38,200:INFO:_master_model_container: 8
2023-03-30 13:54:38,200:INFO:_display_container: 2
2023-03-30 13:54:38,200:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-30 13:54:38,200:INFO:create_model() successfully completed......................................
2023-03-30 13:54:38,349:INFO:SubProcess create_model() end ==================================
2023-03-30 13:54:38,349:INFO:Creating metrics dataframe
2023-03-30 13:54:38,365:INFO:Initializing Ada Boost Classifier
2023-03-30 13:54:38,365:INFO:Total runtime is 13.413831714789072 minutes
2023-03-30 13:54:38,366:INFO:SubProcess create_model() called ==================================
2023-03-30 13:54:38,366:INFO:Initializing create_model()
2023-03-30 13:54:38,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:54:38,366:INFO:Checking exceptions
2023-03-30 13:54:38,366:INFO:Importing libraries
2023-03-30 13:54:38,366:INFO:Copying training dataset
2023-03-30 13:54:38,409:INFO:Defining folds
2023-03-30 13:54:38,409:INFO:Declaring metric variables
2023-03-30 13:54:38,410:INFO:Importing untrained model
2023-03-30 13:54:38,417:INFO:Ada Boost Classifier Imported successfully
2023-03-30 13:54:38,425:INFO:Starting cross validation
2023-03-30 13:54:38,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:54:48,731:INFO:Calculating mean and std
2023-03-30 13:54:48,733:INFO:Creating metrics dataframe
2023-03-30 13:54:48,883:INFO:Uploading results into container
2023-03-30 13:54:48,883:INFO:Uploading model into container now
2023-03-30 13:54:48,883:INFO:_master_model_container: 9
2023-03-30 13:54:48,883:INFO:_display_container: 2
2023-03-30 13:54:48,883:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1080)
2023-03-30 13:54:48,883:INFO:create_model() successfully completed......................................
2023-03-30 13:54:49,036:INFO:SubProcess create_model() end ==================================
2023-03-30 13:54:49,036:INFO:Creating metrics dataframe
2023-03-30 13:54:49,049:INFO:Initializing Gradient Boosting Classifier
2023-03-30 13:54:49,049:INFO:Total runtime is 13.59189563592275 minutes
2023-03-30 13:54:49,049:INFO:SubProcess create_model() called ==================================
2023-03-30 13:54:49,049:INFO:Initializing create_model()
2023-03-30 13:54:49,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:54:49,049:INFO:Checking exceptions
2023-03-30 13:54:49,049:INFO:Importing libraries
2023-03-30 13:54:49,049:INFO:Copying training dataset
2023-03-30 13:54:49,099:INFO:Defining folds
2023-03-30 13:54:49,099:INFO:Declaring metric variables
2023-03-30 13:54:49,100:INFO:Importing untrained model
2023-03-30 13:54:49,100:INFO:Gradient Boosting Classifier Imported successfully
2023-03-30 13:54:49,100:INFO:Starting cross validation
2023-03-30 13:54:49,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:55:18,762:INFO:Calculating mean and std
2023-03-30 13:55:18,762:INFO:Creating metrics dataframe
2023-03-30 13:55:18,895:INFO:Uploading results into container
2023-03-30 13:55:18,895:INFO:Uploading model into container now
2023-03-30 13:55:18,895:INFO:_master_model_container: 10
2023-03-30 13:55:18,895:INFO:_display_container: 2
2023-03-30 13:55:18,895:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1080, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-30 13:55:18,895:INFO:create_model() successfully completed......................................
2023-03-30 13:55:19,044:INFO:SubProcess create_model() end ==================================
2023-03-30 13:55:19,044:INFO:Creating metrics dataframe
2023-03-30 13:55:19,052:INFO:Initializing Linear Discriminant Analysis
2023-03-30 13:55:19,052:INFO:Total runtime is 14.091940240065258 minutes
2023-03-30 13:55:19,052:INFO:SubProcess create_model() called ==================================
2023-03-30 13:55:19,052:INFO:Initializing create_model()
2023-03-30 13:55:19,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:55:19,052:INFO:Checking exceptions
2023-03-30 13:55:19,052:INFO:Importing libraries
2023-03-30 13:55:19,052:INFO:Copying training dataset
2023-03-30 13:55:19,098:INFO:Defining folds
2023-03-30 13:55:19,098:INFO:Declaring metric variables
2023-03-30 13:55:19,100:INFO:Importing untrained model
2023-03-30 13:55:19,103:INFO:Linear Discriminant Analysis Imported successfully
2023-03-30 13:55:19,107:INFO:Starting cross validation
2023-03-30 13:55:19,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:55:21,655:INFO:Calculating mean and std
2023-03-30 13:55:21,655:INFO:Creating metrics dataframe
2023-03-30 13:55:21,778:INFO:Uploading results into container
2023-03-30 13:55:21,778:INFO:Uploading model into container now
2023-03-30 13:55:21,778:INFO:_master_model_container: 11
2023-03-30 13:55:21,778:INFO:_display_container: 2
2023-03-30 13:55:21,778:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-30 13:55:21,778:INFO:create_model() successfully completed......................................
2023-03-30 13:55:21,927:INFO:SubProcess create_model() end ==================================
2023-03-30 13:55:21,927:INFO:Creating metrics dataframe
2023-03-30 13:55:21,934:INFO:Initializing Extra Trees Classifier
2023-03-30 13:55:21,934:INFO:Total runtime is 14.13998047510783 minutes
2023-03-30 13:55:21,934:INFO:SubProcess create_model() called ==================================
2023-03-30 13:55:21,934:INFO:Initializing create_model()
2023-03-30 13:55:21,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019BA851A640>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019BD44A7340>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 13:55:21,934:INFO:Checking exceptions
2023-03-30 13:55:21,934:INFO:Importing libraries
2023-03-30 13:55:21,934:INFO:Copying training dataset
2023-03-30 13:55:21,985:INFO:Defining folds
2023-03-30 13:55:21,985:INFO:Declaring metric variables
2023-03-30 13:55:21,988:INFO:Importing untrained model
2023-03-30 13:55:21,991:INFO:Extra Trees Classifier Imported successfully
2023-03-30 13:55:21,998:INFO:Starting cross validation
2023-03-30 13:55:21,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 13:55:40,328:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:55:43,391:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 13:55:44,838:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:01:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 14:01:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 14:01:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 14:01:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-30 14:01:18,024:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-30 14:01:23,153:INFO:PyCaret ClassificationExperiment
2023-03-30 14:01:23,153:INFO:Logging name: clf-default-name
2023-03-30 14:01:23,153:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-30 14:01:23,153:INFO:version 3.0.0
2023-03-30 14:01:23,153:INFO:Initializing setup()
2023-03-30 14:01:23,153:INFO:self.USI: afd3
2023-03-30 14:01:23,153:INFO:self._variable_keys: {'seed', 'idx', 'gpu_n_jobs_param', 'y_train', 'y_test', 'pipeline', 'gpu_param', 'memory', '_available_plots', 'log_plots_param', 'USI', 'logging_param', 'X_test', 'exp_id', 'fold_groups_param', 'fix_imbalance', 'exp_name_log', 'n_jobs_param', 'fold_shuffle_param', 'target_param', 'fold_generator', 'X_train', '_ml_usecase', 'html_param', 'y', 'is_multiclass', 'data', 'X'}
2023-03-30 14:01:23,153:INFO:Checking environment
2023-03-30 14:01:23,153:INFO:python_version: 3.9.12
2023-03-30 14:01:23,153:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-03-30 14:01:23,153:INFO:machine: AMD64
2023-03-30 14:01:23,153:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-30 14:01:23,153:INFO:Memory: svmem(total=8316030976, available=2096762880, percent=74.8, used=6219268096, free=2096762880)
2023-03-30 14:01:23,153:INFO:Physical Core: 4
2023-03-30 14:01:23,153:INFO:Logical Core: 8
2023-03-30 14:01:23,153:INFO:Checking libraries
2023-03-30 14:01:23,153:INFO:System:
2023-03-30 14:01:23,153:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-03-30 14:01:23,153:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-03-30 14:01:23,153:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-30 14:01:23,153:INFO:PyCaret required dependencies:
2023-03-30 14:01:23,153:INFO:                 pip: 21.2.4
2023-03-30 14:01:23,153:INFO:          setuptools: 61.2.0
2023-03-30 14:01:23,153:INFO:             pycaret: 3.0.0
2023-03-30 14:01:23,153:INFO:             IPython: 8.2.0
2023-03-30 14:01:23,153:INFO:          ipywidgets: 7.6.5
2023-03-30 14:01:23,153:INFO:                tqdm: 4.64.0
2023-03-30 14:01:23,153:INFO:               numpy: 1.21.6
2023-03-30 14:01:23,153:INFO:              pandas: 1.4.2
2023-03-30 14:01:23,153:INFO:              jinja2: 2.11.3
2023-03-30 14:01:23,153:INFO:               scipy: 1.7.3
2023-03-30 14:01:23,153:INFO:              joblib: 1.2.0
2023-03-30 14:01:23,153:INFO:             sklearn: 1.0.2
2023-03-30 14:01:23,153:INFO:                pyod: 1.0.9
2023-03-30 14:01:23,153:INFO:            imblearn: 0.10.1
2023-03-30 14:01:23,153:INFO:   category_encoders: 2.6.0
2023-03-30 14:01:23,153:INFO:            lightgbm: 3.3.5
2023-03-30 14:01:23,153:INFO:               numba: 0.55.1
2023-03-30 14:01:23,153:INFO:            requests: 2.27.1
2023-03-30 14:01:23,153:INFO:          matplotlib: 3.5.1
2023-03-30 14:01:23,153:INFO:          scikitplot: 0.3.7
2023-03-30 14:01:23,153:INFO:         yellowbrick: 1.5
2023-03-30 14:01:23,153:INFO:              plotly: 5.6.0
2023-03-30 14:01:23,153:INFO:             kaleido: 0.2.1
2023-03-30 14:01:23,153:INFO:         statsmodels: 0.13.2
2023-03-30 14:01:23,153:INFO:              sktime: 0.16.1
2023-03-30 14:01:23,153:INFO:               tbats: 1.1.2
2023-03-30 14:01:23,153:INFO:            pmdarima: 2.0.3
2023-03-30 14:01:23,153:INFO:              psutil: 5.9.4
2023-03-30 14:01:23,153:INFO:PyCaret optional dependencies:
2023-03-30 14:01:23,153:INFO:                shap: 0.41.0
2023-03-30 14:01:23,153:INFO:           interpret: Not installed
2023-03-30 14:01:23,153:INFO:                umap: Not installed
2023-03-30 14:01:23,153:INFO:    pandas_profiling: 4.1.2
2023-03-30 14:01:23,153:INFO:  explainerdashboard: Not installed
2023-03-30 14:01:23,153:INFO:             autoviz: Not installed
2023-03-30 14:01:23,153:INFO:           fairlearn: Not installed
2023-03-30 14:01:23,153:INFO:             xgboost: Not installed
2023-03-30 14:01:23,153:INFO:            catboost: Not installed
2023-03-30 14:01:23,153:INFO:              kmodes: Not installed
2023-03-30 14:01:23,153:INFO:             mlxtend: Not installed
2023-03-30 14:01:23,153:INFO:       statsforecast: Not installed
2023-03-30 14:01:23,153:INFO:        tune_sklearn: Not installed
2023-03-30 14:01:23,153:INFO:                 ray: Not installed
2023-03-30 14:01:23,153:INFO:            hyperopt: Not installed
2023-03-30 14:01:23,153:INFO:              optuna: Not installed
2023-03-30 14:01:23,153:INFO:               skopt: Not installed
2023-03-30 14:01:23,153:INFO:              mlflow: Not installed
2023-03-30 14:01:23,153:INFO:              gradio: Not installed
2023-03-30 14:01:23,153:INFO:             fastapi: Not installed
2023-03-30 14:01:23,153:INFO:             uvicorn: Not installed
2023-03-30 14:01:23,153:INFO:              m2cgen: Not installed
2023-03-30 14:01:23,153:INFO:           evidently: Not installed
2023-03-30 14:01:23,153:INFO:               fugue: Not installed
2023-03-30 14:01:23,153:INFO:           streamlit: Not installed
2023-03-30 14:01:23,153:INFO:             prophet: Not installed
2023-03-30 14:01:23,153:INFO:None
2023-03-30 14:01:23,153:INFO:Set up data.
2023-03-30 14:01:23,184:INFO:Set up train/test split.
2023-03-30 14:01:23,247:INFO:Set up index.
2023-03-30 14:01:23,247:INFO:Set up folding strategy.
2023-03-30 14:01:23,247:INFO:Assigning column types.
2023-03-30 14:01:23,278:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-30 14:01:23,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-30 14:01:23,309:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 14:01:23,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-30 14:01:23,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 14:01:23,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,420:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-30 14:01:23,466:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 14:01:23,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-30 14:01:23,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,529:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-30 14:01:23,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:23,654:INFO:Preparing preprocessing pipeline...
2023-03-30 14:01:23,654:INFO:Set up simple imputation.
2023-03-30 14:01:23,748:INFO:Finished creating preprocessing pipeline.
2023-03-30 14:01:23,748:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CODE_GENDER', 'FLAG_OWN_CAR',
                                             'FLAG_OWN_REALTY', 'CNT_CHILDREN',
                                             'AMT_INCOME_TOTAL',
                                             'NAME_INCOME_TYPE',
                                             'NAME_EDUCATION_TYPE',
                                             'NAME_FAMILY_STATUS',
                                             'NAME_HOUSING_TYPE', 'DAYS_BIRTH',
                                             'DAYS_EMPLOYED', 'FLAG_MOBIL...
                                             'CNT_FAM_MEMBERS',
                                             'MONTHS_BALANCE'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-03-30 14:01:23,748:INFO:Creating final display dataframe.
2023-03-30 14:01:23,982:INFO:Setup _display_container:                     Description             Value
0                    Session id              6300
1                        Target            STATUS
2                   Target type            Binary
3           Original data shape      (148486, 19)
4        Transformed data shape      (148486, 19)
5   Transformed train set shape      (103940, 19)
6    Transformed test set shape       (44546, 19)
7              Numeric features                18
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              afd3
2023-03-30 14:01:24,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:24,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:24,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:24,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-30 14:01:24,105:INFO:setup() successfully completed in 1.08s...............
2023-03-30 14:01:27,228:INFO:Initializing compare_models()
2023-03-30 14:01:27,228:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-30 14:01:27,228:INFO:Checking exceptions
2023-03-30 14:01:27,255:INFO:Preparing display monitor
2023-03-30 14:01:27,277:INFO:Initializing Logistic Regression
2023-03-30 14:01:27,277:INFO:Total runtime is 0.0 minutes
2023-03-30 14:01:27,288:INFO:SubProcess create_model() called ==================================
2023-03-30 14:01:27,289:INFO:Initializing create_model()
2023-03-30 14:01:27,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:01:27,289:INFO:Checking exceptions
2023-03-30 14:01:27,289:INFO:Importing libraries
2023-03-30 14:01:27,289:INFO:Copying training dataset
2023-03-30 14:01:27,328:INFO:Defining folds
2023-03-30 14:01:27,328:INFO:Declaring metric variables
2023-03-30 14:01:27,331:INFO:Importing untrained model
2023-03-30 14:01:27,333:INFO:Logistic Regression Imported successfully
2023-03-30 14:01:27,338:INFO:Starting cross validation
2023-03-30 14:01:27,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:01:35,503:INFO:Calculating mean and std
2023-03-30 14:01:35,503:INFO:Creating metrics dataframe
2023-03-30 14:01:35,618:INFO:Uploading results into container
2023-03-30 14:01:35,618:INFO:Uploading model into container now
2023-03-30 14:01:35,618:INFO:_master_model_container: 1
2023-03-30 14:01:35,618:INFO:_display_container: 2
2023-03-30 14:01:35,618:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6300, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-30 14:01:35,618:INFO:create_model() successfully completed......................................
2023-03-30 14:01:35,774:INFO:SubProcess create_model() end ==================================
2023-03-30 14:01:35,774:INFO:Creating metrics dataframe
2023-03-30 14:01:35,777:INFO:Initializing K Neighbors Classifier
2023-03-30 14:01:35,777:INFO:Total runtime is 0.14166659116744995 minutes
2023-03-30 14:01:35,777:INFO:SubProcess create_model() called ==================================
2023-03-30 14:01:35,777:INFO:Initializing create_model()
2023-03-30 14:01:35,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:01:35,777:INFO:Checking exceptions
2023-03-30 14:01:35,777:INFO:Importing libraries
2023-03-30 14:01:35,777:INFO:Copying training dataset
2023-03-30 14:01:35,823:INFO:Defining folds
2023-03-30 14:01:35,823:INFO:Declaring metric variables
2023-03-30 14:01:35,827:INFO:Importing untrained model
2023-03-30 14:01:35,829:INFO:K Neighbors Classifier Imported successfully
2023-03-30 14:01:35,833:INFO:Starting cross validation
2023-03-30 14:01:35,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:01:40,337:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-03-30 14:01:48,239:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-03-30 14:01:49,638:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-30 14:01:55,295:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 6.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:01:54,716:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 7.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:02:07,720:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:02:24,831:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:02:31,514:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 14:02:33,832:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1434, in _parallel_pairwise
    ret = np.empty((X.shape[0], Y.shape[0]), dtype=dtype, order="F")
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1023. MiB for an array with shape (1434, 93546) and data type float64

  warnings.warn(

2023-03-30 14:02:35,208:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\extmath.py", line 153, in safe_sparse_dot
    ret = a @ b
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 14:02:51,924:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 3.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-30 14:03:26,246:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-03-30 14:03:48,932:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 19.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:04:14,627:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11694) and data type float64

  warnings.warn(

2023-03-30 14:04:16,778:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 761, in _score
    scores = scorer(estimator, X_test, y_test)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 103, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 258, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 113, in <lambda>
    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py", line 214, in predict
    neigh_dist, neigh_ind = self.kneighbors(X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\neighbors\_base.py", line 752, in kneighbors
    chunked_results = list(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1717, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1889, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1435, in _parallel_pairwise
    Parallel(backend="threading", n_jobs=n_jobs)(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 1061, in __call__
    self.retrieve()
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 938, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 771, in get
    raise self._value
  File "C:\Users\jaeek\anaconda3\lib\multiprocessing\pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in __call__
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\joblib\parallel.py", line 263, in <listcomp>
    return [func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\fixes.py", line 216, in __call__
    return self.function(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 1418, in _dist_wrapper
    dist_matrix[:, slice_] = dist_func(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 330, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\pairwise.py", line 371, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 128. MiB for an array with shape (1434, 11693) and data type float64

  warnings.warn(

2023-03-30 14:10:45,658:INFO:Calculating mean and std
2023-03-30 14:10:45,752:INFO:Creating metrics dataframe
2023-03-30 14:10:45,996:INFO:Uploading results into container
2023-03-30 14:10:46,003:INFO:Uploading model into container now
2023-03-30 14:10:46,010:INFO:_master_model_container: 2
2023-03-30 14:10:46,010:INFO:_display_container: 2
2023-03-30 14:10:46,022:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-30 14:10:46,022:INFO:create_model() successfully completed......................................
2023-03-30 14:10:46,899:INFO:SubProcess create_model() end ==================================
2023-03-30 14:10:46,899:INFO:Creating metrics dataframe
2023-03-30 14:10:46,908:INFO:Initializing Naive Bayes
2023-03-30 14:10:46,908:INFO:Total runtime is 9.327194674809773 minutes
2023-03-30 14:10:46,908:INFO:SubProcess create_model() called ==================================
2023-03-30 14:10:46,908:INFO:Initializing create_model()
2023-03-30 14:10:46,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:10:46,908:INFO:Checking exceptions
2023-03-30 14:10:46,908:INFO:Importing libraries
2023-03-30 14:10:46,908:INFO:Copying training dataset
2023-03-30 14:10:46,987:INFO:Defining folds
2023-03-30 14:10:46,987:INFO:Declaring metric variables
2023-03-30 14:10:46,990:INFO:Importing untrained model
2023-03-30 14:10:46,992:INFO:Naive Bayes Imported successfully
2023-03-30 14:10:46,997:INFO:Starting cross validation
2023-03-30 14:10:46,998:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:10:49,777:INFO:Calculating mean and std
2023-03-30 14:10:49,777:INFO:Creating metrics dataframe
2023-03-30 14:10:49,903:INFO:Uploading results into container
2023-03-30 14:10:49,903:INFO:Uploading model into container now
2023-03-30 14:10:49,903:INFO:_master_model_container: 3
2023-03-30 14:10:49,903:INFO:_display_container: 2
2023-03-30 14:10:49,903:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-30 14:10:49,903:INFO:create_model() successfully completed......................................
2023-03-30 14:10:50,044:INFO:SubProcess create_model() end ==================================
2023-03-30 14:10:50,044:INFO:Creating metrics dataframe
2023-03-30 14:10:50,057:INFO:Initializing Decision Tree Classifier
2023-03-30 14:10:50,057:INFO:Total runtime is 9.379665935039519 minutes
2023-03-30 14:10:50,059:INFO:SubProcess create_model() called ==================================
2023-03-30 14:10:50,059:INFO:Initializing create_model()
2023-03-30 14:10:50,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:10:50,059:INFO:Checking exceptions
2023-03-30 14:10:50,059:INFO:Importing libraries
2023-03-30 14:10:50,059:INFO:Copying training dataset
2023-03-30 14:10:50,098:INFO:Defining folds
2023-03-30 14:10:50,099:INFO:Declaring metric variables
2023-03-30 14:10:50,102:INFO:Importing untrained model
2023-03-30 14:10:50,105:INFO:Decision Tree Classifier Imported successfully
2023-03-30 14:10:50,107:INFO:Starting cross validation
2023-03-30 14:10:50,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:10:55,281:INFO:Calculating mean and std
2023-03-30 14:10:55,281:INFO:Creating metrics dataframe
2023-03-30 14:10:55,416:INFO:Uploading results into container
2023-03-30 14:10:55,416:INFO:Uploading model into container now
2023-03-30 14:10:55,416:INFO:_master_model_container: 4
2023-03-30 14:10:55,416:INFO:_display_container: 2
2023-03-30 14:10:55,432:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6300, splitter='best')
2023-03-30 14:10:55,432:INFO:create_model() successfully completed......................................
2023-03-30 14:10:55,565:INFO:SubProcess create_model() end ==================================
2023-03-30 14:10:55,570:INFO:Creating metrics dataframe
2023-03-30 14:10:55,571:INFO:Initializing SVM - Linear Kernel
2023-03-30 14:10:55,571:INFO:Total runtime is 9.471565457185108 minutes
2023-03-30 14:10:55,571:INFO:SubProcess create_model() called ==================================
2023-03-30 14:10:55,571:INFO:Initializing create_model()
2023-03-30 14:10:55,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:10:55,571:INFO:Checking exceptions
2023-03-30 14:10:55,571:INFO:Importing libraries
2023-03-30 14:10:55,571:INFO:Copying training dataset
2023-03-30 14:10:55,620:INFO:Defining folds
2023-03-30 14:10:55,621:INFO:Declaring metric variables
2023-03-30 14:10:55,625:INFO:Importing untrained model
2023-03-30 14:10:55,628:INFO:SVM - Linear Kernel Imported successfully
2023-03-30 14:10:55,629:INFO:Starting cross validation
2023-03-30 14:10:55,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:11:02,855:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:03,596:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:04,559:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:05,213:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:05,277:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:05,891:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:05,906:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:06,268:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:10,227:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:10,822:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-30 14:11:10,837:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:11:10,946:INFO:Calculating mean and std
2023-03-30 14:11:10,946:INFO:Creating metrics dataframe
2023-03-30 14:11:11,115:INFO:Uploading results into container
2023-03-30 14:11:11,115:INFO:Uploading model into container now
2023-03-30 14:11:11,115:INFO:_master_model_container: 5
2023-03-30 14:11:11,115:INFO:_display_container: 2
2023-03-30 14:11:11,131:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6300, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-30 14:11:11,131:INFO:create_model() successfully completed......................................
2023-03-30 14:11:11,256:INFO:SubProcess create_model() end ==================================
2023-03-30 14:11:11,256:INFO:Creating metrics dataframe
2023-03-30 14:11:11,273:INFO:Initializing Ridge Classifier
2023-03-30 14:11:11,274:INFO:Total runtime is 9.733288101355233 minutes
2023-03-30 14:11:11,274:INFO:SubProcess create_model() called ==================================
2023-03-30 14:11:11,274:INFO:Initializing create_model()
2023-03-30 14:11:11,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:11:11,274:INFO:Checking exceptions
2023-03-30 14:11:11,274:INFO:Importing libraries
2023-03-30 14:11:11,274:INFO:Copying training dataset
2023-03-30 14:11:11,317:INFO:Defining folds
2023-03-30 14:11:11,318:INFO:Declaring metric variables
2023-03-30 14:11:11,321:INFO:Importing untrained model
2023-03-30 14:11:11,324:INFO:Ridge Classifier Imported successfully
2023-03-30 14:11:11,328:INFO:Starting cross validation
2023-03-30 14:11:11,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:11:11,687:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,703:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,703:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,718:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,797:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,844:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,844:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:11,844:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:12,284:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:12,315:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-30 14:11:13,519:INFO:Calculating mean and std
2023-03-30 14:11:13,519:INFO:Creating metrics dataframe
2023-03-30 14:11:13,650:INFO:Uploading results into container
2023-03-30 14:11:13,650:INFO:Uploading model into container now
2023-03-30 14:11:13,650:INFO:_master_model_container: 6
2023-03-30 14:11:13,650:INFO:_display_container: 2
2023-03-30 14:11:13,650:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6300, solver='auto', tol=0.001)
2023-03-30 14:11:13,650:INFO:create_model() successfully completed......................................
2023-03-30 14:11:13,791:INFO:SubProcess create_model() end ==================================
2023-03-30 14:11:13,791:INFO:Creating metrics dataframe
2023-03-30 14:11:13,804:INFO:Initializing Random Forest Classifier
2023-03-30 14:11:13,804:INFO:Total runtime is 9.775446597735085 minutes
2023-03-30 14:11:13,807:INFO:SubProcess create_model() called ==================================
2023-03-30 14:11:13,807:INFO:Initializing create_model()
2023-03-30 14:11:13,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:11:13,807:INFO:Checking exceptions
2023-03-30 14:11:13,807:INFO:Importing libraries
2023-03-30 14:11:13,807:INFO:Copying training dataset
2023-03-30 14:11:13,845:INFO:Defining folds
2023-03-30 14:11:13,845:INFO:Declaring metric variables
2023-03-30 14:11:13,848:INFO:Importing untrained model
2023-03-30 14:11:13,851:INFO:Random Forest Classifier Imported successfully
2023-03-30 14:11:13,857:INFO:Starting cross validation
2023-03-30 14:11:13,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:11:31,722:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:11:32,793:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:11:40,770:INFO:Calculating mean and std
2023-03-30 14:11:40,770:INFO:Creating metrics dataframe
2023-03-30 14:11:40,886:INFO:Uploading results into container
2023-03-30 14:11:40,886:INFO:Uploading model into container now
2023-03-30 14:11:40,886:INFO:_master_model_container: 7
2023-03-30 14:11:40,886:INFO:_display_container: 2
2023-03-30 14:11:40,886:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:11:40,886:INFO:create_model() successfully completed......................................
2023-03-30 14:11:41,045:INFO:SubProcess create_model() end ==================================
2023-03-30 14:11:41,045:INFO:Creating metrics dataframe
2023-03-30 14:11:41,056:INFO:Initializing Quadratic Discriminant Analysis
2023-03-30 14:11:41,056:INFO:Total runtime is 10.229652833938596 minutes
2023-03-30 14:11:41,056:INFO:SubProcess create_model() called ==================================
2023-03-30 14:11:41,056:INFO:Initializing create_model()
2023-03-30 14:11:41,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:11:41,056:INFO:Checking exceptions
2023-03-30 14:11:41,056:INFO:Importing libraries
2023-03-30 14:11:41,056:INFO:Copying training dataset
2023-03-30 14:11:41,109:INFO:Defining folds
2023-03-30 14:11:41,109:INFO:Declaring metric variables
2023-03-30 14:11:41,112:INFO:Importing untrained model
2023-03-30 14:11:41,115:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-30 14:11:41,121:INFO:Starting cross validation
2023-03-30 14:11:41,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:11:41,428:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,428:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,598:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,613:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,714:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,723:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,755:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:41,848:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:42,398:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:42,430:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-30 14:11:43,486:INFO:Calculating mean and std
2023-03-30 14:11:43,487:INFO:Creating metrics dataframe
2023-03-30 14:11:43,604:INFO:Uploading results into container
2023-03-30 14:11:43,604:INFO:Uploading model into container now
2023-03-30 14:11:43,604:INFO:_master_model_container: 8
2023-03-30 14:11:43,604:INFO:_display_container: 2
2023-03-30 14:11:43,604:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-30 14:11:43,604:INFO:create_model() successfully completed......................................
2023-03-30 14:11:43,759:INFO:SubProcess create_model() end ==================================
2023-03-30 14:11:43,759:INFO:Creating metrics dataframe
2023-03-30 14:11:43,768:INFO:Initializing Ada Boost Classifier
2023-03-30 14:11:43,768:INFO:Total runtime is 10.274855589866636 minutes
2023-03-30 14:11:43,770:INFO:SubProcess create_model() called ==================================
2023-03-30 14:11:43,771:INFO:Initializing create_model()
2023-03-30 14:11:43,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:11:43,771:INFO:Checking exceptions
2023-03-30 14:11:43,771:INFO:Importing libraries
2023-03-30 14:11:43,771:INFO:Copying training dataset
2023-03-30 14:11:43,809:INFO:Defining folds
2023-03-30 14:11:43,810:INFO:Declaring metric variables
2023-03-30 14:11:43,812:INFO:Importing untrained model
2023-03-30 14:11:43,815:INFO:Ada Boost Classifier Imported successfully
2023-03-30 14:11:43,821:INFO:Starting cross validation
2023-03-30 14:11:43,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:11:53,361:INFO:Calculating mean and std
2023-03-30 14:11:53,361:INFO:Creating metrics dataframe
2023-03-30 14:11:53,483:INFO:Uploading results into container
2023-03-30 14:11:53,483:INFO:Uploading model into container now
2023-03-30 14:11:53,483:INFO:_master_model_container: 9
2023-03-30 14:11:53,483:INFO:_display_container: 2
2023-03-30 14:11:53,483:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6300)
2023-03-30 14:11:53,483:INFO:create_model() successfully completed......................................
2023-03-30 14:11:53,614:INFO:SubProcess create_model() end ==================================
2023-03-30 14:11:53,630:INFO:Creating metrics dataframe
2023-03-30 14:11:53,630:INFO:Initializing Gradient Boosting Classifier
2023-03-30 14:11:53,630:INFO:Total runtime is 10.439220523834226 minutes
2023-03-30 14:11:53,641:INFO:SubProcess create_model() called ==================================
2023-03-30 14:11:53,641:INFO:Initializing create_model()
2023-03-30 14:11:53,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:11:53,642:INFO:Checking exceptions
2023-03-30 14:11:53,642:INFO:Importing libraries
2023-03-30 14:11:53,642:INFO:Copying training dataset
2023-03-30 14:11:53,686:INFO:Defining folds
2023-03-30 14:11:53,686:INFO:Declaring metric variables
2023-03-30 14:11:53,686:INFO:Importing untrained model
2023-03-30 14:11:53,686:INFO:Gradient Boosting Classifier Imported successfully
2023-03-30 14:11:53,686:INFO:Starting cross validation
2023-03-30 14:11:53,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:12:22,813:INFO:Calculating mean and std
2023-03-30 14:12:22,813:INFO:Creating metrics dataframe
2023-03-30 14:12:22,934:INFO:Uploading results into container
2023-03-30 14:12:22,934:INFO:Uploading model into container now
2023-03-30 14:12:22,934:INFO:_master_model_container: 10
2023-03-30 14:12:22,934:INFO:_display_container: 2
2023-03-30 14:12:22,934:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6300, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-30 14:12:22,934:INFO:create_model() successfully completed......................................
2023-03-30 14:12:23,072:INFO:SubProcess create_model() end ==================================
2023-03-30 14:12:23,072:INFO:Creating metrics dataframe
2023-03-30 14:12:23,085:INFO:Initializing Linear Discriminant Analysis
2023-03-30 14:12:23,085:INFO:Total runtime is 10.93013752698898 minutes
2023-03-30 14:12:23,087:INFO:SubProcess create_model() called ==================================
2023-03-30 14:12:23,087:INFO:Initializing create_model()
2023-03-30 14:12:23,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:12:23,088:INFO:Checking exceptions
2023-03-30 14:12:23,088:INFO:Importing libraries
2023-03-30 14:12:23,088:INFO:Copying training dataset
2023-03-30 14:12:23,118:INFO:Defining folds
2023-03-30 14:12:23,118:INFO:Declaring metric variables
2023-03-30 14:12:23,118:INFO:Importing untrained model
2023-03-30 14:12:23,134:INFO:Linear Discriminant Analysis Imported successfully
2023-03-30 14:12:23,140:INFO:Starting cross validation
2023-03-30 14:12:23,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:12:25,567:INFO:Calculating mean and std
2023-03-30 14:12:25,567:INFO:Creating metrics dataframe
2023-03-30 14:12:25,698:INFO:Uploading results into container
2023-03-30 14:12:25,698:INFO:Uploading model into container now
2023-03-30 14:12:25,698:INFO:_master_model_container: 11
2023-03-30 14:12:25,698:INFO:_display_container: 2
2023-03-30 14:12:25,698:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-30 14:12:25,698:INFO:create_model() successfully completed......................................
2023-03-30 14:12:25,833:INFO:SubProcess create_model() end ==================================
2023-03-30 14:12:25,833:INFO:Creating metrics dataframe
2023-03-30 14:12:25,833:INFO:Initializing Extra Trees Classifier
2023-03-30 14:12:25,833:INFO:Total runtime is 10.97593058745066 minutes
2023-03-30 14:12:25,848:INFO:SubProcess create_model() called ==================================
2023-03-30 14:12:25,848:INFO:Initializing create_model()
2023-03-30 14:12:25,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:12:25,848:INFO:Checking exceptions
2023-03-30 14:12:25,848:INFO:Importing libraries
2023-03-30 14:12:25,848:INFO:Copying training dataset
2023-03-30 14:12:25,888:INFO:Defining folds
2023-03-30 14:12:25,889:INFO:Declaring metric variables
2023-03-30 14:12:25,890:INFO:Importing untrained model
2023-03-30 14:12:25,890:INFO:Extra Trees Classifier Imported successfully
2023-03-30 14:12:25,890:INFO:Starting cross validation
2023-03-30 14:12:25,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:12:47,276:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:12:52,311:INFO:Calculating mean and std
2023-03-30 14:12:52,327:INFO:Creating metrics dataframe
2023-03-30 14:12:52,575:INFO:Uploading results into container
2023-03-30 14:12:52,575:INFO:Uploading model into container now
2023-03-30 14:12:52,575:INFO:_master_model_container: 12
2023-03-30 14:12:52,575:INFO:_display_container: 2
2023-03-30 14:12:52,587:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:12:52,587:INFO:create_model() successfully completed......................................
2023-03-30 14:12:52,979:INFO:SubProcess create_model() end ==================================
2023-03-30 14:12:52,995:INFO:Creating metrics dataframe
2023-03-30 14:12:53,010:INFO:Initializing Light Gradient Boosting Machine
2023-03-30 14:12:53,010:INFO:Total runtime is 11.428891746203101 minutes
2023-03-30 14:12:53,010:INFO:SubProcess create_model() called ==================================
2023-03-30 14:12:53,010:INFO:Initializing create_model()
2023-03-30 14:12:53,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:12:53,010:INFO:Checking exceptions
2023-03-30 14:12:53,010:INFO:Importing libraries
2023-03-30 14:12:53,010:INFO:Copying training dataset
2023-03-30 14:12:53,072:INFO:Defining folds
2023-03-30 14:12:53,072:INFO:Declaring metric variables
2023-03-30 14:12:53,077:INFO:Importing untrained model
2023-03-30 14:12:53,080:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-30 14:12:53,086:INFO:Starting cross validation
2023-03-30 14:12:53,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:12:57,917:INFO:Calculating mean and std
2023-03-30 14:12:57,917:INFO:Creating metrics dataframe
2023-03-30 14:12:58,060:INFO:Uploading results into container
2023-03-30 14:12:58,060:INFO:Uploading model into container now
2023-03-30 14:12:58,060:INFO:_master_model_container: 13
2023-03-30 14:12:58,060:INFO:_display_container: 2
2023-03-30 14:12:58,060:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6300, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-30 14:12:58,060:INFO:create_model() successfully completed......................................
2023-03-30 14:12:58,219:INFO:SubProcess create_model() end ==================================
2023-03-30 14:12:58,219:INFO:Creating metrics dataframe
2023-03-30 14:12:58,230:INFO:Initializing Dummy Classifier
2023-03-30 14:12:58,231:INFO:Total runtime is 11.515904267628985 minutes
2023-03-30 14:12:58,233:INFO:SubProcess create_model() called ==================================
2023-03-30 14:12:58,233:INFO:Initializing create_model()
2023-03-30 14:12:58,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCBE466B20>, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:12:58,234:INFO:Checking exceptions
2023-03-30 14:12:58,234:INFO:Importing libraries
2023-03-30 14:12:58,234:INFO:Copying training dataset
2023-03-30 14:12:58,271:INFO:Defining folds
2023-03-30 14:12:58,271:INFO:Declaring metric variables
2023-03-30 14:12:58,284:INFO:Importing untrained model
2023-03-30 14:12:58,287:INFO:Dummy Classifier Imported successfully
2023-03-30 14:12:58,292:INFO:Starting cross validation
2023-03-30 14:12:58,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:12:58,541:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,556:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,603:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,667:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,667:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,698:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,708:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:58,777:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:59,028:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:12:59,060:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-30 14:13:00,066:INFO:Calculating mean and std
2023-03-30 14:13:00,066:INFO:Creating metrics dataframe
2023-03-30 14:13:00,180:INFO:Uploading results into container
2023-03-30 14:13:00,180:INFO:Uploading model into container now
2023-03-30 14:13:00,180:INFO:_master_model_container: 14
2023-03-30 14:13:00,180:INFO:_display_container: 2
2023-03-30 14:13:00,180:INFO:DummyClassifier(constant=None, random_state=6300, strategy='prior')
2023-03-30 14:13:00,180:INFO:create_model() successfully completed......................................
2023-03-30 14:13:00,312:INFO:SubProcess create_model() end ==================================
2023-03-30 14:13:00,312:INFO:Creating metrics dataframe
2023-03-30 14:13:00,339:INFO:Initializing create_model()
2023-03-30 14:13:00,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:13:00,339:INFO:Checking exceptions
2023-03-30 14:13:00,343:INFO:Importing libraries
2023-03-30 14:13:00,343:INFO:Copying training dataset
2023-03-30 14:13:00,388:INFO:Defining folds
2023-03-30 14:13:00,388:INFO:Declaring metric variables
2023-03-30 14:13:00,388:INFO:Importing untrained model
2023-03-30 14:13:00,388:INFO:Declaring custom model
2023-03-30 14:13:00,389:INFO:Random Forest Classifier Imported successfully
2023-03-30 14:13:00,389:INFO:Cross validation set to False
2023-03-30 14:13:00,389:INFO:Fitting Model
2023-03-30 14:13:03,401:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:13:03,401:INFO:create_model() successfully completed......................................
2023-03-30 14:13:03,595:INFO:_master_model_container: 14
2023-03-30 14:13:03,595:INFO:_display_container: 2
2023-03-30 14:13:03,596:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:13:03,596:INFO:compare_models() successfully completed......................................
2023-03-30 14:13:17,719:INFO:Initializing tune_model()
2023-03-30 14:13:17,719:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>)
2023-03-30 14:13:17,720:INFO:Checking exceptions
2023-03-30 14:13:17,756:INFO:Copying training dataset
2023-03-30 14:13:17,781:INFO:Checking base model
2023-03-30 14:13:17,781:INFO:Base model : Random Forest Classifier
2023-03-30 14:13:17,784:INFO:Declaring metric variables
2023-03-30 14:13:17,786:INFO:Defining Hyperparameters
2023-03-30 14:13:17,930:INFO:Tuning with n_jobs=-1
2023-03-30 14:13:17,930:INFO:Initializing RandomizedSearchCV
2023-03-30 14:13:22,500:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:22,672:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:22,844:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:23,439:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:23,464:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:27,281:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:29,533:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:30,769:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:37,414:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:38,181:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:38,228:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:38,934:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:39,090:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:39,825:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:39,892:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:40,014:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:40,076:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:41,344:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:42,095:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:42,533:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:44,051:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:44,396:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:46,445:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:47,009:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:48,997:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:51,691:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:51,988:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:52,245:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:53,193:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:54,194:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:54,883:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:13:55,274:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:13:55,916:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:06,308:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:06,324:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:07,170:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:07,874:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:07,968:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:08,906:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:09,000:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:09,080:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:10,255:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:12,087:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:13,856:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:19,725:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:20,930:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:21,806:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:23,260:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:23,605:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:24,793:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:25,952:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:26,593:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:27,281:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:28,204:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:28,921:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:29,171:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:30,605:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:31,736:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:32,831:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:34,832:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:36,100:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:36,648:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:41,455:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:43,131:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:43,325:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:44,067:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:45,748:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:50,992:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:52,570:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:52,836:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-30 14:14:53,133:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:14:54,431:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:15:04,275:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:15:08,440:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-30 14:15:11,361:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2023-03-30 14:15:11,361:INFO:Hyperparameter search completed
2023-03-30 14:15:11,361:INFO:SubProcess create_model() called ==================================
2023-03-30 14:15:11,361:INFO:Initializing create_model()
2023-03-30 14:15:11,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BCAD8B5A60>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 9, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2023-03-30 14:15:11,361:INFO:Checking exceptions
2023-03-30 14:15:11,361:INFO:Importing libraries
2023-03-30 14:15:11,361:INFO:Copying training dataset
2023-03-30 14:15:11,416:INFO:Defining folds
2023-03-30 14:15:11,417:INFO:Declaring metric variables
2023-03-30 14:15:11,420:INFO:Importing untrained model
2023-03-30 14:15:11,420:INFO:Declaring custom model
2023-03-30 14:15:11,426:INFO:Random Forest Classifier Imported successfully
2023-03-30 14:15:11,430:INFO:Starting cross validation
2023-03-30 14:15:11,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:15:14,123:INFO:Calculating mean and std
2023-03-30 14:15:14,123:INFO:Creating metrics dataframe
2023-03-30 14:15:14,123:INFO:Finalizing model
2023-03-30 14:15:15,662:INFO:Uploading results into container
2023-03-30 14:15:15,675:INFO:Uploading model into container now
2023-03-30 14:15:15,675:INFO:_master_model_container: 15
2023-03-30 14:15:15,675:INFO:_display_container: 3
2023-03-30 14:15:15,676:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:15:15,676:INFO:create_model() successfully completed......................................
2023-03-30 14:15:15,824:INFO:SubProcess create_model() end ==================================
2023-03-30 14:15:15,824:INFO:choose_better activated
2023-03-30 14:15:15,824:INFO:SubProcess create_model() called ==================================
2023-03-30 14:15:15,824:INFO:Initializing create_model()
2023-03-30 14:15:15,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-30 14:15:15,824:INFO:Checking exceptions
2023-03-30 14:15:15,824:INFO:Importing libraries
2023-03-30 14:15:15,824:INFO:Copying training dataset
2023-03-30 14:15:15,865:INFO:Defining folds
2023-03-30 14:15:15,865:INFO:Declaring metric variables
2023-03-30 14:15:15,865:INFO:Importing untrained model
2023-03-30 14:15:15,865:INFO:Declaring custom model
2023-03-30 14:15:15,865:INFO:Random Forest Classifier Imported successfully
2023-03-30 14:15:15,865:INFO:Starting cross validation
2023-03-30 14:15:15,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-30 14:15:20,886:INFO:Calculating mean and std
2023-03-30 14:15:20,886:INFO:Creating metrics dataframe
2023-03-30 14:15:20,886:INFO:Finalizing model
2023-03-30 14:15:21,293:INFO:Uploading results into container
2023-03-30 14:15:21,293:INFO:Uploading model into container now
2023-03-30 14:15:21,293:INFO:_master_model_container: 16
2023-03-30 14:15:21,293:INFO:_display_container: 4
2023-03-30 14:15:21,293:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:15:21,293:INFO:create_model() successfully completed......................................
2023-03-30 14:15:21,433:INFO:SubProcess create_model() end ==================================
2023-03-30 14:15:21,433:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False) result for Accuracy is 0.8624
2023-03-30 14:15:21,433:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=8, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=2,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False) result for Accuracy is 0.647
2023-03-30 14:15:21,433:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False) is best model
2023-03-30 14:15:21,433:INFO:choose_better completed
2023-03-30 14:15:21,433:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-03-30 14:15:21,454:INFO:_master_model_container: 16
2023-03-30 14:15:21,454:INFO:_display_container: 3
2023-03-30 14:15:21,455:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False)
2023-03-30 14:15:21,455:INFO:tune_model() successfully completed......................................
2023-03-30 14:15:28,100:INFO:Initializing plot_model()
2023-03-30 14:15:28,100:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6300, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BCBEF715B0>, system=True)
2023-03-30 14:15:28,100:INFO:Checking exceptions
2023-03-30 14:15:28,129:INFO:Preloading libraries
2023-03-30 14:15:28,281:INFO:Copying training dataset
2023-03-30 14:15:28,281:INFO:Plot type: confusion_matrix
2023-03-30 14:15:28,501:INFO:Fitting Model
2023-03-30 14:15:28,501:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-30 14:15:28,501:INFO:Scoring test/hold-out set
2023-03-30 14:15:28,984:INFO:Visual Rendered Successfully
2023-03-30 14:15:29,125:INFO:plot_model() successfully completed......................................
2023-03-31 16:13:45,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 16:13:45,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 16:13:45,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 16:13:45,367:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 16:13:47,165:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-31 16:14:28,717:INFO:PyCaret ClassificationExperiment
2023-03-31 16:14:28,717:INFO:Logging name: clf-default-name
2023-03-31 16:14:28,717:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-31 16:14:28,717:INFO:version 3.0.0
2023-03-31 16:14:28,717:INFO:Initializing setup()
2023-03-31 16:14:28,717:INFO:self.USI: 5dc4
2023-03-31 16:14:28,717:INFO:self._variable_keys: {'y', 'y_train', 'X', 'target_param', 'USI', 'fold_shuffle_param', 'n_jobs_param', 'X_train', 'seed', 'idx', 'y_test', 'html_param', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'is_multiclass', 'memory', 'data', 'X_test', 'exp_id', 'log_plots_param', 'exp_name_log', 'logging_param', '_ml_usecase', '_available_plots', 'gpu_n_jobs_param', 'fold_generator', 'pipeline'}
2023-03-31 16:14:28,717:INFO:Checking environment
2023-03-31 16:14:28,717:INFO:python_version: 3.9.12
2023-03-31 16:14:28,717:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-03-31 16:14:28,717:INFO:machine: AMD64
2023-03-31 16:14:28,717:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-31 16:14:28,717:INFO:Memory: svmem(total=8316030976, available=1164402688, percent=86.0, used=7151628288, free=1164402688)
2023-03-31 16:14:28,717:INFO:Physical Core: 4
2023-03-31 16:14:28,717:INFO:Logical Core: 8
2023-03-31 16:14:28,717:INFO:Checking libraries
2023-03-31 16:14:28,717:INFO:System:
2023-03-31 16:14:28,717:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-03-31 16:14:28,717:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-03-31 16:14:28,717:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-31 16:14:28,717:INFO:PyCaret required dependencies:
2023-03-31 16:14:28,717:INFO:                 pip: 21.2.4
2023-03-31 16:14:28,717:INFO:          setuptools: 61.2.0
2023-03-31 16:14:28,717:INFO:             pycaret: 3.0.0
2023-03-31 16:14:28,717:INFO:             IPython: 8.2.0
2023-03-31 16:14:28,717:INFO:          ipywidgets: 7.6.5
2023-03-31 16:14:28,717:INFO:                tqdm: 4.64.0
2023-03-31 16:14:28,717:INFO:               numpy: 1.21.6
2023-03-31 16:14:28,717:INFO:              pandas: 1.4.2
2023-03-31 16:14:28,717:INFO:              jinja2: 2.11.3
2023-03-31 16:14:28,717:INFO:               scipy: 1.7.3
2023-03-31 16:14:28,717:INFO:              joblib: 1.2.0
2023-03-31 16:14:28,717:INFO:             sklearn: 1.0.2
2023-03-31 16:14:28,717:INFO:                pyod: 1.0.9
2023-03-31 16:14:28,717:INFO:            imblearn: 0.10.1
2023-03-31 16:14:28,717:INFO:   category_encoders: 2.6.0
2023-03-31 16:14:28,717:INFO:            lightgbm: 3.3.5
2023-03-31 16:14:28,717:INFO:               numba: 0.55.1
2023-03-31 16:14:28,717:INFO:            requests: 2.27.1
2023-03-31 16:14:28,717:INFO:          matplotlib: 3.5.1
2023-03-31 16:14:28,717:INFO:          scikitplot: 0.3.7
2023-03-31 16:14:28,717:INFO:         yellowbrick: 1.5
2023-03-31 16:14:28,717:INFO:              plotly: 5.6.0
2023-03-31 16:14:28,717:INFO:             kaleido: 0.2.1
2023-03-31 16:14:28,717:INFO:         statsmodels: 0.13.2
2023-03-31 16:14:28,717:INFO:              sktime: 0.16.1
2023-03-31 16:14:28,717:INFO:               tbats: 1.1.2
2023-03-31 16:14:28,717:INFO:            pmdarima: 2.0.3
2023-03-31 16:14:28,717:INFO:              psutil: 5.9.4
2023-03-31 16:14:28,717:INFO:PyCaret optional dependencies:
2023-03-31 16:14:28,748:INFO:                shap: 0.41.0
2023-03-31 16:14:28,748:INFO:           interpret: Not installed
2023-03-31 16:14:28,748:INFO:                umap: Not installed
2023-03-31 16:14:28,748:INFO:    pandas_profiling: 4.1.2
2023-03-31 16:14:28,748:INFO:  explainerdashboard: Not installed
2023-03-31 16:14:28,748:INFO:             autoviz: Not installed
2023-03-31 16:14:28,748:INFO:           fairlearn: Not installed
2023-03-31 16:14:28,748:INFO:             xgboost: Not installed
2023-03-31 16:14:28,748:INFO:            catboost: Not installed
2023-03-31 16:14:28,748:INFO:              kmodes: Not installed
2023-03-31 16:14:28,748:INFO:             mlxtend: Not installed
2023-03-31 16:14:28,748:INFO:       statsforecast: Not installed
2023-03-31 16:14:28,752:INFO:        tune_sklearn: Not installed
2023-03-31 16:14:28,752:INFO:                 ray: Not installed
2023-03-31 16:14:28,752:INFO:            hyperopt: Not installed
2023-03-31 16:14:28,752:INFO:              optuna: Not installed
2023-03-31 16:14:28,752:INFO:               skopt: Not installed
2023-03-31 16:14:28,752:INFO:              mlflow: Not installed
2023-03-31 16:14:28,752:INFO:              gradio: Not installed
2023-03-31 16:14:28,752:INFO:             fastapi: Not installed
2023-03-31 16:14:28,752:INFO:             uvicorn: Not installed
2023-03-31 16:14:28,752:INFO:              m2cgen: Not installed
2023-03-31 16:14:28,752:INFO:           evidently: Not installed
2023-03-31 16:14:28,752:INFO:               fugue: Not installed
2023-03-31 16:14:28,752:INFO:           streamlit: Not installed
2023-03-31 16:14:28,752:INFO:             prophet: Not installed
2023-03-31 16:14:28,752:INFO:None
2023-03-31 16:14:28,752:INFO:Set up data.
2023-03-31 16:14:28,828:INFO:Set up train/test split.
2023-03-31 16:14:29,113:INFO:Set up index.
2023-03-31 16:14:29,113:INFO:Set up folding strategy.
2023-03-31 16:14:29,113:INFO:Assigning column types.
2023-03-31 16:14:29,192:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-31 16:14:29,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-31 16:14:29,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 16:14:29,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:29,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:29,618:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-31 16:14:29,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 16:14:29,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:29,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:29,666:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-31 16:14:29,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 16:14:29,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:29,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:29,996:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 16:14:30,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:30,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:30,074:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-31 16:14:30,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:30,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:30,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:30,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:30,501:INFO:Preparing preprocessing pipeline...
2023-03-31 16:14:30,532:INFO:Set up simple imputation.
2023-03-31 16:14:30,815:INFO:Finished creating preprocessing pipeline.
2023-03-31 16:14:30,831:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['MONTHS_BALANCE', 'DAYS_BIRTH',
                                             'DAYS_EMPLOYED',
                                             'AMT_INCOME_TOTAL',
                                             'OCCUPATION_TYPE'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-03-31 16:14:30,831:INFO:Creating final display dataframe.
2023-03-31 16:14:31,625:INFO:Setup _display_container:                     Description             Value
0                    Session id              4181
1                        Target            STATUS
2                   Target type            Binary
3           Original data shape       (365322, 6)
4        Transformed data shape       (365322, 6)
5   Transformed train set shape       (255725, 6)
6    Transformed test set shape       (109597, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5dc4
2023-03-31 16:14:31,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:31,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:32,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:32,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 16:14:32,048:INFO:setup() successfully completed in 4.31s...............
2023-03-31 16:14:32,069:INFO:Initializing compare_models()
2023-03-31 16:14:32,069:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-31 16:14:32,069:INFO:Checking exceptions
2023-03-31 16:14:32,142:INFO:Preparing display monitor
2023-03-31 16:14:32,237:INFO:Initializing Logistic Regression
2023-03-31 16:14:32,237:INFO:Total runtime is 0.0 minutes
2023-03-31 16:14:32,237:INFO:SubProcess create_model() called ==================================
2023-03-31 16:14:32,253:INFO:Initializing create_model()
2023-03-31 16:14:32,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:14:32,253:INFO:Checking exceptions
2023-03-31 16:14:32,253:INFO:Importing libraries
2023-03-31 16:14:32,253:INFO:Copying training dataset
2023-03-31 16:14:32,427:INFO:Defining folds
2023-03-31 16:14:32,427:INFO:Declaring metric variables
2023-03-31 16:14:32,427:INFO:Importing untrained model
2023-03-31 16:14:32,445:INFO:Logistic Regression Imported successfully
2023-03-31 16:14:32,445:INFO:Starting cross validation
2023-03-31 16:14:32,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:14:41,386:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,398:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,411:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,411:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,431:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,521:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:41,741:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:43,906:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:43,906:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:14:48,118:INFO:Calculating mean and std
2023-03-31 16:14:48,118:INFO:Creating metrics dataframe
2023-03-31 16:14:49,071:INFO:Uploading results into container
2023-03-31 16:14:49,071:INFO:Uploading model into container now
2023-03-31 16:14:49,071:INFO:_master_model_container: 1
2023-03-31 16:14:49,071:INFO:_display_container: 2
2023-03-31 16:14:49,087:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4181, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-31 16:14:49,087:INFO:create_model() successfully completed......................................
2023-03-31 16:14:49,748:INFO:SubProcess create_model() end ==================================
2023-03-31 16:14:49,748:INFO:Creating metrics dataframe
2023-03-31 16:14:49,764:INFO:Initializing K Neighbors Classifier
2023-03-31 16:14:49,764:INFO:Total runtime is 0.2921259005864461 minutes
2023-03-31 16:14:49,780:INFO:SubProcess create_model() called ==================================
2023-03-31 16:14:49,780:INFO:Initializing create_model()
2023-03-31 16:14:49,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:14:49,780:INFO:Checking exceptions
2023-03-31 16:14:49,780:INFO:Importing libraries
2023-03-31 16:14:49,780:INFO:Copying training dataset
2023-03-31 16:14:49,956:INFO:Defining folds
2023-03-31 16:14:49,956:INFO:Declaring metric variables
2023-03-31 16:14:49,971:INFO:Importing untrained model
2023-03-31 16:14:49,973:INFO:K Neighbors Classifier Imported successfully
2023-03-31 16:14:49,990:INFO:Starting cross validation
2023-03-31 16:14:49,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:15:06,937:INFO:Calculating mean and std
2023-03-31 16:15:06,937:INFO:Creating metrics dataframe
2023-03-31 16:15:07,876:INFO:Uploading results into container
2023-03-31 16:15:07,877:INFO:Uploading model into container now
2023-03-31 16:15:07,877:INFO:_master_model_container: 2
2023-03-31 16:15:07,879:INFO:_display_container: 2
2023-03-31 16:15:07,879:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 16:15:07,879:INFO:create_model() successfully completed......................................
2023-03-31 16:15:08,368:INFO:SubProcess create_model() end ==================================
2023-03-31 16:15:08,368:INFO:Creating metrics dataframe
2023-03-31 16:15:08,384:INFO:Initializing Naive Bayes
2023-03-31 16:15:08,384:INFO:Total runtime is 0.6024472792943318 minutes
2023-03-31 16:15:08,400:INFO:SubProcess create_model() called ==================================
2023-03-31 16:15:08,400:INFO:Initializing create_model()
2023-03-31 16:15:08,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:15:08,400:INFO:Checking exceptions
2023-03-31 16:15:08,400:INFO:Importing libraries
2023-03-31 16:15:08,400:INFO:Copying training dataset
2023-03-31 16:15:08,573:INFO:Defining folds
2023-03-31 16:15:08,573:INFO:Declaring metric variables
2023-03-31 16:15:08,584:INFO:Importing untrained model
2023-03-31 16:15:08,589:INFO:Naive Bayes Imported successfully
2023-03-31 16:15:08,606:INFO:Starting cross validation
2023-03-31 16:15:08,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:15:16,069:INFO:Calculating mean and std
2023-03-31 16:15:16,069:INFO:Creating metrics dataframe
2023-03-31 16:15:16,992:INFO:Uploading results into container
2023-03-31 16:15:16,992:INFO:Uploading model into container now
2023-03-31 16:15:16,992:INFO:_master_model_container: 3
2023-03-31 16:15:16,992:INFO:_display_container: 2
2023-03-31 16:15:16,992:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-31 16:15:16,992:INFO:create_model() successfully completed......................................
2023-03-31 16:15:17,418:INFO:SubProcess create_model() end ==================================
2023-03-31 16:15:17,418:INFO:Creating metrics dataframe
2023-03-31 16:15:17,434:INFO:Initializing Decision Tree Classifier
2023-03-31 16:15:17,450:INFO:Total runtime is 0.7535467545191447 minutes
2023-03-31 16:15:17,450:INFO:SubProcess create_model() called ==================================
2023-03-31 16:15:17,450:INFO:Initializing create_model()
2023-03-31 16:15:17,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:15:17,450:INFO:Checking exceptions
2023-03-31 16:15:17,450:INFO:Importing libraries
2023-03-31 16:15:17,450:INFO:Copying training dataset
2023-03-31 16:15:17,624:INFO:Defining folds
2023-03-31 16:15:17,624:INFO:Declaring metric variables
2023-03-31 16:15:17,625:INFO:Importing untrained model
2023-03-31 16:15:17,625:INFO:Decision Tree Classifier Imported successfully
2023-03-31 16:15:17,646:INFO:Starting cross validation
2023-03-31 16:15:17,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:15:28,603:INFO:Calculating mean and std
2023-03-31 16:15:28,603:INFO:Creating metrics dataframe
2023-03-31 16:15:29,599:INFO:Uploading results into container
2023-03-31 16:15:29,599:INFO:Uploading model into container now
2023-03-31 16:15:29,599:INFO:_master_model_container: 4
2023-03-31 16:15:29,599:INFO:_display_container: 2
2023-03-31 16:15:29,599:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4181, splitter='best')
2023-03-31 16:15:29,599:INFO:create_model() successfully completed......................................
2023-03-31 16:15:30,039:INFO:SubProcess create_model() end ==================================
2023-03-31 16:15:30,039:INFO:Creating metrics dataframe
2023-03-31 16:15:30,072:INFO:Initializing SVM - Linear Kernel
2023-03-31 16:15:30,072:INFO:Total runtime is 0.963918681939443 minutes
2023-03-31 16:15:30,072:INFO:SubProcess create_model() called ==================================
2023-03-31 16:15:30,072:INFO:Initializing create_model()
2023-03-31 16:15:30,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:15:30,072:INFO:Checking exceptions
2023-03-31 16:15:30,072:INFO:Importing libraries
2023-03-31 16:15:30,072:INFO:Copying training dataset
2023-03-31 16:15:30,244:INFO:Defining folds
2023-03-31 16:15:30,244:INFO:Declaring metric variables
2023-03-31 16:15:30,264:INFO:Importing untrained model
2023-03-31 16:15:30,265:INFO:SVM - Linear Kernel Imported successfully
2023-03-31 16:15:30,276:INFO:Starting cross validation
2023-03-31 16:15:30,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:16:03,299:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:03,331:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:04,678:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:04,709:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:10,292:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:10,339:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:11,592:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:11,640:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:11,640:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:11,687:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:13,726:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:13,757:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:15,344:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:15,375:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:16,603:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:16,635:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:30,863:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:34,832:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 16:16:34,863:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:35,021:INFO:Calculating mean and std
2023-03-31 16:16:35,021:INFO:Creating metrics dataframe
2023-03-31 16:16:36,166:INFO:Uploading results into container
2023-03-31 16:16:36,166:INFO:Uploading model into container now
2023-03-31 16:16:36,166:INFO:_master_model_container: 5
2023-03-31 16:16:36,166:INFO:_display_container: 2
2023-03-31 16:16:36,177:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4181, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-31 16:16:36,177:INFO:create_model() successfully completed......................................
2023-03-31 16:16:36,671:INFO:SubProcess create_model() end ==================================
2023-03-31 16:16:36,671:INFO:Creating metrics dataframe
2023-03-31 16:16:36,704:INFO:Initializing Ridge Classifier
2023-03-31 16:16:36,704:INFO:Total runtime is 2.074444345633189 minutes
2023-03-31 16:16:36,713:INFO:SubProcess create_model() called ==================================
2023-03-31 16:16:36,713:INFO:Initializing create_model()
2023-03-31 16:16:36,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:16:36,713:INFO:Checking exceptions
2023-03-31 16:16:36,713:INFO:Importing libraries
2023-03-31 16:16:36,713:INFO:Copying training dataset
2023-03-31 16:16:36,876:INFO:Defining folds
2023-03-31 16:16:36,876:INFO:Declaring metric variables
2023-03-31 16:16:36,891:INFO:Importing untrained model
2023-03-31 16:16:36,893:INFO:Ridge Classifier Imported successfully
2023-03-31 16:16:36,912:INFO:Starting cross validation
2023-03-31 16:16:36,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:16:37,697:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:37,697:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:37,728:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:37,744:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:37,791:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:37,837:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:37,869:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:37,916:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:37,916:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:37,963:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:38,010:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:38,041:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:38,072:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:38,119:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:38,119:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:38,167:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:39,663:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:39,695:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:39,727:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 16:16:39,774:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:16:45,253:INFO:Calculating mean and std
2023-03-31 16:16:45,253:INFO:Creating metrics dataframe
2023-03-31 16:16:46,332:INFO:Uploading results into container
2023-03-31 16:16:46,332:INFO:Uploading model into container now
2023-03-31 16:16:46,332:INFO:_master_model_container: 6
2023-03-31 16:16:46,332:INFO:_display_container: 2
2023-03-31 16:16:46,332:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=4181, solver='auto', tol=0.001)
2023-03-31 16:16:46,332:INFO:create_model() successfully completed......................................
2023-03-31 16:16:46,647:INFO:SubProcess create_model() end ==================================
2023-03-31 16:16:46,647:INFO:Creating metrics dataframe
2023-03-31 16:16:46,647:INFO:Initializing Random Forest Classifier
2023-03-31 16:16:46,647:INFO:Total runtime is 2.2401750802993776 minutes
2023-03-31 16:16:46,663:INFO:SubProcess create_model() called ==================================
2023-03-31 16:16:46,663:INFO:Initializing create_model()
2023-03-31 16:16:46,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:16:46,663:INFO:Checking exceptions
2023-03-31 16:16:46,663:INFO:Importing libraries
2023-03-31 16:16:46,663:INFO:Copying training dataset
2023-03-31 16:16:46,804:INFO:Defining folds
2023-03-31 16:16:46,804:INFO:Declaring metric variables
2023-03-31 16:16:46,804:INFO:Importing untrained model
2023-03-31 16:16:46,820:INFO:Random Forest Classifier Imported successfully
2023-03-31 16:16:46,836:INFO:Starting cross validation
2023-03-31 16:16:46,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:18:47,220:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:48,070:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:48,331:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:48,706:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:18:53,932:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:54,277:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:54,308:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:54,663:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:54,919:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:18:55,595:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:18:56,563:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:18:56,585:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:19:35,627:INFO:Calculating mean and std
2023-03-31 16:19:35,801:INFO:Creating metrics dataframe
2023-03-31 16:19:37,056:INFO:Uploading results into container
2023-03-31 16:19:37,072:INFO:Uploading model into container now
2023-03-31 16:19:37,072:INFO:_master_model_container: 7
2023-03-31 16:19:37,072:INFO:_display_container: 2
2023-03-31 16:19:37,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4181, verbose=0, warm_start=False)
2023-03-31 16:19:37,104:INFO:create_model() successfully completed......................................
2023-03-31 16:19:39,552:INFO:SubProcess create_model() end ==================================
2023-03-31 16:19:39,552:INFO:Creating metrics dataframe
2023-03-31 16:19:39,599:INFO:Initializing Quadratic Discriminant Analysis
2023-03-31 16:19:39,599:INFO:Total runtime is 5.122709739208222 minutes
2023-03-31 16:19:39,615:INFO:SubProcess create_model() called ==================================
2023-03-31 16:19:39,615:INFO:Initializing create_model()
2023-03-31 16:19:39,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:19:39,615:INFO:Checking exceptions
2023-03-31 16:19:39,615:INFO:Importing libraries
2023-03-31 16:19:39,615:INFO:Copying training dataset
2023-03-31 16:19:39,868:INFO:Defining folds
2023-03-31 16:19:39,868:INFO:Declaring metric variables
2023-03-31 16:19:39,868:INFO:Importing untrained model
2023-03-31 16:19:39,883:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-31 16:19:39,899:INFO:Starting cross validation
2023-03-31 16:19:39,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:19:47,854:INFO:Calculating mean and std
2023-03-31 16:19:47,857:INFO:Creating metrics dataframe
2023-03-31 16:19:48,825:INFO:Uploading results into container
2023-03-31 16:19:48,825:INFO:Uploading model into container now
2023-03-31 16:19:48,841:INFO:_master_model_container: 8
2023-03-31 16:19:48,841:INFO:_display_container: 2
2023-03-31 16:19:48,841:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-31 16:19:48,841:INFO:create_model() successfully completed......................................
2023-03-31 16:19:49,284:INFO:SubProcess create_model() end ==================================
2023-03-31 16:19:49,284:INFO:Creating metrics dataframe
2023-03-31 16:19:49,332:INFO:Initializing Ada Boost Classifier
2023-03-31 16:19:49,332:INFO:Total runtime is 5.284910515944164 minutes
2023-03-31 16:19:49,332:INFO:SubProcess create_model() called ==================================
2023-03-31 16:19:49,332:INFO:Initializing create_model()
2023-03-31 16:19:49,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:19:49,332:INFO:Checking exceptions
2023-03-31 16:19:49,332:INFO:Importing libraries
2023-03-31 16:19:49,332:INFO:Copying training dataset
2023-03-31 16:19:49,522:INFO:Defining folds
2023-03-31 16:19:49,522:INFO:Declaring metric variables
2023-03-31 16:19:49,522:INFO:Importing untrained model
2023-03-31 16:19:49,531:INFO:Ada Boost Classifier Imported successfully
2023-03-31 16:19:49,548:INFO:Starting cross validation
2023-03-31 16:19:49,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:20:27,694:INFO:Calculating mean and std
2023-03-31 16:20:27,694:INFO:Creating metrics dataframe
2023-03-31 16:20:28,727:INFO:Uploading results into container
2023-03-31 16:20:28,743:INFO:Uploading model into container now
2023-03-31 16:20:28,743:INFO:_master_model_container: 9
2023-03-31 16:20:28,743:INFO:_display_container: 2
2023-03-31 16:20:28,743:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4181)
2023-03-31 16:20:28,743:INFO:create_model() successfully completed......................................
2023-03-31 16:20:29,246:INFO:SubProcess create_model() end ==================================
2023-03-31 16:20:29,246:INFO:Creating metrics dataframe
2023-03-31 16:20:29,278:INFO:Initializing Gradient Boosting Classifier
2023-03-31 16:20:29,293:INFO:Total runtime is 5.950942114988964 minutes
2023-03-31 16:20:29,293:INFO:SubProcess create_model() called ==================================
2023-03-31 16:20:29,293:INFO:Initializing create_model()
2023-03-31 16:20:29,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:20:29,293:INFO:Checking exceptions
2023-03-31 16:20:29,293:INFO:Importing libraries
2023-03-31 16:20:29,293:INFO:Copying training dataset
2023-03-31 16:20:29,467:INFO:Defining folds
2023-03-31 16:20:29,467:INFO:Declaring metric variables
2023-03-31 16:20:29,473:INFO:Importing untrained model
2023-03-31 16:20:29,484:INFO:Gradient Boosting Classifier Imported successfully
2023-03-31 16:20:29,499:INFO:Starting cross validation
2023-03-31 16:20:29,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:22:29,709:INFO:Calculating mean and std
2023-03-31 16:22:29,709:INFO:Creating metrics dataframe
2023-03-31 16:22:30,851:INFO:Uploading results into container
2023-03-31 16:22:30,851:INFO:Uploading model into container now
2023-03-31 16:22:30,851:INFO:_master_model_container: 10
2023-03-31 16:22:30,851:INFO:_display_container: 2
2023-03-31 16:22:30,851:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4181, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-31 16:22:30,851:INFO:create_model() successfully completed......................................
2023-03-31 16:22:31,368:INFO:SubProcess create_model() end ==================================
2023-03-31 16:22:31,368:INFO:Creating metrics dataframe
2023-03-31 16:22:31,400:INFO:Initializing Linear Discriminant Analysis
2023-03-31 16:22:31,400:INFO:Total runtime is 7.986051579316458 minutes
2023-03-31 16:22:31,400:INFO:SubProcess create_model() called ==================================
2023-03-31 16:22:31,400:INFO:Initializing create_model()
2023-03-31 16:22:31,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:22:31,400:INFO:Checking exceptions
2023-03-31 16:22:31,400:INFO:Importing libraries
2023-03-31 16:22:31,400:INFO:Copying training dataset
2023-03-31 16:22:31,572:INFO:Defining folds
2023-03-31 16:22:31,572:INFO:Declaring metric variables
2023-03-31 16:22:31,588:INFO:Importing untrained model
2023-03-31 16:22:31,589:INFO:Linear Discriminant Analysis Imported successfully
2023-03-31 16:22:31,605:INFO:Starting cross validation
2023-03-31 16:22:31,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:22:33,001:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,001:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,111:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,189:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,251:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,251:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,362:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:33,393:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:35,432:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:35,432:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:22:41,436:INFO:Calculating mean and std
2023-03-31 16:22:41,436:INFO:Creating metrics dataframe
2023-03-31 16:22:42,396:INFO:Uploading results into container
2023-03-31 16:22:42,404:INFO:Uploading model into container now
2023-03-31 16:22:42,404:INFO:_master_model_container: 11
2023-03-31 16:22:42,404:INFO:_display_container: 2
2023-03-31 16:22:42,404:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-31 16:22:42,404:INFO:create_model() successfully completed......................................
2023-03-31 16:22:42,776:INFO:SubProcess create_model() end ==================================
2023-03-31 16:22:42,776:INFO:Creating metrics dataframe
2023-03-31 16:22:42,811:INFO:Initializing Extra Trees Classifier
2023-03-31 16:22:42,811:INFO:Total runtime is 8.176231527328492 minutes
2023-03-31 16:22:42,811:INFO:SubProcess create_model() called ==================================
2023-03-31 16:22:42,811:INFO:Initializing create_model()
2023-03-31 16:22:42,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:22:42,811:INFO:Checking exceptions
2023-03-31 16:22:42,811:INFO:Importing libraries
2023-03-31 16:22:42,811:INFO:Copying training dataset
2023-03-31 16:22:43,006:INFO:Defining folds
2023-03-31 16:22:43,006:INFO:Declaring metric variables
2023-03-31 16:22:43,015:INFO:Importing untrained model
2023-03-31 16:22:43,023:INFO:Extra Trees Classifier Imported successfully
2023-03-31 16:22:43,039:INFO:Starting cross validation
2023-03-31 16:22:43,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:24:38,428:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 24.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:39,982:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 27.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:40,545:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 26.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:42,384:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 27.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:43,473:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:44,546:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 30.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:47,143:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:24:47,656:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 29.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:25:14,352:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 15.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:25:21,882:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 20.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:25:25,491:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 23.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:25:28,554:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 25.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:25:31,184:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 27.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:25:43,310:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 38.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:25:43,334:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 34.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:26:03,861:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:26:05,029:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 53.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 16:26:29,278:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:26:31,046:INFO:Calculating mean and std
2023-03-31 16:26:31,204:INFO:Creating metrics dataframe
2023-03-31 16:26:32,251:INFO:Uploading results into container
2023-03-31 16:26:32,271:INFO:Uploading model into container now
2023-03-31 16:26:32,283:INFO:_master_model_container: 12
2023-03-31 16:26:32,283:INFO:_display_container: 2
2023-03-31 16:26:32,283:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4181, verbose=0, warm_start=False)
2023-03-31 16:26:32,283:INFO:create_model() successfully completed......................................
2023-03-31 16:26:35,037:INFO:SubProcess create_model() end ==================================
2023-03-31 16:26:35,037:INFO:Creating metrics dataframe
2023-03-31 16:26:35,085:INFO:Initializing Light Gradient Boosting Machine
2023-03-31 16:26:35,085:INFO:Total runtime is 12.04746019045512 minutes
2023-03-31 16:26:35,094:INFO:SubProcess create_model() called ==================================
2023-03-31 16:26:35,094:INFO:Initializing create_model()
2023-03-31 16:26:35,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:26:35,094:INFO:Checking exceptions
2023-03-31 16:26:35,094:INFO:Importing libraries
2023-03-31 16:26:35,100:INFO:Copying training dataset
2023-03-31 16:26:35,370:INFO:Defining folds
2023-03-31 16:26:35,370:INFO:Declaring metric variables
2023-03-31 16:26:35,389:INFO:Importing untrained model
2023-03-31 16:26:35,402:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-31 16:26:35,417:INFO:Starting cross validation
2023-03-31 16:26:35,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:26:49,773:INFO:Calculating mean and std
2023-03-31 16:26:49,773:INFO:Creating metrics dataframe
2023-03-31 16:26:50,568:INFO:Uploading results into container
2023-03-31 16:26:50,568:INFO:Uploading model into container now
2023-03-31 16:26:50,568:INFO:_master_model_container: 13
2023-03-31 16:26:50,568:INFO:_display_container: 2
2023-03-31 16:26:50,568:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4181, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-31 16:26:50,568:INFO:create_model() successfully completed......................................
2023-03-31 16:26:51,108:INFO:SubProcess create_model() end ==================================
2023-03-31 16:26:51,108:INFO:Creating metrics dataframe
2023-03-31 16:26:51,140:INFO:Initializing Dummy Classifier
2023-03-31 16:26:51,140:INFO:Total runtime is 12.31504887342453 minutes
2023-03-31 16:26:51,155:INFO:SubProcess create_model() called ==================================
2023-03-31 16:26:51,155:INFO:Initializing create_model()
2023-03-31 16:26:51,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BB827EBD30>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:26:51,155:INFO:Checking exceptions
2023-03-31 16:26:51,155:INFO:Importing libraries
2023-03-31 16:26:51,155:INFO:Copying training dataset
2023-03-31 16:26:51,329:INFO:Defining folds
2023-03-31 16:26:51,329:INFO:Declaring metric variables
2023-03-31 16:26:51,329:INFO:Importing untrained model
2023-03-31 16:26:51,345:INFO:Dummy Classifier Imported successfully
2023-03-31 16:26:51,363:INFO:Starting cross validation
2023-03-31 16:26:51,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:26:51,951:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:51,995:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:52,090:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:52,121:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:52,169:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:52,216:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:52,278:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:52,310:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:53,457:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:53,520:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 16:26:57,696:INFO:Calculating mean and std
2023-03-31 16:26:57,696:INFO:Creating metrics dataframe
2023-03-31 16:26:58,455:INFO:Uploading results into container
2023-03-31 16:26:58,471:INFO:Uploading model into container now
2023-03-31 16:26:58,472:INFO:_master_model_container: 14
2023-03-31 16:26:58,472:INFO:_display_container: 2
2023-03-31 16:26:58,472:INFO:DummyClassifier(constant=None, random_state=4181, strategy='prior')
2023-03-31 16:26:58,472:INFO:create_model() successfully completed......................................
2023-03-31 16:26:58,772:INFO:SubProcess create_model() end ==================================
2023-03-31 16:26:58,772:INFO:Creating metrics dataframe
2023-03-31 16:26:58,821:INFO:Initializing create_model()
2023-03-31 16:26:58,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:26:58,821:INFO:Checking exceptions
2023-03-31 16:26:58,821:INFO:Importing libraries
2023-03-31 16:26:58,836:INFO:Copying training dataset
2023-03-31 16:26:58,993:INFO:Defining folds
2023-03-31 16:26:58,993:INFO:Declaring metric variables
2023-03-31 16:26:58,993:INFO:Importing untrained model
2023-03-31 16:26:58,993:INFO:Declaring custom model
2023-03-31 16:26:58,993:INFO:K Neighbors Classifier Imported successfully
2023-03-31 16:26:59,009:INFO:Cross validation set to False
2023-03-31 16:26:59,009:INFO:Fitting Model
2023-03-31 16:27:00,509:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 16:27:00,509:INFO:create_model() successfully completed......................................
2023-03-31 16:27:01,048:INFO:_master_model_container: 14
2023-03-31 16:27:01,048:INFO:_display_container: 2
2023-03-31 16:27:01,052:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 16:27:01,052:INFO:compare_models() successfully completed......................................
2023-03-31 16:27:01,077:INFO:Initializing tune_model()
2023-03-31 16:27:01,077:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>)
2023-03-31 16:27:01,077:INFO:Checking exceptions
2023-03-31 16:27:01,203:INFO:Copying training dataset
2023-03-31 16:27:01,331:INFO:Checking base model
2023-03-31 16:27:01,331:INFO:Base model : K Neighbors Classifier
2023-03-31 16:27:01,331:INFO:Declaring metric variables
2023-03-31 16:27:01,331:INFO:Defining Hyperparameters
2023-03-31 16:27:01,791:INFO:Tuning with n_jobs=-1
2023-03-31 16:27:01,791:INFO:Initializing RandomizedSearchCV
2023-03-31 16:29:05,699:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 24, 'actual_estimator__metric': 'minkowski'}
2023-03-31 16:29:05,699:INFO:Hyperparameter search completed
2023-03-31 16:29:05,699:INFO:SubProcess create_model() called ==================================
2023-03-31 16:29:05,699:INFO:Initializing create_model()
2023-03-31 16:29:05,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BC0B9319D0>, model_only=True, return_train_score=False, kwargs={'weights': 'uniform', 'n_neighbors': 24, 'metric': 'minkowski'})
2023-03-31 16:29:05,699:INFO:Checking exceptions
2023-03-31 16:29:05,699:INFO:Importing libraries
2023-03-31 16:29:05,699:INFO:Copying training dataset
2023-03-31 16:29:05,873:INFO:Defining folds
2023-03-31 16:29:05,873:INFO:Declaring metric variables
2023-03-31 16:29:05,873:INFO:Importing untrained model
2023-03-31 16:29:05,873:INFO:Declaring custom model
2023-03-31 16:29:05,889:INFO:K Neighbors Classifier Imported successfully
2023-03-31 16:29:05,905:INFO:Starting cross validation
2023-03-31 16:29:05,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:29:23,431:INFO:Calculating mean and std
2023-03-31 16:29:23,431:INFO:Creating metrics dataframe
2023-03-31 16:29:23,447:INFO:Finalizing model
2023-03-31 16:29:25,432:INFO:Uploading results into container
2023-03-31 16:29:25,434:INFO:Uploading model into container now
2023-03-31 16:29:25,436:INFO:_master_model_container: 15
2023-03-31 16:29:25,436:INFO:_display_container: 3
2023-03-31 16:29:25,436:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=24, p=2,
                     weights='uniform')
2023-03-31 16:29:25,436:INFO:create_model() successfully completed......................................
2023-03-31 16:29:25,930:INFO:SubProcess create_model() end ==================================
2023-03-31 16:29:25,930:INFO:choose_better activated
2023-03-31 16:29:25,946:INFO:SubProcess create_model() called ==================================
2023-03-31 16:29:25,946:INFO:Initializing create_model()
2023-03-31 16:29:25,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-31 16:29:25,946:INFO:Checking exceptions
2023-03-31 16:29:25,946:INFO:Importing libraries
2023-03-31 16:29:25,946:INFO:Copying training dataset
2023-03-31 16:29:26,153:INFO:Defining folds
2023-03-31 16:29:26,153:INFO:Declaring metric variables
2023-03-31 16:29:26,153:INFO:Importing untrained model
2023-03-31 16:29:26,153:INFO:Declaring custom model
2023-03-31 16:29:26,153:INFO:K Neighbors Classifier Imported successfully
2023-03-31 16:29:26,153:INFO:Starting cross validation
2023-03-31 16:29:26,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 16:29:40,365:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 16:29:45,314:INFO:Calculating mean and std
2023-03-31 16:29:45,314:INFO:Creating metrics dataframe
2023-03-31 16:29:45,314:INFO:Finalizing model
2023-03-31 16:29:46,503:INFO:Uploading results into container
2023-03-31 16:29:46,504:INFO:Uploading model into container now
2023-03-31 16:29:46,504:INFO:_master_model_container: 16
2023-03-31 16:29:46,504:INFO:_display_container: 4
2023-03-31 16:29:46,504:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 16:29:46,504:INFO:create_model() successfully completed......................................
2023-03-31 16:29:46,961:INFO:SubProcess create_model() end ==================================
2023-03-31 16:29:46,964:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for Accuracy is 0.8467
2023-03-31 16:29:46,964:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=24, p=2,
                     weights='uniform') result for Accuracy is 0.8574
2023-03-31 16:29:46,964:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=24, p=2,
                     weights='uniform') is best model
2023-03-31 16:29:46,964:INFO:choose_better completed
2023-03-31 16:29:46,993:INFO:_master_model_container: 16
2023-03-31 16:29:46,993:INFO:_display_container: 3
2023-03-31 16:29:46,993:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=24, p=2,
                     weights='uniform')
2023-03-31 16:29:46,993:INFO:tune_model() successfully completed......................................
2023-03-31 16:29:48,143:INFO:Initializing plot_model()
2023-03-31 16:29:48,143:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=24, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BB827EBB50>, system=True)
2023-03-31 16:29:48,143:INFO:Checking exceptions
2023-03-31 16:29:48,206:INFO:Preloading libraries
2023-03-31 16:29:48,222:INFO:Copying training dataset
2023-03-31 16:29:48,222:INFO:Plot type: confusion_matrix
2023-03-31 16:29:48,966:INFO:Fitting Model
2023-03-31 16:29:48,982:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(

2023-03-31 16:29:48,982:INFO:Scoring test/hold-out set
2023-03-31 16:30:04,685:INFO:Visual Rendered Successfully
2023-03-31 16:30:05,124:INFO:plot_model() successfully completed......................................
2023-03-31 21:04:32,437:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 21:04:32,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 21:04:32,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 21:04:32,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-31 21:04:33,264:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-31 21:04:36,225:INFO:PyCaret ClassificationExperiment
2023-03-31 21:04:36,225:INFO:Logging name: clf-default-name
2023-03-31 21:04:36,225:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-31 21:04:36,225:INFO:version 3.0.0
2023-03-31 21:04:36,225:INFO:Initializing setup()
2023-03-31 21:04:36,225:INFO:self.USI: 70a7
2023-03-31 21:04:36,225:INFO:self._variable_keys: {'y', 'log_plots_param', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'exp_id', 'idx', 'memory', 'logging_param', 'X', 'n_jobs_param', 'target_param', 'gpu_param', 'X_train', '_ml_usecase', 'fold_groups_param', 'X_test', 'fix_imbalance', 'data', '_available_plots', 'pipeline', 'USI', 'fold_generator', 'y_test', 'is_multiclass', 'exp_name_log', 'html_param', 'y_train'}
2023-03-31 21:04:36,225:INFO:Checking environment
2023-03-31 21:04:36,225:INFO:python_version: 3.9.12
2023-03-31 21:04:36,225:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-03-31 21:04:36,225:INFO:machine: AMD64
2023-03-31 21:04:36,225:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-31 21:04:36,225:INFO:Memory: svmem(total=8316030976, available=507453440, percent=93.9, used=7808577536, free=507453440)
2023-03-31 21:04:36,225:INFO:Physical Core: 4
2023-03-31 21:04:36,225:INFO:Logical Core: 8
2023-03-31 21:04:36,225:INFO:Checking libraries
2023-03-31 21:04:36,225:INFO:System:
2023-03-31 21:04:36,225:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-03-31 21:04:36,225:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-03-31 21:04:36,225:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-31 21:04:36,225:INFO:PyCaret required dependencies:
2023-03-31 21:04:36,225:INFO:                 pip: 21.2.4
2023-03-31 21:04:36,225:INFO:          setuptools: 61.2.0
2023-03-31 21:04:36,225:INFO:             pycaret: 3.0.0
2023-03-31 21:04:36,225:INFO:             IPython: 8.2.0
2023-03-31 21:04:36,225:INFO:          ipywidgets: 7.6.5
2023-03-31 21:04:36,225:INFO:                tqdm: 4.64.0
2023-03-31 21:04:36,225:INFO:               numpy: 1.21.6
2023-03-31 21:04:36,225:INFO:              pandas: 1.4.2
2023-03-31 21:04:36,225:INFO:              jinja2: 2.11.3
2023-03-31 21:04:36,225:INFO:               scipy: 1.7.3
2023-03-31 21:04:36,225:INFO:              joblib: 1.2.0
2023-03-31 21:04:36,225:INFO:             sklearn: 1.0.2
2023-03-31 21:04:36,225:INFO:                pyod: 1.0.9
2023-03-31 21:04:36,225:INFO:            imblearn: 0.10.1
2023-03-31 21:04:36,225:INFO:   category_encoders: 2.6.0
2023-03-31 21:04:36,225:INFO:            lightgbm: 3.3.5
2023-03-31 21:04:36,225:INFO:               numba: 0.55.1
2023-03-31 21:04:36,225:INFO:            requests: 2.27.1
2023-03-31 21:04:36,225:INFO:          matplotlib: 3.5.1
2023-03-31 21:04:36,225:INFO:          scikitplot: 0.3.7
2023-03-31 21:04:36,225:INFO:         yellowbrick: 1.5
2023-03-31 21:04:36,225:INFO:              plotly: 5.6.0
2023-03-31 21:04:36,225:INFO:             kaleido: 0.2.1
2023-03-31 21:04:36,225:INFO:         statsmodels: 0.13.2
2023-03-31 21:04:36,225:INFO:              sktime: 0.16.1
2023-03-31 21:04:36,225:INFO:               tbats: 1.1.2
2023-03-31 21:04:36,225:INFO:            pmdarima: 2.0.3
2023-03-31 21:04:36,225:INFO:              psutil: 5.9.4
2023-03-31 21:04:36,225:INFO:PyCaret optional dependencies:
2023-03-31 21:04:36,240:INFO:                shap: 0.41.0
2023-03-31 21:04:36,240:INFO:           interpret: Not installed
2023-03-31 21:04:36,240:INFO:                umap: Not installed
2023-03-31 21:04:36,240:INFO:    pandas_profiling: 4.1.2
2023-03-31 21:04:36,240:INFO:  explainerdashboard: Not installed
2023-03-31 21:04:36,240:INFO:             autoviz: Not installed
2023-03-31 21:04:36,240:INFO:           fairlearn: Not installed
2023-03-31 21:04:36,240:INFO:             xgboost: Not installed
2023-03-31 21:04:36,240:INFO:            catboost: Not installed
2023-03-31 21:04:36,240:INFO:              kmodes: Not installed
2023-03-31 21:04:36,240:INFO:             mlxtend: Not installed
2023-03-31 21:04:36,240:INFO:       statsforecast: Not installed
2023-03-31 21:04:36,240:INFO:        tune_sklearn: Not installed
2023-03-31 21:04:36,240:INFO:                 ray: Not installed
2023-03-31 21:04:36,240:INFO:            hyperopt: Not installed
2023-03-31 21:04:36,240:INFO:              optuna: Not installed
2023-03-31 21:04:36,240:INFO:               skopt: Not installed
2023-03-31 21:04:36,240:INFO:              mlflow: Not installed
2023-03-31 21:04:36,240:INFO:              gradio: Not installed
2023-03-31 21:04:36,240:INFO:             fastapi: Not installed
2023-03-31 21:04:36,240:INFO:             uvicorn: Not installed
2023-03-31 21:04:36,240:INFO:              m2cgen: Not installed
2023-03-31 21:04:36,240:INFO:           evidently: Not installed
2023-03-31 21:04:36,240:INFO:               fugue: Not installed
2023-03-31 21:04:36,240:INFO:           streamlit: Not installed
2023-03-31 21:04:36,240:INFO:             prophet: Not installed
2023-03-31 21:04:36,240:INFO:None
2023-03-31 21:04:36,240:INFO:Set up data.
2023-03-31 21:04:36,271:INFO:Set up train/test split.
2023-03-31 21:04:36,433:INFO:Set up index.
2023-03-31 21:04:36,434:INFO:Set up folding strategy.
2023-03-31 21:04:36,434:INFO:Assigning column types.
2023-03-31 21:04:36,456:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-31 21:04:36,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-31 21:04:36,506:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 21:04:36,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,643:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-31 21:04:36,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 21:04:36,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,676:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-31 21:04:36,740:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 21:04:36,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-31 21:04:36,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,859:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-31 21:04:36,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:36,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,099:INFO:Preparing preprocessing pipeline...
2023-03-31 21:04:37,115:INFO:Set up simple imputation.
2023-03-31 21:04:37,271:INFO:Finished creating preprocessing pipeline.
2023-03-31 21:04:37,287:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['MONTHS_BALANCE', 'DAYS_BIRTH',
                                             'DAYS_EMPLOYED',
                                             'AMT_INCOME_TOTAL',
                                             'OCCUPATION_TYPE'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-03-31 21:04:37,287:INFO:Creating final display dataframe.
2023-03-31 21:04:37,693:INFO:Setup _display_container:                     Description             Value
0                    Session id              6110
1                        Target            STATUS
2                   Target type            Binary
3           Original data shape       (365322, 6)
4        Transformed data shape       (365322, 6)
5   Transformed train set shape       (255725, 6)
6    Transformed test set shape       (109597, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              70a7
2023-03-31 21:04:37,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-31 21:04:37,850:INFO:setup() successfully completed in 2.44s...............
2023-03-31 21:04:40,543:INFO:Initializing compare_models()
2023-03-31 21:04:40,544:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-31 21:04:40,544:INFO:Checking exceptions
2023-03-31 21:04:40,595:INFO:Preparing display monitor
2023-03-31 21:04:40,622:INFO:Initializing Logistic Regression
2023-03-31 21:04:40,622:INFO:Total runtime is 0.0 minutes
2023-03-31 21:04:40,622:INFO:SubProcess create_model() called ==================================
2023-03-31 21:04:40,622:INFO:Initializing create_model()
2023-03-31 21:04:40,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:04:40,622:INFO:Checking exceptions
2023-03-31 21:04:40,622:INFO:Importing libraries
2023-03-31 21:04:40,622:INFO:Copying training dataset
2023-03-31 21:04:40,706:INFO:Defining folds
2023-03-31 21:04:40,706:INFO:Declaring metric variables
2023-03-31 21:04:40,706:INFO:Importing untrained model
2023-03-31 21:04:40,706:INFO:Logistic Regression Imported successfully
2023-03-31 21:04:40,725:INFO:Starting cross validation
2023-03-31 21:04:40,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:04:49,402:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,402:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,415:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,513:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,519:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,550:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,566:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:49,619:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:50,790:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:50,821:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:04:52,638:INFO:Calculating mean and std
2023-03-31 21:04:52,638:INFO:Creating metrics dataframe
2023-03-31 21:04:53,128:INFO:Uploading results into container
2023-03-31 21:04:53,144:INFO:Uploading model into container now
2023-03-31 21:04:53,144:INFO:_master_model_container: 1
2023-03-31 21:04:53,144:INFO:_display_container: 2
2023-03-31 21:04:53,144:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-31 21:04:53,144:INFO:create_model() successfully completed......................................
2023-03-31 21:04:53,361:INFO:SubProcess create_model() end ==================================
2023-03-31 21:04:53,361:INFO:Creating metrics dataframe
2023-03-31 21:04:53,377:INFO:Initializing K Neighbors Classifier
2023-03-31 21:04:53,377:INFO:Total runtime is 0.21257654031117756 minutes
2023-03-31 21:04:53,377:INFO:SubProcess create_model() called ==================================
2023-03-31 21:04:53,377:INFO:Initializing create_model()
2023-03-31 21:04:53,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:04:53,377:INFO:Checking exceptions
2023-03-31 21:04:53,377:INFO:Importing libraries
2023-03-31 21:04:53,377:INFO:Copying training dataset
2023-03-31 21:04:53,503:INFO:Defining folds
2023-03-31 21:04:53,503:INFO:Declaring metric variables
2023-03-31 21:04:53,508:INFO:Importing untrained model
2023-03-31 21:04:53,511:INFO:K Neighbors Classifier Imported successfully
2023-03-31 21:04:53,524:INFO:Starting cross validation
2023-03-31 21:04:53,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:05:01,965:INFO:Calculating mean and std
2023-03-31 21:05:01,965:INFO:Creating metrics dataframe
2023-03-31 21:05:02,414:INFO:Uploading results into container
2023-03-31 21:05:02,429:INFO:Uploading model into container now
2023-03-31 21:05:02,429:INFO:_master_model_container: 2
2023-03-31 21:05:02,429:INFO:_display_container: 2
2023-03-31 21:05:02,429:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 21:05:02,429:INFO:create_model() successfully completed......................................
2023-03-31 21:05:02,614:INFO:SubProcess create_model() end ==================================
2023-03-31 21:05:02,614:INFO:Creating metrics dataframe
2023-03-31 21:05:02,630:INFO:Initializing Naive Bayes
2023-03-31 21:05:02,630:INFO:Total runtime is 0.36679574648539226 minutes
2023-03-31 21:05:02,630:INFO:SubProcess create_model() called ==================================
2023-03-31 21:05:02,646:INFO:Initializing create_model()
2023-03-31 21:05:02,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:05:02,647:INFO:Checking exceptions
2023-03-31 21:05:02,647:INFO:Importing libraries
2023-03-31 21:05:02,647:INFO:Copying training dataset
2023-03-31 21:05:02,738:INFO:Defining folds
2023-03-31 21:05:02,738:INFO:Declaring metric variables
2023-03-31 21:05:02,754:INFO:Importing untrained model
2023-03-31 21:05:02,755:INFO:Naive Bayes Imported successfully
2023-03-31 21:05:02,755:INFO:Starting cross validation
2023-03-31 21:05:02,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:05:06,332:INFO:Calculating mean and std
2023-03-31 21:05:06,332:INFO:Creating metrics dataframe
2023-03-31 21:05:06,673:INFO:Uploading results into container
2023-03-31 21:05:06,673:INFO:Uploading model into container now
2023-03-31 21:05:06,673:INFO:_master_model_container: 3
2023-03-31 21:05:06,673:INFO:_display_container: 2
2023-03-31 21:05:06,673:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-31 21:05:06,673:INFO:create_model() successfully completed......................................
2023-03-31 21:05:06,817:INFO:SubProcess create_model() end ==================================
2023-03-31 21:05:06,817:INFO:Creating metrics dataframe
2023-03-31 21:05:06,833:INFO:Initializing Decision Tree Classifier
2023-03-31 21:05:06,833:INFO:Total runtime is 0.43684431314468386 minutes
2023-03-31 21:05:06,833:INFO:SubProcess create_model() called ==================================
2023-03-31 21:05:06,833:INFO:Initializing create_model()
2023-03-31 21:05:06,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:05:06,833:INFO:Checking exceptions
2023-03-31 21:05:06,844:INFO:Importing libraries
2023-03-31 21:05:06,844:INFO:Copying training dataset
2023-03-31 21:05:06,936:INFO:Defining folds
2023-03-31 21:05:06,936:INFO:Declaring metric variables
2023-03-31 21:05:06,936:INFO:Importing untrained model
2023-03-31 21:05:06,952:INFO:Decision Tree Classifier Imported successfully
2023-03-31 21:05:06,961:INFO:Starting cross validation
2023-03-31 21:05:06,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:05:12,491:INFO:Calculating mean and std
2023-03-31 21:05:12,491:INFO:Creating metrics dataframe
2023-03-31 21:05:13,028:INFO:Uploading results into container
2023-03-31 21:05:13,044:INFO:Uploading model into container now
2023-03-31 21:05:13,044:INFO:_master_model_container: 4
2023-03-31 21:05:13,044:INFO:_display_container: 2
2023-03-31 21:05:13,044:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6110, splitter='best')
2023-03-31 21:05:13,047:INFO:create_model() successfully completed......................................
2023-03-31 21:05:13,214:INFO:SubProcess create_model() end ==================================
2023-03-31 21:05:13,215:INFO:Creating metrics dataframe
2023-03-31 21:05:13,230:INFO:Initializing SVM - Linear Kernel
2023-03-31 21:05:13,230:INFO:Total runtime is 0.5434653639793396 minutes
2023-03-31 21:05:13,230:INFO:SubProcess create_model() called ==================================
2023-03-31 21:05:13,238:INFO:Initializing create_model()
2023-03-31 21:05:13,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:05:13,238:INFO:Checking exceptions
2023-03-31 21:05:13,238:INFO:Importing libraries
2023-03-31 21:05:13,238:INFO:Copying training dataset
2023-03-31 21:05:13,306:INFO:Defining folds
2023-03-31 21:05:13,306:INFO:Declaring metric variables
2023-03-31 21:05:13,321:INFO:Importing untrained model
2023-03-31 21:05:13,324:INFO:SVM - Linear Kernel Imported successfully
2023-03-31 21:05:13,325:INFO:Starting cross validation
2023-03-31 21:05:13,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:05:37,950:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:37,965:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:05:39,232:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:40,843:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:40,859:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:05:41,355:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:41,384:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:05:42,198:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:43,015:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:43,030:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:05:44,729:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:44,745:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:05:44,966:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:05:44,981:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:02,140:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:06:02,156:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:03,328:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-03-31 21:06:03,563:INFO:Calculating mean and std
2023-03-31 21:06:03,563:INFO:Creating metrics dataframe
2023-03-31 21:06:03,871:INFO:Uploading results into container
2023-03-31 21:06:03,871:INFO:Uploading model into container now
2023-03-31 21:06:03,871:INFO:_master_model_container: 5
2023-03-31 21:06:03,871:INFO:_display_container: 2
2023-03-31 21:06:03,871:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6110, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-31 21:06:03,871:INFO:create_model() successfully completed......................................
2023-03-31 21:06:04,047:INFO:SubProcess create_model() end ==================================
2023-03-31 21:06:04,047:INFO:Creating metrics dataframe
2023-03-31 21:06:04,071:INFO:Initializing Ridge Classifier
2023-03-31 21:06:04,071:INFO:Total runtime is 1.3908192197481792 minutes
2023-03-31 21:06:04,074:INFO:SubProcess create_model() called ==================================
2023-03-31 21:06:04,074:INFO:Initializing create_model()
2023-03-31 21:06:04,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:06:04,074:INFO:Checking exceptions
2023-03-31 21:06:04,075:INFO:Importing libraries
2023-03-31 21:06:04,075:INFO:Copying training dataset
2023-03-31 21:06:04,153:INFO:Defining folds
2023-03-31 21:06:04,153:INFO:Declaring metric variables
2023-03-31 21:06:04,169:INFO:Importing untrained model
2023-03-31 21:06:04,176:INFO:Ridge Classifier Imported successfully
2023-03-31 21:06:04,188:INFO:Starting cross validation
2023-03-31 21:06:04,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:06:04,583:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,599:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,615:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,615:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,630:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,646:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,646:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,661:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,677:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,693:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,740:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,740:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,756:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,756:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:04,756:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:04,771:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:05,383:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:05,399:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:05,446:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-03-31 21:06:05,462:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:06:08,121:INFO:Calculating mean and std
2023-03-31 21:06:08,121:INFO:Creating metrics dataframe
2023-03-31 21:06:08,655:INFO:Uploading results into container
2023-03-31 21:06:08,655:INFO:Uploading model into container now
2023-03-31 21:06:08,655:INFO:_master_model_container: 6
2023-03-31 21:06:08,655:INFO:_display_container: 2
2023-03-31 21:06:08,655:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=6110, solver='auto', tol=0.001)
2023-03-31 21:06:08,655:INFO:create_model() successfully completed......................................
2023-03-31 21:06:08,827:INFO:SubProcess create_model() end ==================================
2023-03-31 21:06:08,827:INFO:Creating metrics dataframe
2023-03-31 21:06:08,853:INFO:Initializing Random Forest Classifier
2023-03-31 21:06:08,853:INFO:Total runtime is 1.470517404874166 minutes
2023-03-31 21:06:08,856:INFO:SubProcess create_model() called ==================================
2023-03-31 21:06:08,856:INFO:Initializing create_model()
2023-03-31 21:06:08,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:06:08,856:INFO:Checking exceptions
2023-03-31 21:06:08,856:INFO:Importing libraries
2023-03-31 21:06:08,856:INFO:Copying training dataset
2023-03-31 21:06:08,920:INFO:Defining folds
2023-03-31 21:06:08,920:INFO:Declaring metric variables
2023-03-31 21:06:08,934:INFO:Importing untrained model
2023-03-31 21:06:08,938:INFO:Random Forest Classifier Imported successfully
2023-03-31 21:06:08,938:INFO:Starting cross validation
2023-03-31 21:06:08,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:07:14,781:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:14,913:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:14,943:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:14,943:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:14,943:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:14,951:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:15,146:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:15,342:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:07:16,465:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:07:17,490:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:07:17,537:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:07:17,837:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:07:18,098:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:07:18,514:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:07:39,458:INFO:Calculating mean and std
2023-03-31 21:07:39,505:INFO:Creating metrics dataframe
2023-03-31 21:07:40,355:INFO:Uploading results into container
2023-03-31 21:07:40,355:INFO:Uploading model into container now
2023-03-31 21:07:40,369:INFO:_master_model_container: 7
2023-03-31 21:07:40,369:INFO:_display_container: 2
2023-03-31 21:07:40,373:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=6110, verbose=0, warm_start=False)
2023-03-31 21:07:40,373:INFO:create_model() successfully completed......................................
2023-03-31 21:07:41,408:INFO:SubProcess create_model() end ==================================
2023-03-31 21:07:41,408:INFO:Creating metrics dataframe
2023-03-31 21:07:41,440:INFO:Initializing Quadratic Discriminant Analysis
2023-03-31 21:07:41,440:INFO:Total runtime is 3.013627326488495 minutes
2023-03-31 21:07:41,449:INFO:SubProcess create_model() called ==================================
2023-03-31 21:07:41,449:INFO:Initializing create_model()
2023-03-31 21:07:41,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:07:41,449:INFO:Checking exceptions
2023-03-31 21:07:41,449:INFO:Importing libraries
2023-03-31 21:07:41,450:INFO:Copying training dataset
2023-03-31 21:07:41,705:INFO:Defining folds
2023-03-31 21:07:41,705:INFO:Declaring metric variables
2023-03-31 21:07:41,713:INFO:Importing untrained model
2023-03-31 21:07:41,722:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-31 21:07:41,737:INFO:Starting cross validation
2023-03-31 21:07:41,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:07:46,224:INFO:Calculating mean and std
2023-03-31 21:07:46,224:INFO:Creating metrics dataframe
2023-03-31 21:07:46,599:INFO:Uploading results into container
2023-03-31 21:07:46,599:INFO:Uploading model into container now
2023-03-31 21:07:46,599:INFO:_master_model_container: 8
2023-03-31 21:07:46,599:INFO:_display_container: 2
2023-03-31 21:07:46,599:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-31 21:07:46,599:INFO:create_model() successfully completed......................................
2023-03-31 21:07:46,771:INFO:SubProcess create_model() end ==================================
2023-03-31 21:07:46,771:INFO:Creating metrics dataframe
2023-03-31 21:07:46,787:INFO:Initializing Ada Boost Classifier
2023-03-31 21:07:46,787:INFO:Total runtime is 3.1027363777160644 minutes
2023-03-31 21:07:46,802:INFO:SubProcess create_model() called ==================================
2023-03-31 21:07:46,803:INFO:Initializing create_model()
2023-03-31 21:07:46,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:07:46,803:INFO:Checking exceptions
2023-03-31 21:07:46,804:INFO:Importing libraries
2023-03-31 21:07:46,804:INFO:Copying training dataset
2023-03-31 21:07:46,882:INFO:Defining folds
2023-03-31 21:07:46,882:INFO:Declaring metric variables
2023-03-31 21:07:46,882:INFO:Importing untrained model
2023-03-31 21:07:46,896:INFO:Ada Boost Classifier Imported successfully
2023-03-31 21:07:46,904:INFO:Starting cross validation
2023-03-31 21:07:46,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:07:59,469:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:08:07,057:INFO:Calculating mean and std
2023-03-31 21:08:07,057:INFO:Creating metrics dataframe
2023-03-31 21:08:07,619:INFO:Uploading results into container
2023-03-31 21:08:07,619:INFO:Uploading model into container now
2023-03-31 21:08:07,619:INFO:_master_model_container: 9
2023-03-31 21:08:07,619:INFO:_display_container: 2
2023-03-31 21:08:07,619:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6110)
2023-03-31 21:08:07,619:INFO:create_model() successfully completed......................................
2023-03-31 21:08:07,777:INFO:SubProcess create_model() end ==================================
2023-03-31 21:08:07,777:INFO:Creating metrics dataframe
2023-03-31 21:08:07,808:INFO:Initializing Gradient Boosting Classifier
2023-03-31 21:08:07,808:INFO:Total runtime is 3.4530948360761005 minutes
2023-03-31 21:08:07,820:INFO:SubProcess create_model() called ==================================
2023-03-31 21:08:07,821:INFO:Initializing create_model()
2023-03-31 21:08:07,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:08:07,821:INFO:Checking exceptions
2023-03-31 21:08:07,821:INFO:Importing libraries
2023-03-31 21:08:07,821:INFO:Copying training dataset
2023-03-31 21:08:07,947:INFO:Defining folds
2023-03-31 21:08:07,947:INFO:Declaring metric variables
2023-03-31 21:08:07,961:INFO:Importing untrained model
2023-03-31 21:08:07,966:INFO:Gradient Boosting Classifier Imported successfully
2023-03-31 21:08:07,969:INFO:Starting cross validation
2023-03-31 21:08:07,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:10:01,441:INFO:Calculating mean and std
2023-03-31 21:10:01,441:INFO:Creating metrics dataframe
2023-03-31 21:10:02,658:INFO:Uploading results into container
2023-03-31 21:10:02,658:INFO:Uploading model into container now
2023-03-31 21:10:02,658:INFO:_master_model_container: 10
2023-03-31 21:10:02,658:INFO:_display_container: 2
2023-03-31 21:10:02,658:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6110, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-31 21:10:02,658:INFO:create_model() successfully completed......................................
2023-03-31 21:10:02,972:INFO:SubProcess create_model() end ==================================
2023-03-31 21:10:02,972:INFO:Creating metrics dataframe
2023-03-31 21:10:03,020:INFO:Initializing Linear Discriminant Analysis
2023-03-31 21:10:03,020:INFO:Total runtime is 5.373302372296651 minutes
2023-03-31 21:10:03,026:INFO:SubProcess create_model() called ==================================
2023-03-31 21:10:03,026:INFO:Initializing create_model()
2023-03-31 21:10:03,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:10:03,026:INFO:Checking exceptions
2023-03-31 21:10:03,026:INFO:Importing libraries
2023-03-31 21:10:03,026:INFO:Copying training dataset
2023-03-31 21:10:03,193:INFO:Defining folds
2023-03-31 21:10:03,193:INFO:Declaring metric variables
2023-03-31 21:10:03,213:INFO:Importing untrained model
2023-03-31 21:10:03,219:INFO:Linear Discriminant Analysis Imported successfully
2023-03-31 21:10:03,235:INFO:Starting cross validation
2023-03-31 21:10:03,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:10:04,574:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,613:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,626:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,709:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,786:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,864:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,958:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:04,989:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:07,032:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:07,144:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:10:12,998:INFO:Calculating mean and std
2023-03-31 21:10:12,998:INFO:Creating metrics dataframe
2023-03-31 21:10:14,186:INFO:Uploading results into container
2023-03-31 21:10:14,197:INFO:Uploading model into container now
2023-03-31 21:10:14,197:INFO:_master_model_container: 11
2023-03-31 21:10:14,197:INFO:_display_container: 2
2023-03-31 21:10:14,197:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-31 21:10:14,197:INFO:create_model() successfully completed......................................
2023-03-31 21:10:14,464:INFO:SubProcess create_model() end ==================================
2023-03-31 21:10:14,464:INFO:Creating metrics dataframe
2023-03-31 21:10:14,511:INFO:Initializing Extra Trees Classifier
2023-03-31 21:10:14,511:INFO:Total runtime is 5.564816192785899 minutes
2023-03-31 21:10:14,511:INFO:SubProcess create_model() called ==================================
2023-03-31 21:10:14,511:INFO:Initializing create_model()
2023-03-31 21:10:14,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:10:14,521:INFO:Checking exceptions
2023-03-31 21:10:14,521:INFO:Importing libraries
2023-03-31 21:10:14,521:INFO:Copying training dataset
2023-03-31 21:10:14,685:INFO:Defining folds
2023-03-31 21:10:14,685:INFO:Declaring metric variables
2023-03-31 21:10:14,700:INFO:Importing untrained model
2023-03-31 21:10:14,705:INFO:Extra Trees Classifier Imported successfully
2023-03-31 21:10:14,718:INFO:Starting cross validation
2023-03-31 21:10:14,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:12:20,078:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:22,682:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:22,866:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:23,241:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:23,571:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 27.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:23,853:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:24,156:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:12:25,563:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 28.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:13:19,334:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 34.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:26,026:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 37.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:27,720:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 38.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:28,657:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 38.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:29,891:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 39.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:31,060:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 40.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:32,085:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 40.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:13:34,513:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 42.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-31 21:16:02,541:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-31 21:16:04,795:INFO:Calculating mean and std
2023-03-31 21:16:04,984:INFO:Creating metrics dataframe
2023-03-31 21:16:06,160:INFO:Uploading results into container
2023-03-31 21:16:06,169:INFO:Uploading model into container now
2023-03-31 21:16:06,176:INFO:_master_model_container: 12
2023-03-31 21:16:06,176:INFO:_display_container: 2
2023-03-31 21:16:06,192:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6110, verbose=0, warm_start=False)
2023-03-31 21:16:06,192:INFO:create_model() successfully completed......................................
2023-03-31 21:16:07,950:INFO:SubProcess create_model() end ==================================
2023-03-31 21:16:07,950:INFO:Creating metrics dataframe
2023-03-31 21:16:07,996:INFO:Initializing Light Gradient Boosting Machine
2023-03-31 21:16:07,996:INFO:Total runtime is 11.456226674715678 minutes
2023-03-31 21:16:07,996:INFO:SubProcess create_model() called ==================================
2023-03-31 21:16:07,996:INFO:Initializing create_model()
2023-03-31 21:16:07,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:16:07,996:INFO:Checking exceptions
2023-03-31 21:16:07,996:INFO:Importing libraries
2023-03-31 21:16:08,012:INFO:Copying training dataset
2023-03-31 21:16:08,278:INFO:Defining folds
2023-03-31 21:16:08,278:INFO:Declaring metric variables
2023-03-31 21:16:08,278:INFO:Importing untrained model
2023-03-31 21:16:08,278:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-31 21:16:08,294:INFO:Starting cross validation
2023-03-31 21:16:08,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:16:23,274:INFO:Calculating mean and std
2023-03-31 21:16:23,274:INFO:Creating metrics dataframe
2023-03-31 21:16:24,305:INFO:Uploading results into container
2023-03-31 21:16:24,320:INFO:Uploading model into container now
2023-03-31 21:16:24,320:INFO:_master_model_container: 13
2023-03-31 21:16:24,320:INFO:_display_container: 2
2023-03-31 21:16:24,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6110, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-31 21:16:24,320:INFO:create_model() successfully completed......................................
2023-03-31 21:16:24,650:INFO:SubProcess create_model() end ==================================
2023-03-31 21:16:24,650:INFO:Creating metrics dataframe
2023-03-31 21:16:24,681:INFO:Initializing Dummy Classifier
2023-03-31 21:16:24,681:INFO:Total runtime is 11.734311056137084 minutes
2023-03-31 21:16:24,681:INFO:SubProcess create_model() called ==================================
2023-03-31 21:16:24,681:INFO:Initializing create_model()
2023-03-31 21:16:24,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246B811AFD0>, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:16:24,681:INFO:Checking exceptions
2023-03-31 21:16:24,681:INFO:Importing libraries
2023-03-31 21:16:24,681:INFO:Copying training dataset
2023-03-31 21:16:24,868:INFO:Defining folds
2023-03-31 21:16:24,868:INFO:Declaring metric variables
2023-03-31 21:16:24,884:INFO:Importing untrained model
2023-03-31 21:16:24,884:INFO:Dummy Classifier Imported successfully
2023-03-31 21:16:24,900:INFO:Starting cross validation
2023-03-31 21:16:24,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:16:25,480:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,543:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,574:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,653:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,747:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,778:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,825:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:25,919:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:27,097:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:27,097:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-31 21:16:32,442:INFO:Calculating mean and std
2023-03-31 21:16:32,442:INFO:Creating metrics dataframe
2023-03-31 21:16:33,568:INFO:Uploading results into container
2023-03-31 21:16:33,568:INFO:Uploading model into container now
2023-03-31 21:16:33,568:INFO:_master_model_container: 14
2023-03-31 21:16:33,568:INFO:_display_container: 2
2023-03-31 21:16:33,568:INFO:DummyClassifier(constant=None, random_state=6110, strategy='prior')
2023-03-31 21:16:33,568:INFO:create_model() successfully completed......................................
2023-03-31 21:16:33,833:INFO:SubProcess create_model() end ==================================
2023-03-31 21:16:33,833:INFO:Creating metrics dataframe
2023-03-31 21:16:33,896:INFO:Initializing create_model()
2023-03-31 21:16:33,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:16:33,896:INFO:Checking exceptions
2023-03-31 21:16:33,896:INFO:Importing libraries
2023-03-31 21:16:33,896:INFO:Copying training dataset
2023-03-31 21:16:34,100:INFO:Defining folds
2023-03-31 21:16:34,100:INFO:Declaring metric variables
2023-03-31 21:16:34,100:INFO:Importing untrained model
2023-03-31 21:16:34,100:INFO:Declaring custom model
2023-03-31 21:16:34,100:INFO:K Neighbors Classifier Imported successfully
2023-03-31 21:16:34,100:INFO:Cross validation set to False
2023-03-31 21:16:34,100:INFO:Fitting Model
2023-03-31 21:16:35,725:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 21:16:35,725:INFO:create_model() successfully completed......................................
2023-03-31 21:16:35,975:INFO:_master_model_container: 14
2023-03-31 21:16:35,975:INFO:_display_container: 2
2023-03-31 21:16:35,975:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 21:16:35,975:INFO:compare_models() successfully completed......................................
2023-03-31 21:16:44,582:INFO:Initializing tune_model()
2023-03-31 21:16:44,582:INFO:tune_model(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>)
2023-03-31 21:16:44,582:INFO:Checking exceptions
2023-03-31 21:16:44,706:INFO:Copying training dataset
2023-03-31 21:16:44,831:INFO:Checking base model
2023-03-31 21:16:44,831:INFO:Base model : K Neighbors Classifier
2023-03-31 21:16:44,831:INFO:Declaring metric variables
2023-03-31 21:16:44,847:INFO:Defining Hyperparameters
2023-03-31 21:16:45,116:INFO:Tuning with n_jobs=-1
2023-03-31 21:16:45,116:INFO:Initializing RandomizedSearchCV
2023-03-31 21:19:02,939:INFO:best_params: {'actual_estimator__weights': 'uniform', 'actual_estimator__n_neighbors': 21, 'actual_estimator__metric': 'manhattan'}
2023-03-31 21:19:02,939:INFO:Hyperparameter search completed
2023-03-31 21:19:02,939:INFO:SubProcess create_model() called ==================================
2023-03-31 21:19:02,939:INFO:Initializing create_model()
2023-03-31 21:19:02,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000246A618C1F0>, model_only=True, return_train_score=False, kwargs={'weights': 'uniform', 'n_neighbors': 21, 'metric': 'manhattan'})
2023-03-31 21:19:02,939:INFO:Checking exceptions
2023-03-31 21:19:02,939:INFO:Importing libraries
2023-03-31 21:19:02,939:INFO:Copying training dataset
2023-03-31 21:19:03,114:INFO:Defining folds
2023-03-31 21:19:03,114:INFO:Declaring metric variables
2023-03-31 21:19:03,123:INFO:Importing untrained model
2023-03-31 21:19:03,123:INFO:Declaring custom model
2023-03-31 21:19:03,129:INFO:K Neighbors Classifier Imported successfully
2023-03-31 21:19:03,145:INFO:Starting cross validation
2023-03-31 21:19:03,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:19:22,874:INFO:Calculating mean and std
2023-03-31 21:19:22,874:INFO:Creating metrics dataframe
2023-03-31 21:19:22,890:INFO:Finalizing model
2023-03-31 21:19:24,645:INFO:Uploading results into container
2023-03-31 21:19:24,645:INFO:Uploading model into container now
2023-03-31 21:19:24,645:INFO:_master_model_container: 15
2023-03-31 21:19:24,645:INFO:_display_container: 3
2023-03-31 21:19:24,645:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=21, p=2,
                     weights='uniform')
2023-03-31 21:19:24,645:INFO:create_model() successfully completed......................................
2023-03-31 21:19:24,850:INFO:SubProcess create_model() end ==================================
2023-03-31 21:19:24,850:INFO:choose_better activated
2023-03-31 21:19:24,850:INFO:SubProcess create_model() called ==================================
2023-03-31 21:19:24,850:INFO:Initializing create_model()
2023-03-31 21:19:24,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-31 21:19:24,850:INFO:Checking exceptions
2023-03-31 21:19:24,866:INFO:Importing libraries
2023-03-31 21:19:24,866:INFO:Copying training dataset
2023-03-31 21:19:25,024:INFO:Defining folds
2023-03-31 21:19:25,024:INFO:Declaring metric variables
2023-03-31 21:19:25,024:INFO:Importing untrained model
2023-03-31 21:19:25,024:INFO:Declaring custom model
2023-03-31 21:19:25,024:INFO:K Neighbors Classifier Imported successfully
2023-03-31 21:19:25,024:INFO:Starting cross validation
2023-03-31 21:19:25,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-31 21:19:43,692:INFO:Calculating mean and std
2023-03-31 21:19:43,692:INFO:Creating metrics dataframe
2023-03-31 21:19:43,692:INFO:Finalizing model
2023-03-31 21:19:45,080:INFO:Uploading results into container
2023-03-31 21:19:45,080:INFO:Uploading model into container now
2023-03-31 21:19:45,080:INFO:_master_model_container: 16
2023-03-31 21:19:45,080:INFO:_display_container: 4
2023-03-31 21:19:45,080:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-31 21:19:45,080:INFO:create_model() successfully completed......................................
2023-03-31 21:19:45,396:INFO:SubProcess create_model() end ==================================
2023-03-31 21:19:45,396:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') result for Accuracy is 0.846
2023-03-31 21:19:45,396:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=21, p=2,
                     weights='uniform') result for Accuracy is 0.8577
2023-03-31 21:19:45,396:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=21, p=2,
                     weights='uniform') is best model
2023-03-31 21:19:45,396:INFO:choose_better completed
2023-03-31 21:19:45,426:INFO:_master_model_container: 16
2023-03-31 21:19:45,426:INFO:_display_container: 3
2023-03-31 21:19:45,426:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=21, p=2,
                     weights='uniform')
2023-03-31 21:19:45,439:INFO:tune_model() successfully completed......................................
2023-03-31 21:19:54,344:INFO:Initializing plot_model()
2023-03-31 21:19:54,344:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',
                     metric_params=None, n_jobs=-1, n_neighbors=21, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000246E20F2490>, system=True)
2023-03-31 21:19:54,344:INFO:Checking exceptions
2023-03-31 21:19:54,406:INFO:Preloading libraries
2023-03-31 21:19:54,406:INFO:Copying training dataset
2023-03-31 21:19:54,406:INFO:Plot type: confusion_matrix
2023-03-31 21:19:55,032:INFO:Fitting Model
2023-03-31 21:19:55,032:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(

2023-03-31 21:19:55,047:INFO:Scoring test/hold-out set
2023-03-31 21:20:11,337:INFO:Visual Rendered Successfully
2023-03-31 21:20:11,524:INFO:plot_model() successfully completed......................................
2023-04-01 10:41:07,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-01 10:41:07,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-01 10:41:07,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-01 10:41:07,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-01 10:41:08,806:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-01 10:41:13,562:INFO:PyCaret ClassificationExperiment
2023-04-01 10:41:13,562:INFO:Logging name: clf-default-name
2023-04-01 10:41:13,562:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-01 10:41:13,562:INFO:version 3.0.0
2023-04-01 10:41:13,562:INFO:Initializing setup()
2023-04-01 10:41:13,562:INFO:self.USI: 3c93
2023-04-01 10:41:13,562:INFO:self._variable_keys: {'X', 'X_test', 'y', 'fold_generator', 'is_multiclass', 'gpu_param', 'y_test', 'fold_groups_param', 'fix_imbalance', 'log_plots_param', '_ml_usecase', 'exp_id', 'fold_shuffle_param', 'data', 'y_train', 'seed', 'html_param', 'memory', 'exp_name_log', 'USI', '_available_plots', 'idx', 'pipeline', 'X_train', 'target_param', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param'}
2023-04-01 10:41:13,562:INFO:Checking environment
2023-04-01 10:41:13,562:INFO:python_version: 3.9.12
2023-04-01 10:41:13,562:INFO:python_build: ('main', 'Apr  4 2022 05:22:27')
2023-04-01 10:41:13,562:INFO:machine: AMD64
2023-04-01 10:41:13,562:INFO:platform: Windows-10-10.0.22621-SP0
2023-04-01 10:41:13,562:INFO:Memory: svmem(total=8316030976, available=665829376, percent=92.0, used=7650201600, free=665829376)
2023-04-01 10:41:13,562:INFO:Physical Core: 4
2023-04-01 10:41:13,562:INFO:Logical Core: 8
2023-04-01 10:41:13,562:INFO:Checking libraries
2023-04-01 10:41:13,562:INFO:System:
2023-04-01 10:41:13,562:INFO:    python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
2023-04-01 10:41:13,562:INFO:executable: C:\Users\jaeek\anaconda3\python.exe
2023-04-01 10:41:13,562:INFO:   machine: Windows-10-10.0.22621-SP0
2023-04-01 10:41:13,562:INFO:PyCaret required dependencies:
2023-04-01 10:41:13,562:INFO:                 pip: 21.2.4
2023-04-01 10:41:13,562:INFO:          setuptools: 61.2.0
2023-04-01 10:41:13,562:INFO:             pycaret: 3.0.0
2023-04-01 10:41:13,562:INFO:             IPython: 8.2.0
2023-04-01 10:41:13,562:INFO:          ipywidgets: 7.6.5
2023-04-01 10:41:13,562:INFO:                tqdm: 4.64.0
2023-04-01 10:41:13,562:INFO:               numpy: 1.21.6
2023-04-01 10:41:13,562:INFO:              pandas: 1.4.2
2023-04-01 10:41:13,562:INFO:              jinja2: 2.11.3
2023-04-01 10:41:13,562:INFO:               scipy: 1.7.3
2023-04-01 10:41:13,562:INFO:              joblib: 1.2.0
2023-04-01 10:41:13,562:INFO:             sklearn: 1.0.2
2023-04-01 10:41:13,562:INFO:                pyod: 1.0.9
2023-04-01 10:41:13,562:INFO:            imblearn: 0.10.1
2023-04-01 10:41:13,562:INFO:   category_encoders: 2.6.0
2023-04-01 10:41:13,562:INFO:            lightgbm: 3.3.5
2023-04-01 10:41:13,562:INFO:               numba: 0.55.1
2023-04-01 10:41:13,562:INFO:            requests: 2.27.1
2023-04-01 10:41:13,562:INFO:          matplotlib: 3.5.1
2023-04-01 10:41:13,562:INFO:          scikitplot: 0.3.7
2023-04-01 10:41:13,562:INFO:         yellowbrick: 1.5
2023-04-01 10:41:13,562:INFO:              plotly: 5.6.0
2023-04-01 10:41:13,562:INFO:             kaleido: 0.2.1
2023-04-01 10:41:13,562:INFO:         statsmodels: 0.13.2
2023-04-01 10:41:13,562:INFO:              sktime: 0.16.1
2023-04-01 10:41:13,562:INFO:               tbats: 1.1.2
2023-04-01 10:41:13,562:INFO:            pmdarima: 2.0.3
2023-04-01 10:41:13,562:INFO:              psutil: 5.9.4
2023-04-01 10:41:13,562:INFO:PyCaret optional dependencies:
2023-04-01 10:41:13,578:INFO:                shap: 0.41.0
2023-04-01 10:41:13,578:INFO:           interpret: Not installed
2023-04-01 10:41:13,578:INFO:                umap: Not installed
2023-04-01 10:41:13,578:INFO:    pandas_profiling: 4.1.2
2023-04-01 10:41:13,578:INFO:  explainerdashboard: Not installed
2023-04-01 10:41:13,578:INFO:             autoviz: Not installed
2023-04-01 10:41:13,578:INFO:           fairlearn: Not installed
2023-04-01 10:41:13,578:INFO:             xgboost: Not installed
2023-04-01 10:41:13,578:INFO:            catboost: Not installed
2023-04-01 10:41:13,578:INFO:              kmodes: Not installed
2023-04-01 10:41:13,578:INFO:             mlxtend: Not installed
2023-04-01 10:41:13,578:INFO:       statsforecast: Not installed
2023-04-01 10:41:13,578:INFO:        tune_sklearn: Not installed
2023-04-01 10:41:13,578:INFO:                 ray: Not installed
2023-04-01 10:41:13,578:INFO:            hyperopt: Not installed
2023-04-01 10:41:13,578:INFO:              optuna: Not installed
2023-04-01 10:41:13,578:INFO:               skopt: Not installed
2023-04-01 10:41:13,578:INFO:              mlflow: Not installed
2023-04-01 10:41:13,578:INFO:              gradio: Not installed
2023-04-01 10:41:13,578:INFO:             fastapi: Not installed
2023-04-01 10:41:13,578:INFO:             uvicorn: Not installed
2023-04-01 10:41:13,578:INFO:              m2cgen: Not installed
2023-04-01 10:41:13,578:INFO:           evidently: Not installed
2023-04-01 10:41:13,578:INFO:               fugue: Not installed
2023-04-01 10:41:13,578:INFO:           streamlit: Not installed
2023-04-01 10:41:13,578:INFO:             prophet: Not installed
2023-04-01 10:41:13,578:INFO:None
2023-04-01 10:41:13,578:INFO:Set up data.
2023-04-01 10:41:13,625:INFO:Set up train/test split.
2023-04-01 10:41:13,766:INFO:Set up index.
2023-04-01 10:41:13,766:INFO:Set up folding strategy.
2023-04-01 10:41:13,766:INFO:Assigning column types.
2023-04-01 10:41:13,788:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-01 10:41:13,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-01 10:41:13,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-01 10:41:13,905:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:13,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-01 10:41:14,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-01 10:41:14,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,054:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-01 10:41:14,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-01 10:41:14,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,255:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-01 10:41:14,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,285:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-01 10:41:14,381:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:14,491:INFO:Preparing preprocessing pipeline...
2023-04-01 10:41:14,506:INFO:Set up simple imputation.
2023-04-01 10:41:14,631:INFO:Finished creating preprocessing pipeline.
2023-04-01 10:41:14,647:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jaeek\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['MONTHS_BALANCE', 'DAYS_BIRTH',
                                             'DAYS_EMPLOYED',
                                             'AMT_INCOME_TOTAL',
                                             'OCCUPATION_TYPE'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-04-01 10:41:14,647:INFO:Creating final display dataframe.
2023-04-01 10:41:15,084:INFO:Setup _display_container:                     Description             Value
0                    Session id              1004
1                        Target            STATUS
2                   Target type            Binary
3           Original data shape       (365322, 6)
4        Transformed data shape       (365322, 6)
5   Transformed train set shape       (255725, 6)
6    Transformed test set shape       (109597, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3c93
2023-04-01 10:41:15,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:15,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:15,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:15,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-01 10:41:15,269:INFO:setup() successfully completed in 2.45s...............
2023-04-01 10:41:18,134:INFO:Initializing compare_models()
2023-04-01 10:41:18,134:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-01 10:41:18,135:INFO:Checking exceptions
2023-04-01 10:41:18,172:INFO:Preparing display monitor
2023-04-01 10:41:18,211:INFO:Initializing Logistic Regression
2023-04-01 10:41:18,211:INFO:Total runtime is 0.0 minutes
2023-04-01 10:41:18,222:INFO:SubProcess create_model() called ==================================
2023-04-01 10:41:18,222:INFO:Initializing create_model()
2023-04-01 10:41:18,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:41:18,222:INFO:Checking exceptions
2023-04-01 10:41:18,222:INFO:Importing libraries
2023-04-01 10:41:18,222:INFO:Copying training dataset
2023-04-01 10:41:18,303:INFO:Defining folds
2023-04-01 10:41:18,303:INFO:Declaring metric variables
2023-04-01 10:41:18,319:INFO:Importing untrained model
2023-04-01 10:41:18,319:INFO:Logistic Regression Imported successfully
2023-04-01 10:41:18,332:INFO:Starting cross validation
2023-04-01 10:41:18,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:41:27,062:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,082:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,098:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,098:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,129:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,182:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,197:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:27,339:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:28,689:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:28,720:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:41:31,441:INFO:Calculating mean and std
2023-04-01 10:41:31,441:INFO:Creating metrics dataframe
2023-04-01 10:41:32,089:INFO:Uploading results into container
2023-04-01 10:41:32,089:INFO:Uploading model into container now
2023-04-01 10:41:32,089:INFO:_master_model_container: 1
2023-04-01 10:41:32,089:INFO:_display_container: 2
2023-04-01 10:41:32,089:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1004, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-01 10:41:32,089:INFO:create_model() successfully completed......................................
2023-04-01 10:41:32,398:INFO:SubProcess create_model() end ==================================
2023-04-01 10:41:32,398:INFO:Creating metrics dataframe
2023-04-01 10:41:32,413:INFO:Initializing K Neighbors Classifier
2023-04-01 10:41:32,413:INFO:Total runtime is 0.23671342929204306 minutes
2023-04-01 10:41:32,436:INFO:SubProcess create_model() called ==================================
2023-04-01 10:41:32,436:INFO:Initializing create_model()
2023-04-01 10:41:32,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:41:32,437:INFO:Checking exceptions
2023-04-01 10:41:32,437:INFO:Importing libraries
2023-04-01 10:41:32,437:INFO:Copying training dataset
2023-04-01 10:41:32,535:INFO:Defining folds
2023-04-01 10:41:32,535:INFO:Declaring metric variables
2023-04-01 10:41:32,551:INFO:Importing untrained model
2023-04-01 10:41:32,554:INFO:K Neighbors Classifier Imported successfully
2023-04-01 10:41:32,554:INFO:Starting cross validation
2023-04-01 10:41:32,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:41:41,138:INFO:Calculating mean and std
2023-04-01 10:41:41,138:INFO:Creating metrics dataframe
2023-04-01 10:41:41,735:INFO:Uploading results into container
2023-04-01 10:41:41,735:INFO:Uploading model into container now
2023-04-01 10:41:41,735:INFO:_master_model_container: 2
2023-04-01 10:41:41,735:INFO:_display_container: 2
2023-04-01 10:41:41,751:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-01 10:41:41,751:INFO:create_model() successfully completed......................................
2023-04-01 10:41:41,915:INFO:SubProcess create_model() end ==================================
2023-04-01 10:41:41,915:INFO:Creating metrics dataframe
2023-04-01 10:41:41,915:INFO:Initializing Naive Bayes
2023-04-01 10:41:41,915:INFO:Total runtime is 0.3950691103935242 minutes
2023-04-01 10:41:41,930:INFO:SubProcess create_model() called ==================================
2023-04-01 10:41:41,930:INFO:Initializing create_model()
2023-04-01 10:41:41,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:41:41,930:INFO:Checking exceptions
2023-04-01 10:41:41,930:INFO:Importing libraries
2023-04-01 10:41:41,930:INFO:Copying training dataset
2023-04-01 10:41:42,050:INFO:Defining folds
2023-04-01 10:41:42,050:INFO:Declaring metric variables
2023-04-01 10:41:42,070:INFO:Importing untrained model
2023-04-01 10:41:42,071:INFO:Naive Bayes Imported successfully
2023-04-01 10:41:42,071:INFO:Starting cross validation
2023-04-01 10:41:42,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:41:47,119:INFO:Calculating mean and std
2023-04-01 10:41:47,119:INFO:Creating metrics dataframe
2023-04-01 10:41:47,796:INFO:Uploading results into container
2023-04-01 10:41:47,796:INFO:Uploading model into container now
2023-04-01 10:41:47,796:INFO:_master_model_container: 3
2023-04-01 10:41:47,796:INFO:_display_container: 2
2023-04-01 10:41:47,796:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-01 10:41:47,796:INFO:create_model() successfully completed......................................
2023-04-01 10:41:47,980:INFO:SubProcess create_model() end ==================================
2023-04-01 10:41:47,980:INFO:Creating metrics dataframe
2023-04-01 10:41:47,996:INFO:Initializing Decision Tree Classifier
2023-04-01 10:41:47,996:INFO:Total runtime is 0.4964201132456462 minutes
2023-04-01 10:41:48,016:INFO:SubProcess create_model() called ==================================
2023-04-01 10:41:48,017:INFO:Initializing create_model()
2023-04-01 10:41:48,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:41:48,017:INFO:Checking exceptions
2023-04-01 10:41:48,018:INFO:Importing libraries
2023-04-01 10:41:48,018:INFO:Copying training dataset
2023-04-01 10:41:48,118:INFO:Defining folds
2023-04-01 10:41:48,118:INFO:Declaring metric variables
2023-04-01 10:41:48,127:INFO:Importing untrained model
2023-04-01 10:41:48,130:INFO:Decision Tree Classifier Imported successfully
2023-04-01 10:41:48,138:INFO:Starting cross validation
2023-04-01 10:41:48,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:41:54,210:INFO:Calculating mean and std
2023-04-01 10:41:54,210:INFO:Creating metrics dataframe
2023-04-01 10:41:54,714:INFO:Uploading results into container
2023-04-01 10:41:54,714:INFO:Uploading model into container now
2023-04-01 10:41:54,729:INFO:_master_model_container: 4
2023-04-01 10:41:54,729:INFO:_display_container: 2
2023-04-01 10:41:54,729:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1004, splitter='best')
2023-04-01 10:41:54,729:INFO:create_model() successfully completed......................................
2023-04-01 10:41:54,895:INFO:SubProcess create_model() end ==================================
2023-04-01 10:41:54,895:INFO:Creating metrics dataframe
2023-04-01 10:41:54,910:INFO:Initializing SVM - Linear Kernel
2023-04-01 10:41:54,926:INFO:Total runtime is 0.6119224389394124 minutes
2023-04-01 10:41:54,931:INFO:SubProcess create_model() called ==================================
2023-04-01 10:41:54,932:INFO:Initializing create_model()
2023-04-01 10:41:54,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:41:54,932:INFO:Checking exceptions
2023-04-01 10:41:54,932:INFO:Importing libraries
2023-04-01 10:41:54,932:INFO:Copying training dataset
2023-04-01 10:41:55,066:INFO:Defining folds
2023-04-01 10:41:55,066:INFO:Declaring metric variables
2023-04-01 10:41:55,074:INFO:Importing untrained model
2023-04-01 10:41:55,077:INFO:SVM - Linear Kernel Imported successfully
2023-04-01 10:41:55,088:INFO:Starting cross validation
2023-04-01 10:41:55,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:42:20,431:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:20,829:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:23,026:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:24,577:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:24,580:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:24,700:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:25,019:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:25,035:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:25,967:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:26,376:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:26,392:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:36,786:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:36,802:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:43,074:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-01 10:42:43,233:INFO:Calculating mean and std
2023-04-01 10:42:43,233:INFO:Creating metrics dataframe
2023-04-01 10:42:43,935:INFO:Uploading results into container
2023-04-01 10:42:43,935:INFO:Uploading model into container now
2023-04-01 10:42:43,935:INFO:_master_model_container: 5
2023-04-01 10:42:43,935:INFO:_display_container: 2
2023-04-01 10:42:43,945:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1004, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-01 10:42:43,945:INFO:create_model() successfully completed......................................
2023-04-01 10:42:44,113:INFO:SubProcess create_model() end ==================================
2023-04-01 10:42:44,113:INFO:Creating metrics dataframe
2023-04-01 10:42:44,128:INFO:Initializing Ridge Classifier
2023-04-01 10:42:44,128:INFO:Total runtime is 1.4319502234458925 minutes
2023-04-01 10:42:44,128:INFO:SubProcess create_model() called ==================================
2023-04-01 10:42:44,128:INFO:Initializing create_model()
2023-04-01 10:42:44,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:42:44,128:INFO:Checking exceptions
2023-04-01 10:42:44,128:INFO:Importing libraries
2023-04-01 10:42:44,128:INFO:Copying training dataset
2023-04-01 10:42:44,264:INFO:Defining folds
2023-04-01 10:42:44,264:INFO:Declaring metric variables
2023-04-01 10:42:44,283:INFO:Importing untrained model
2023-04-01 10:42:44,288:INFO:Ridge Classifier Imported successfully
2023-04-01 10:42:44,288:INFO:Starting cross validation
2023-04-01 10:42:44,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:42:44,777:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,777:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,794:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,808:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,824:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,840:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,903:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,903:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,918:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,926:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,965:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,982:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,982:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:44,982:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,997:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:44,997:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:45,799:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:45,815:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:45,878:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-01 10:42:45,894:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:42:49,201:INFO:Calculating mean and std
2023-04-01 10:42:49,201:INFO:Creating metrics dataframe
2023-04-01 10:42:49,802:INFO:Uploading results into container
2023-04-01 10:42:49,802:INFO:Uploading model into container now
2023-04-01 10:42:49,818:INFO:_master_model_container: 6
2023-04-01 10:42:49,818:INFO:_display_container: 2
2023-04-01 10:42:49,818:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=1004, solver='auto', tol=0.001)
2023-04-01 10:42:49,818:INFO:create_model() successfully completed......................................
2023-04-01 10:42:49,978:INFO:SubProcess create_model() end ==================================
2023-04-01 10:42:49,978:INFO:Creating metrics dataframe
2023-04-01 10:42:50,010:INFO:Initializing Random Forest Classifier
2023-04-01 10:42:50,010:INFO:Total runtime is 1.5299910744031273 minutes
2023-04-01 10:42:50,019:INFO:SubProcess create_model() called ==================================
2023-04-01 10:42:50,020:INFO:Initializing create_model()
2023-04-01 10:42:50,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:42:50,020:INFO:Checking exceptions
2023-04-01 10:42:50,020:INFO:Importing libraries
2023-04-01 10:42:50,020:INFO:Copying training dataset
2023-04-01 10:42:50,100:INFO:Defining folds
2023-04-01 10:42:50,100:INFO:Declaring metric variables
2023-04-01 10:42:50,109:INFO:Importing untrained model
2023-04-01 10:42:50,114:INFO:Random Forest Classifier Imported successfully
2023-04-01 10:42:50,121:INFO:Starting cross validation
2023-04-01 10:42:50,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:43:54,973:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:43:55,445:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:43:55,465:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:43:56,331:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:43:56,638:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:43:57,166:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:43:57,186:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:43:57,270:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:43:58,179:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:44:18,894:INFO:Calculating mean and std
2023-04-01 10:44:18,941:INFO:Creating metrics dataframe
2023-04-01 10:44:19,799:INFO:Uploading results into container
2023-04-01 10:44:19,799:INFO:Uploading model into container now
2023-04-01 10:44:19,815:INFO:_master_model_container: 7
2023-04-01 10:44:19,815:INFO:_display_container: 2
2023-04-01 10:44:19,822:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1004, verbose=0, warm_start=False)
2023-04-01 10:44:19,822:INFO:create_model() successfully completed......................................
2023-04-01 10:44:20,613:INFO:SubProcess create_model() end ==================================
2023-04-01 10:44:20,613:INFO:Creating metrics dataframe
2023-04-01 10:44:20,645:INFO:Initializing Quadratic Discriminant Analysis
2023-04-01 10:44:20,645:INFO:Total runtime is 3.040565661589305 minutes
2023-04-01 10:44:20,645:INFO:SubProcess create_model() called ==================================
2023-04-01 10:44:20,645:INFO:Initializing create_model()
2023-04-01 10:44:20,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:44:20,645:INFO:Checking exceptions
2023-04-01 10:44:20,645:INFO:Importing libraries
2023-04-01 10:44:20,645:INFO:Copying training dataset
2023-04-01 10:44:20,843:INFO:Defining folds
2023-04-01 10:44:20,843:INFO:Declaring metric variables
2023-04-01 10:44:20,857:INFO:Importing untrained model
2023-04-01 10:44:20,859:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-01 10:44:20,869:INFO:Starting cross validation
2023-04-01 10:44:20,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:44:25,849:INFO:Calculating mean and std
2023-04-01 10:44:25,849:INFO:Creating metrics dataframe
2023-04-01 10:44:26,422:INFO:Uploading results into container
2023-04-01 10:44:26,422:INFO:Uploading model into container now
2023-04-01 10:44:26,422:INFO:_master_model_container: 8
2023-04-01 10:44:26,422:INFO:_display_container: 2
2023-04-01 10:44:26,422:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-01 10:44:26,422:INFO:create_model() successfully completed......................................
2023-04-01 10:44:26,608:INFO:SubProcess create_model() end ==================================
2023-04-01 10:44:26,608:INFO:Creating metrics dataframe
2023-04-01 10:44:26,624:INFO:Initializing Ada Boost Classifier
2023-04-01 10:44:26,624:INFO:Total runtime is 3.140218257904053 minutes
2023-04-01 10:44:26,624:INFO:SubProcess create_model() called ==================================
2023-04-01 10:44:26,624:INFO:Initializing create_model()
2023-04-01 10:44:26,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:44:26,624:INFO:Checking exceptions
2023-04-01 10:44:26,624:INFO:Importing libraries
2023-04-01 10:44:26,624:INFO:Copying training dataset
2023-04-01 10:44:26,747:INFO:Defining folds
2023-04-01 10:44:26,747:INFO:Declaring metric variables
2023-04-01 10:44:26,764:INFO:Importing untrained model
2023-04-01 10:44:26,766:INFO:Ada Boost Classifier Imported successfully
2023-04-01 10:44:26,770:INFO:Starting cross validation
2023-04-01 10:44:26,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:44:46,957:INFO:Calculating mean and std
2023-04-01 10:44:46,957:INFO:Creating metrics dataframe
2023-04-01 10:44:47,723:INFO:Uploading results into container
2023-04-01 10:44:47,723:INFO:Uploading model into container now
2023-04-01 10:44:47,723:INFO:_master_model_container: 9
2023-04-01 10:44:47,723:INFO:_display_container: 2
2023-04-01 10:44:47,723:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1004)
2023-04-01 10:44:47,723:INFO:create_model() successfully completed......................................
2023-04-01 10:44:47,954:INFO:SubProcess create_model() end ==================================
2023-04-01 10:44:47,954:INFO:Creating metrics dataframe
2023-04-01 10:44:47,992:INFO:Initializing Gradient Boosting Classifier
2023-04-01 10:44:47,992:INFO:Total runtime is 3.4963517904281622 minutes
2023-04-01 10:44:47,999:INFO:SubProcess create_model() called ==================================
2023-04-01 10:44:47,999:INFO:Initializing create_model()
2023-04-01 10:44:48,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:44:48,000:INFO:Checking exceptions
2023-04-01 10:44:48,000:INFO:Importing libraries
2023-04-01 10:44:48,000:INFO:Copying training dataset
2023-04-01 10:44:48,080:INFO:Defining folds
2023-04-01 10:44:48,080:INFO:Declaring metric variables
2023-04-01 10:44:48,098:INFO:Importing untrained model
2023-04-01 10:44:48,098:INFO:Gradient Boosting Classifier Imported successfully
2023-04-01 10:44:48,098:INFO:Starting cross validation
2023-04-01 10:44:48,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:45:57,028:INFO:Calculating mean and std
2023-04-01 10:45:57,028:INFO:Creating metrics dataframe
2023-04-01 10:45:57,633:INFO:Uploading results into container
2023-04-01 10:45:57,633:INFO:Uploading model into container now
2023-04-01 10:45:57,633:INFO:_master_model_container: 10
2023-04-01 10:45:57,633:INFO:_display_container: 2
2023-04-01 10:45:57,633:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1004, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-01 10:45:57,633:INFO:create_model() successfully completed......................................
2023-04-01 10:45:57,804:INFO:SubProcess create_model() end ==================================
2023-04-01 10:45:57,804:INFO:Creating metrics dataframe
2023-04-01 10:45:57,804:INFO:Initializing Linear Discriminant Analysis
2023-04-01 10:45:57,804:INFO:Total runtime is 4.659891947110495 minutes
2023-04-01 10:45:57,821:INFO:SubProcess create_model() called ==================================
2023-04-01 10:45:57,821:INFO:Initializing create_model()
2023-04-01 10:45:57,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:45:57,822:INFO:Checking exceptions
2023-04-01 10:45:57,822:INFO:Importing libraries
2023-04-01 10:45:57,822:INFO:Copying training dataset
2023-04-01 10:45:57,928:INFO:Defining folds
2023-04-01 10:45:57,928:INFO:Declaring metric variables
2023-04-01 10:45:57,928:INFO:Importing untrained model
2023-04-01 10:45:57,936:INFO:Linear Discriminant Analysis Imported successfully
2023-04-01 10:45:57,940:INFO:Starting cross validation
2023-04-01 10:45:57,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:45:58,670:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,685:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,780:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,795:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,873:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,905:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,936:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:45:58,936:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:46:00,053:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:46:00,053:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:46:03,217:INFO:Calculating mean and std
2023-04-01 10:46:03,217:INFO:Creating metrics dataframe
2023-04-01 10:46:03,937:INFO:Uploading results into container
2023-04-01 10:46:03,937:INFO:Uploading model into container now
2023-04-01 10:46:03,937:INFO:_master_model_container: 11
2023-04-01 10:46:03,937:INFO:_display_container: 2
2023-04-01 10:46:03,953:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-01 10:46:03,953:INFO:create_model() successfully completed......................................
2023-04-01 10:46:04,089:INFO:SubProcess create_model() end ==================================
2023-04-01 10:46:04,089:INFO:Creating metrics dataframe
2023-04-01 10:46:04,104:INFO:Initializing Extra Trees Classifier
2023-04-01 10:46:04,104:INFO:Total runtime is 4.7648965199788424 minutes
2023-04-01 10:46:04,122:INFO:SubProcess create_model() called ==================================
2023-04-01 10:46:04,122:INFO:Initializing create_model()
2023-04-01 10:46:04,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:46:04,122:INFO:Checking exceptions
2023-04-01 10:46:04,122:INFO:Importing libraries
2023-04-01 10:46:04,122:INFO:Copying training dataset
2023-04-01 10:46:04,211:INFO:Defining folds
2023-04-01 10:46:04,211:INFO:Declaring metric variables
2023-04-01 10:46:04,230:INFO:Importing untrained model
2023-04-01 10:46:04,233:INFO:Extra Trees Classifier Imported successfully
2023-04-01 10:46:04,233:INFO:Starting cross validation
2023-04-01 10:46:04,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:47:30,284:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 23.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:31,171:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 24.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:34,129:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 23.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:34,212:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 23.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:35,638:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 24.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:38,946:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 23.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:39,432:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 22.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:47:42,628:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 23.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:48:13,473:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 22.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:17,455:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 22.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:20,163:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 23.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:27,872:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 28.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:27,909:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 32.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:28,749:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 27.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:29,126:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 25.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:31,058:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 25.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:42,826:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 4.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:48:46,440:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-01 10:48:48,208:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-01 10:48:55,663:INFO:Calculating mean and std
2023-04-01 10:48:55,759:INFO:Creating metrics dataframe
2023-04-01 10:48:56,303:INFO:Uploading results into container
2023-04-01 10:48:56,315:INFO:Uploading model into container now
2023-04-01 10:48:56,315:INFO:_master_model_container: 12
2023-04-01 10:48:56,315:INFO:_display_container: 2
2023-04-01 10:48:56,347:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1004, verbose=0, warm_start=False)
2023-04-01 10:48:56,347:INFO:create_model() successfully completed......................................
2023-04-01 10:48:57,276:INFO:SubProcess create_model() end ==================================
2023-04-01 10:48:57,276:INFO:Creating metrics dataframe
2023-04-01 10:48:57,292:INFO:Initializing Light Gradient Boosting Machine
2023-04-01 10:48:57,292:INFO:Total runtime is 7.65135240952174 minutes
2023-04-01 10:48:57,292:INFO:SubProcess create_model() called ==================================
2023-04-01 10:48:57,292:INFO:Initializing create_model()
2023-04-01 10:48:57,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:48:57,292:INFO:Checking exceptions
2023-04-01 10:48:57,292:INFO:Importing libraries
2023-04-01 10:48:57,292:INFO:Copying training dataset
2023-04-01 10:48:57,461:INFO:Defining folds
2023-04-01 10:48:57,461:INFO:Declaring metric variables
2023-04-01 10:48:57,461:INFO:Importing untrained model
2023-04-01 10:48:57,473:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-01 10:48:57,480:INFO:Starting cross validation
2023-04-01 10:48:57,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:49:06,308:INFO:Calculating mean and std
2023-04-01 10:49:06,308:INFO:Creating metrics dataframe
2023-04-01 10:49:06,749:INFO:Uploading results into container
2023-04-01 10:49:06,749:INFO:Uploading model into container now
2023-04-01 10:49:06,749:INFO:_master_model_container: 13
2023-04-01 10:49:06,749:INFO:_display_container: 2
2023-04-01 10:49:06,749:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1004, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-01 10:49:06,749:INFO:create_model() successfully completed......................................
2023-04-01 10:49:06,919:INFO:SubProcess create_model() end ==================================
2023-04-01 10:49:06,919:INFO:Creating metrics dataframe
2023-04-01 10:49:06,950:INFO:Initializing Dummy Classifier
2023-04-01 10:49:06,950:INFO:Total runtime is 7.812318746248883 minutes
2023-04-01 10:49:06,965:INFO:SubProcess create_model() called ==================================
2023-04-01 10:49:06,965:INFO:Initializing create_model()
2023-04-01 10:49:06,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000162BD201340>, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:49:06,966:INFO:Checking exceptions
2023-04-01 10:49:06,966:INFO:Importing libraries
2023-04-01 10:49:06,966:INFO:Copying training dataset
2023-04-01 10:49:07,056:INFO:Defining folds
2023-04-01 10:49:07,056:INFO:Declaring metric variables
2023-04-01 10:49:07,056:INFO:Importing untrained model
2023-04-01 10:49:07,067:INFO:Dummy Classifier Imported successfully
2023-04-01 10:49:07,076:INFO:Starting cross validation
2023-04-01 10:49:07,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-01 10:49:07,391:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,423:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,439:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,486:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,517:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,533:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,595:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:07,611:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:08,287:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:08,287:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-01 10:49:11,194:INFO:Calculating mean and std
2023-04-01 10:49:11,194:INFO:Creating metrics dataframe
2023-04-01 10:49:11,727:INFO:Uploading results into container
2023-04-01 10:49:11,727:INFO:Uploading model into container now
2023-04-01 10:49:11,727:INFO:_master_model_container: 14
2023-04-01 10:49:11,727:INFO:_display_container: 2
2023-04-01 10:49:11,727:INFO:DummyClassifier(constant=None, random_state=1004, strategy='prior')
2023-04-01 10:49:11,727:INFO:create_model() successfully completed......................................
2023-04-01 10:49:11,884:INFO:SubProcess create_model() end ==================================
2023-04-01 10:49:11,884:INFO:Creating metrics dataframe
2023-04-01 10:49:11,925:INFO:Initializing create_model()
2023-04-01 10:49:11,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162AB7D39A0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-01 10:49:11,925:INFO:Checking exceptions
2023-04-01 10:49:11,931:INFO:Importing libraries
2023-04-01 10:49:11,931:INFO:Copying training dataset
2023-04-01 10:49:12,006:INFO:Defining folds
2023-04-01 10:49:12,006:INFO:Declaring metric variables
2023-04-01 10:49:12,006:INFO:Importing untrained model
2023-04-01 10:49:12,006:INFO:Declaring custom model
2023-04-01 10:49:12,006:INFO:K Neighbors Classifier Imported successfully
2023-04-01 10:49:12,006:INFO:Cross validation set to False
2023-04-01 10:49:12,006:INFO:Fitting Model
2023-04-01 10:49:12,934:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-01 10:49:12,934:INFO:create_model() successfully completed......................................
2023-04-01 10:49:13,116:INFO:_master_model_container: 14
2023-04-01 10:49:13,116:INFO:_display_container: 2
2023-04-01 10:49:13,116:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-01 10:49:13,116:INFO:compare_models() successfully completed......................................
2023-04-01 10:49:29,218:WARNING:C:\Users\jaeek\anaconda3\lib\site-packages\multimethod\__init__.py:315: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  return func(*args, **kwargs)

